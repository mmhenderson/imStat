{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc92beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import fft, ifft\n",
    "import scipy\n",
    "\n",
    "from skimage import data\n",
    "from skimage import io, transform, color\n",
    "from skimage.util import img_as_float, pad\n",
    "from skimage.filters import gabor_kernel\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import nibabel as nib\n",
    "\n",
    "import gfb_utils as g\n",
    "import nsd_utils as n\n",
    "\n",
    "sys.path.append('/user_data/mmhender/coco_annot/cocoapi/PythonAPI/')\n",
    "from pycocotools.coco import COCO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e8ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories and what sessions/subjects to load\n",
    "\n",
    "code_dir = '/user_data/mmhender/test_code/'\n",
    "nsd_dir = '/lab_data/tarrlab/common/datasets/NSD/'\n",
    "\n",
    "trials_per_sess = 750\n",
    "nsess = 40\n",
    "trials_per_subj = trials_per_sess*nsess\n",
    "subj = 1\n",
    "sess = 3\n",
    "\n",
    "subj_data_dir = os.path.join(nsd_dir,\n",
    "                 'nsddata_betas','ppdata','subj%02d'%subj,'func1pt8mm',\n",
    "                             'betas_fithrf_GLMdenoise_RR')\n",
    "subj_roi_dir = os.path.join(nsd_dir, 'nsddata','ppdata','subj%02d'%subj,\n",
    "                           'func1pt8mm','roi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127dc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the dataset here\n",
    "subj = 1\n",
    "roi_label = 1\n",
    "sess=2\n",
    "\n",
    "roi_filename='lh.prf-visualrois.nii.gz'\n",
    "\n",
    "roi_voxels = n.get_roi_voxels(subj, roi_label, roi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj=1\n",
    "batch_size=10\n",
    "\n",
    "dset = n.nsd_dataset(subj, voxel_inds = roi_voxels)\n",
    "trn, val, trn_subset = n.get_dataset_splits(dset1, subset_trn=True, rndseed = 983458)\n",
    "valgenerator = n.nsd_dataloader(val1, batch_size=batch_size, shuffle=True, rndseed = 858875)\n",
    "\n",
    "item = valgenerator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98457066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_inds = np.tile(np.arange(0,10),[2])\n",
    "which_sess = np.repeat(np.arange(1,3), 10)\n",
    "\n",
    "which_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16d3b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "<class 'numpy.ndarray'>\n",
      "h5py loading time is 5.19\n",
      "first indexing time  is 0.00\n",
      "<class 'numpy.ndarray'>\n",
      "second indexing time  is 0.00\n",
      "<class 'list'>\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "<class 'numpy.ndarray'>\n",
      "h5py loading time is 5.11\n",
      "first indexing time  is 0.00\n",
      "<class 'numpy.ndarray'>\n",
      "second indexing time  is 0.00\n"
     ]
    }
   ],
   "source": [
    "nsd_dir = '/lab_data/tarrlab/common/datasets/NSD/'\n",
    "subj_data_dir = os.path.join(nsd_dir,\n",
    "                 'nsddata_betas','ppdata','subj%02d'%subj,'func1pt8mm',\n",
    "                             'betas_fithrf_GLMdenoise_RR')\n",
    "se=1\n",
    "\n",
    "trial_inds = np.tile(np.arange(0,10),[2])\n",
    "which_sess = np.repeat(np.arange(1,3), 10)\n",
    "trials_per_sess=10\n",
    "\n",
    "voxel_inds = roi_voxels\n",
    "big_array = np.zeros([20,np.shape(voxel_inds)[1]])\n",
    "\n",
    "for se in np.arange(1,3):\n",
    "    \n",
    "    trials_this_sess = (trial_inds[which_sess==se]).tolist()\n",
    "    print(type(trials_this_sess))\n",
    "    print(trials_this_sess)\n",
    "    \n",
    "    t = time.time()\n",
    "\n",
    "    hd5_fn = os.path.join(subj_data_dir,'betas_session%02d.hdf5'%se)\n",
    "\n",
    "    data_this_sess = h5py.File(hd5_fn, \"r\").get('betas')[0:10,:,:,:]\n",
    "    print(type(data_this_sess))\n",
    "    elapsed = time.time() - t\n",
    "    print('h5py loading time is %.2f'%elapsed)\n",
    "    np.shape(data_this_sess)\n",
    "  \n",
    "    \n",
    "    t = time.time()\n",
    "#     data_this_sess = data_this_sess[:,voxel_inds[0], voxel_inds[1], voxel_inds[2]]\n",
    "    data_this_sess = data_this_sess\n",
    "    elapsed = time.time() - t\n",
    "    print('first indexing time  is %.2f'%elapsed)\n",
    "    print(type(data_this_sess))\n",
    "        \n",
    "    t = time.time()\n",
    "#     big_array[which_sess==se,:] = data_this_sess[trials_this_sess,:,:,:]\n",
    "    big_array[which_sess==se,:] = data_this_sess[:,voxel_inds[0], voxel_inds[1], voxel_inds[2]]\n",
    "    elapsed = time.time() - t\n",
    "    print('second indexing time  is %.2f'%elapsed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f100036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5py loading time is 9.76\n",
      "int16 -32768 32767 (750, 83, 104, 81)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "beta_data_set = h5py.File(hd5_fn, 'r')\n",
    "values = np.copy(beta_data_set['betas'])\n",
    "elapsed = time.time() - t\n",
    "print('h5py loading time is %.2f'%elapsed)\n",
    "\n",
    "print (values.dtype, np.min(values), np.max(values), values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e245c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5py loading time is 9.36\n",
      "int16 -32768 32767 (750, 83, 104, 81)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "beta_data_set = h5py.File(hd5_fn, 'r')\n",
    "values = np.array(beta_data_set['betas'])\n",
    "elapsed = time.time() - t\n",
    "print('h5py loading time is %.2f'%elapsed)\n",
    "\n",
    "print (values.dtype, np.min(values), np.max(values), values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c07f56e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "source: axis 3 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7ccf43cf4969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# nii_volume = nii_volume[:,:,:,0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnii_volume_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnii_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# np.shape(nii_volume_reshaped)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0mtranspose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'source'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'destination'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1389\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1389\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: source: axis 3 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "nsd_dir = '/lab_data/tarrlab/common/datasets/NSD/'\n",
    "subj_data_dir = os.path.join(nsd_dir,\n",
    "                 'nsddata_betas','ppdata','subj%02d'%subj,'func1pt8mm',\n",
    "                             'betas_fithrf_GLMdenoise_RR')\n",
    "se=2\n",
    "nii_fn = os.path.join(subj_data_dir,'betas_session%02d.nii.gz'%se)\n",
    "nii_volume = nib.load(nii_fn)\n",
    "np.shape(nii_volume)\n",
    "\n",
    "# nii_volume = nii_volume[:,:,:,0]\n",
    "nii_volume_reshaped = np.moveaxis(nii_volume, 3,0)\n",
    "# np.shape(nii_volume_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb9f04d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ab8e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 83, 104, 81)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsd_dir = '/lab_data/tarrlab/common/datasets/NSD/'\n",
    "subj_data_dir = os.path.join(nsd_dir,\n",
    "                 'nsddata_betas','ppdata','subj%02d'%subj,'func1pt8mm',\n",
    "                             'betas_fithrf_GLMdenoise_RR')\n",
    "se=1\n",
    "\n",
    "trial_inds = np.tile(np.arange(0,10),[2])\n",
    "which_sess = np.repeat(np.arange(1,3), 10)\n",
    "trials_per_sess=10\n",
    "\n",
    "voxel_inds = roi_voxels\n",
    "big_array = np.zeros([20,np.shape(voxel_inds)[1]])\n",
    "\n",
    "for se in np.arange(1,3):\n",
    "    \n",
    "    trials_this_sess = trial_inds[which_sess==se]\n",
    "#     print(type(trials_this_sess))\n",
    "#     print(trials_this_sess)\n",
    "    \n",
    "    t = time.time()\n",
    "\n",
    "    nii_fn = os.path.join(subj_data_dir,'betas_session%02d.nii.gz'%se)\n",
    "\n",
    "    t = time.time()\n",
    "    data_this_sess = nib.load(nii_fn)\n",
    "    elapsed = time.time() - t\n",
    "    print('nii loading time is %.2f'%elapsed)\n",
    "\n",
    "    print(np.type(data_this_sess)\n",
    "    np.shape(data_this_sess)\n",
    "  \n",
    "    \n",
    "    t = time.time()\n",
    "#     data_this_sess = data_this_sess[:,voxel_inds[0], voxel_inds[1], voxel_inds[2]]\n",
    "    data_this_sess = data_this_sess[:,:,:,trials_this_sess]\n",
    "    elapsed = time.time() - t\n",
    "    print('first indexing time  is %.2f'%elapsed)\n",
    "    print(type(data_this_sess))\n",
    "        \n",
    "    t = time.time()\n",
    "#     big_array[which_sess==se,:] = data_this_sess[trials_this_sess,:,:,:]\n",
    "    big_array[which_sess==se,:] = data_this_sess[voxel_inds[0], voxel_inds[1], voxel_inds[2],:]\n",
    "    elapsed = time.time() - t\n",
    "    print('second indexing time  is %.2f'%elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5d4d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nii loading time is 9.79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(81, 104, 83, 750)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsd_dir = '/lab_data/tarrlab/common/datasets/NSD/'\n",
    "subj_data_dir = os.path.join(nsd_dir,\n",
    "                 'nsddata_betas','ppdata','subj%02d'%subj,'func1pt8mm',\n",
    "                             'betas_fithrf_GLMdenoise_RR')\n",
    "se=2\n",
    "nii_fn = os.path.join(subj_data_dir,'betas_session%02d.nii.gz'%se)\n",
    "\n",
    "t = time.time()\n",
    "data_this_sess = nib.load(nii_fn).get_fdata()\n",
    "elapsed = time.time() - t\n",
    "print('nii loading time is %.2f'%elapsed)\n",
    "np.shape(data_this_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6256a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nsd_dataset(Dataset):\n",
    "  \n",
    "  \"\"\"\n",
    "  Custom dataset class that loads NSD data (voxels), and deals with corresponding image labels.\n",
    "  Returns a Pytorch dataset object. Can access items with <object>[indices].\n",
    "  Items are objects with fields 'data' [nTrials x nVoxels]\n",
    "  and 'subject_df' which is a pandas dataframe listing everything about those trials. \n",
    "  \"\"\" \n",
    "\n",
    "  def __init__(self, subj, voxel_inds, trials_per_sess=750, num_sess = 40,  \n",
    "               nsd_dir = '/lab_data/tarrlab/common/datasets/NSD/',\n",
    "               nsd_meta_file = '/lab_data/tarrlab/common/datasets/NSD/nsddata/experiments/nsd/nsd_stim_info_merged.pkl'):\n",
    "\n",
    "    self.subj = subj;\n",
    "    self.voxel_inds = voxel_inds;\n",
    "    self.num_vox = np.shape(voxel_inds)[1]\n",
    "   \n",
    "    self.trials_per_sess=trials_per_sess\n",
    "    self.num_sess=num_sess\n",
    "    \n",
    "    subj_data_dir = os.path.join(nsd_dir,\n",
    "                 'nsddata_betas','ppdata','subj%02d'%subj,'func1pt8mm',\n",
    "                             'betas_fithrf_GLMdenoise_RR')\n",
    "    \n",
    "    self.subj_data_dir = subj_data_dir\n",
    "    self.nsd_meta_file = nsd_meta_file\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    if hasattr(self, 'data'):\n",
    "        mylen = np.shape(self.data)[0]\n",
    "    else:\n",
    "        mylen = self.num_sess*self.trials_per_sess\n",
    "        \n",
    "    return mylen\n",
    "\n",
    "  def __getitem__(self, trial_inds):\n",
    "\n",
    "    if hasattr(trial_inds, '__len__')==True:\n",
    "        nTrials = len(trial_inds)\n",
    "    else:\n",
    "        nTrials=1\n",
    "\n",
    "    trial_inds = np.squeeze(np.array([trial_inds]))\n",
    "    \n",
    "    which_sess = np.floor(trial_inds/self.trials_per_sess)+1\n",
    "    sess2load = np.unique(which_sess)\n",
    "    data  = np.zeros([nTrials, self.num_vox])\n",
    "    \n",
    "    # looping over all the sessions we need data from\n",
    "    for se in sess2load:\n",
    "        \n",
    "        trials_this_sess = (trial_inds[which_sess==se] - (se-1)*self.trials_per_sess).astype('int')        \n",
    "#         print(trials_this_sess)\n",
    "        \n",
    "        # Load in the data for this session (slow)\n",
    "        hd5_fn = os.path.join(self.subj_data_dir,'betas_session%02d.hdf5'%se)\n",
    "#         print('loading from %s'%nii_fn)\n",
    "        \n",
    "        if len(trials_this_sess)==1:\n",
    "#             print('loading trial of interest')\n",
    "            # if just one trial in this session, can make this a bit faster by indexing rather than loading all data.\n",
    "            # otherwise will load whole file then choose trials of interest.\n",
    "            t = time.time()\n",
    "            data_this_sess = h5read\n",
    "#             with h5py.File(nii_fn, \"r\") as f:\n",
    "#                 data_this_sess = np.array(f['betas'][trials_this_sess,:,:,:])\n",
    "            elapsed = time.time() - t\n",
    "            print('h5py loading time is %.2f'%elapsed)\n",
    "        else:\n",
    "#             print('loading whole file for this sess')\n",
    "            t = time.time()\n",
    "            with h5py.File(nii_fn, \"r\") as f:\n",
    "                data_this_sess = np.array(f['betas'])\n",
    "            elapsed = time.time() - t\n",
    "#             print('h5py loading time is %.2f'%elapsed)\n",
    "\n",
    "            # grab just the trials of interest\n",
    "            data_this_sess = data_this_sess[trials_this_sess,:,:,:]\n",
    "\n",
    "        # adjusting for the 300x scaling\n",
    "        data_this_sess = data_this_sess/300\n",
    "        \n",
    "        # All NIFTI files in the prepared NSD data are in LPI ordering\n",
    "        # (the first voxel is Left, Posterior, and Inferior)\n",
    "        data_this_sess = data_this_sess[:,self.voxel_inds[0],self.voxel_inds[1],self.voxel_inds[2]]\n",
    "        \n",
    "#         print(which_sess)\n",
    "        # putting data from this session into the correct rows of our big matrix\n",
    "        data[which_sess==se, :] = data_this_sess\n",
    "        \n",
    "    assert(np.shape(data)[0]==nTrials)\n",
    "\n",
    "    df = get_subj_stim_seq(self.subj).loc[trial_inds.astype(int)]\n",
    "                            \n",
    "    item = {'data': data, 'subject_df': df}\n",
    "\n",
    "    return item "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
