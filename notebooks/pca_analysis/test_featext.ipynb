{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919c9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b82f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#device: 1\n",
      "device#: 0\n",
      "device name: GeForce GTX TITAN X\n",
      "\n",
      "torch: 1.8.1+cu111\n",
      "cuda:  11.1\n",
      "cudnn: 8005\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run the model fitting for FWRF model. \n",
    "There are a few different versions of fitting in this script, the input arguments tell which kind of fitting to do.\n",
    "\"\"\"\n",
    "\n",
    "# import basic modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "import skimage.transform\n",
    "\n",
    "# import custom modules\n",
    "code_dir = '/user_data/mmhender/imStat/code/'\n",
    "sys.path.append(code_dir)\n",
    "from feature_extraction import texture_statistics_gabor, bdcn_features, sketch_token_features\n",
    "from feature_extraction import texture_statistics_pyramid\n",
    "from utils import nsd_utils, roi_utils, default_paths\n",
    "\n",
    "from model_fitting import initialize_fitting, arg_parser, merge_features, fwrf_fit, fwrf_predict\n",
    "\n",
    "fpX = np.float32\n",
    "device = initialize_fitting.init_cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d72c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_type='sketch_tokens'\n",
    "use_pca_st_feats = True\n",
    "use_lda_st_feats = False\n",
    "subject = 1\n",
    "debug=True\n",
    "min_pct_var = 95; max_pc_to_retain = 100; \n",
    "\n",
    "do_stack=False\n",
    "subject=1\n",
    "volume_space = True\n",
    "up_to_sess = 10\n",
    "n_ori = 4\n",
    "n_sf = 4\n",
    "nonlin_fn = False\n",
    "padding_mode = 'circular';\n",
    "group_all_hl_feats = True; \\\n",
    "sample_batch_size = 50; voxel_batch_size = 100; \\\n",
    "zscore_features = True; ridge = True; \\\n",
    "shuffle_images = False; random_images = False; random_voxel_data = False; \\\n",
    "do_fitting = True; do_val = True; do_varpart = True; date_str = None;\n",
    "shuff_rnd_seed = 0; \n",
    "do_pca_pyr_hl = False;\n",
    "map_ind = -1; \\\n",
    "n_prf_sd_out = 2; mult_patch_by_prf = True; \\\n",
    "downsample_factor = 1.0; do_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1792e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stamp: Oct-04-2021_2223_03\n",
      "\n",
      "Will save final output file to /user_data/mmhender/imStat/model_fits/S01/sketch_tokens_pca/Oct-04-2021_2223_03_DEBUG/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def save_all(fn2save, fitting_type):\n",
    "    \"\"\"\n",
    "    Define all the important parameters that have to be saved\n",
    "    \"\"\"\n",
    "    dict2save = {\n",
    "    'subject': subject,\n",
    "    'volume_space': volume_space,\n",
    "    'fitting_type': fitting_type,\n",
    "    'voxel_mask': voxel_mask,\n",
    "    'brain_nii_shape': brain_nii_shape,\n",
    "    'image_order': image_order,\n",
    "    'voxel_index': voxel_index,\n",
    "    'voxel_roi': voxel_roi,\n",
    "    'voxel_ncsnr': voxel_ncsnr, \n",
    "    'aperture': aperture,\n",
    "    'aperture_rf_range': aperture_rf_range,\n",
    "    'models': models,        \n",
    "    'n_prf_sd_out': n_prf_sd_out,\n",
    "    'best_losses': best_losses,           \n",
    "    'best_lambdas': best_lambdas,\n",
    "    'best_params': best_params,       \n",
    "    'lambdas': lambdas, \n",
    "    'val_cc': val_cc,\n",
    "    'val_r2': val_r2,    \n",
    "    'partial_masks': partial_masks, \n",
    "    'partial_version_names': partial_version_names,\n",
    "    'stack_result': stack_result,\n",
    "    'stack_result_lo': stack_result_lo,\n",
    "    'partial_models_used_for_stack': partial_models_used_for_stack,\n",
    "    'train_r2': train_r2, \n",
    "    'train_cc': train_cc,\n",
    "    'zscore_features': zscore_features,        \n",
    "    'ridge': ridge,\n",
    "    'debug': debug,\n",
    "    'up_to_sess': up_to_sess,\n",
    "    'shuff_rnd_seed': shuff_rnd_seed\n",
    "    }\n",
    "    # Might be some more things to save, depending what kind of fitting this is\n",
    "    if 'bdcn' in fitting_type:\n",
    "        dict2save.update({\n",
    "        'pc': pc,\n",
    "        'min_pct_var': min_pct_var,\n",
    "        'max_pc_to_retain': max_pc_to_retain,           \n",
    "        'mult_patch_by_prf': mult_patch_by_prf,\n",
    "        'do_nms': do_nms, \n",
    "        'downsample_factor': downsample_factor,\n",
    "        })\n",
    "\n",
    "    if 'sketch_tokens' in fitting_type:\n",
    "        dict2save.update({\n",
    "        'min_pct_var': min_pct_var,\n",
    "        'max_pc_to_retain': max_pc_to_retain,           \n",
    "        'use_pca_st_feats': use_pca_st_feats, \n",
    "        'use_lda_st_feats': use_lda_st_feats,\n",
    "        })\n",
    "\n",
    "    if 'pyramid' in fitting_type:\n",
    "        dict2save.update({\n",
    "        'pc': pc,\n",
    "        'min_pct_var': min_pct_var,\n",
    "        'max_pc_to_retain': max_pc_to_retain,   \n",
    "        'feature_info':feature_info,\n",
    "        'group_all_hl_feats': group_all_hl_feats,\n",
    "        })\n",
    "\n",
    "    if 'gabor' in fitting_type:\n",
    "        dict2save.update({\n",
    "        'feature_table_simple': _gabor_ext_simple.feature_table,\n",
    "        'filter_pars_simple': _gabor_ext_simple.gabor_filter_pars,\n",
    "        'orient_filters_simple': _gabor_ext_simple.filter_stack,  \n",
    "        'feature_table_complex': _gabor_ext_complex.feature_table,\n",
    "        'filter_pars_complex': _gabor_ext_complex.gabor_filter_pars,\n",
    "        'orient_filters_complex': _gabor_ext_complex.filter_stack, \n",
    "        'feature_types_exclude': feature_types_exclude,\n",
    "        'feature_info':feature_info,\n",
    "        'nonlin_fn': nonlin_fn,\n",
    "        'padding_mode': padding_mode,\n",
    "        'autocorr_output_pix': autocorr_output_pix,\n",
    "        'group_all_hl_feats': group_all_hl_feats,\n",
    "        })\n",
    "\n",
    "    print('\\nSaving to %s\\n'%fn2save)\n",
    "    torch.save(dict2save, fn2save, pickle_protocol=4)\n",
    "\n",
    "if date_str==0:\n",
    "    date_str = None\n",
    "\n",
    "if do_fitting==False and date_str is None:\n",
    "    raise ValueError('if you want to start midway through the process (--do_fitting=False), then specify the date when training result was saved (--date_str).')\n",
    "\n",
    "if do_fitting==True and date_str is not None:\n",
    "    raise ValueError('if you want to do fitting from scratch (--do_fitting=True), specify --date_str=None (rather than entering a date)')\n",
    "\n",
    "if do_fitting==False and (do_pca_pyr_hl or do_pca_st or do_pca_bdcn):\n",
    "    raise ValueError('Cannot start midway through the process (--do_fitting=False) when doing pca, because the pca weight matrix is not saved in between trn/val.')\n",
    "\n",
    "if 'pyramid' in fitting_type:\n",
    "    model_name = initialize_fitting.get_pyramid_model_name(ridge, n_ori, n_sf, do_pca_hl = do_pca_pyr_hl)\n",
    "#         feature_types_exclude = []\n",
    "    feature_types_exclude = ['pixel']\n",
    "    name1 = 'pyramid_texture'\n",
    "\n",
    "elif 'gabor_texture' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_texture_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = []\n",
    "    name1 = 'gabor_texture'\n",
    "\n",
    "elif 'gabor_solo' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_solo_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = ['pixel', 'simple_feature_means', 'autocorrs', 'crosscorrs']\n",
    "    name1 = 'gabor_solo'\n",
    "\n",
    "elif 'bdcn' in fitting_type:\n",
    "    model_name = initialize_fitting.get_bdcn_model_name(do_pca_bdcn, map_ind)   \n",
    "    name1 = 'bdcn'\n",
    "\n",
    "elif 'sketch_tokens' in fitting_type:\n",
    "    if use_pca_st_feats:\n",
    "        # not allowing both of these to be true\n",
    "        use_lda_st_feats = False\n",
    "    model_name = initialize_fitting.get_sketch_tokens_model_name(use_pca_st_feats, use_lda_st_feats)   \n",
    "    name1 = 'sketch_tokens'\n",
    "\n",
    "else:\n",
    "    raise ValueError('your string for fitting_type was not recognized')\n",
    "\n",
    "if 'plus_sketch_tokens' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_sketch_tokens_model_name(use_pca_st_feats, use_lda_st_feats)   \n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "elif 'plus_bdcn' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_bdcn_model_name(do_pca_bdcn, map_ind)\n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "\n",
    "if do_stack:\n",
    "    model_name += '_stacked'\n",
    "\n",
    "output_dir, fn2save = initialize_fitting.get_save_path(subject, volume_space, model_name, shuffle_images, random_images, random_voxel_data, debug, date_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b216267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Volume space: ROI defs are located at: /lab_data/tarrlab/common/datasets/NSD/nsddata/ppdata/subj01/func1pt8mm/roi\n",
      "\n",
      "3794 voxels of overlap between kastner and prf definitions, using prf defs\n",
      "unique values in retino labels:\n",
      "[-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18. 19. 20. 21. 22. 23. 24. 25.]\n",
      "0 voxels of overlap between face and place definitions, using place defs\n",
      "unique values in categ labels:\n",
      "[-1.  0. 26. 27. 28. 30. 31. 32. 33.]\n",
      "1535 voxels are defined (differently) in both retinotopic areas and category areas\n",
      "\n",
      "14913 voxels are defined across all areas, and will be used for analysis\n",
      "\n",
      "Loading numerical label/name mappings for all ROIs:\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'VO1', 'VO2', 'PHC1', 'PHC2', 'TO2', 'TO1', 'LO2', 'LO1', 'V3B', 'V3A', 'IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'SPL1', 'FEF']\n",
      "[1, 2, 3, 4, 5]\n",
      "['OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces']\n",
      "[1, 2, 3]\n",
      "['OPA', 'PPA', 'RSC']\n",
      "\n",
      "Sizes of all defined ROIs in this subject:\n",
      "Region V1 has 2392 voxels. Includes subregions:\n",
      "['V1v', 'V1d']\n",
      "Region V2 has 2096 voxels. Includes subregions:\n",
      "['V2v', 'V2d']\n",
      "Region V3 has 1674 voxels. Includes subregions:\n",
      "['V3v', 'V3d']\n",
      "Region hV4 has 721 voxels. Includes subregions:\n",
      "['hV4']\n",
      "Region VO1-2 has 482 voxels. Includes subregions:\n",
      "['VO1', 'VO2']\n",
      "Region PHC1-2 has 382 voxels. Includes subregions:\n",
      "['PHC1', 'PHC2']\n",
      "Region LO1-2 has 488 voxels. Includes subregions:\n",
      "['LO2', 'LO1']\n",
      "Region TO1-2 has 339 voxels. Includes subregions:\n",
      "['TO2', 'TO1']\n",
      "Region V3ab has 965 voxels. Includes subregions:\n",
      "['V3B', 'V3A']\n",
      "Region IPS0-5 has 2155 voxels. Includes subregions:\n",
      "['IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5']\n",
      "Region SPL1 has 164 voxels. Includes subregions:\n",
      "['SPL1']\n",
      "Region FEF has 72 voxels. Includes subregions:\n",
      "['FEF']\n",
      "\n",
      "\n",
      "Region OFA has 355 voxels.\n",
      "Region FFA-1 has 484 voxels.\n",
      "Region FFA-2 has 310 voxels.\n",
      "Region mTL-faces has 0 voxels.\n",
      "Region aTL-faces has 159 voxels.\n",
      "Region OPA has 1611 voxels.\n",
      "Region PPA has 1033 voxels.\n",
      "Region RSC has 566 voxels.\n",
      "\n",
      "Loading images for subject 1\n",
      "\n",
      "image data size: (10000, 3, 240, 240) , dtype: uint8 , value range: 0 255\n",
      "Loading data for sessions:\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "Data is located in: /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR...\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session01.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.237, sigma = 1.391\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session02.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.110, sigma = 1.286\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session03.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.299, sigma = 1.365\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session04.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.055, sigma = 1.259\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session05.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.175, sigma = 1.421\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session06.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.312, sigma = 1.477\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session07.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.187, sigma = 1.486\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session08.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.212, sigma = 1.472\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session09.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.260, sigma = 1.503\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session10.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.176, sigma = 1.507\n",
      "\n",
      "Size of full data set [nTrials x nVoxels] is:\n",
      "(7500, 14913)\n",
      "\n",
      "Possible lambda values are:\n",
      "[1.0000000e+00 4.2169652e+00 1.7782795e+01 7.4989418e+01 3.1622775e+02\n",
      " 1.3335215e+03 5.6234131e+03 2.3713736e+04 1.0000000e+05]\n",
      "most extreme RF positions:\n",
      "[-0.55 -0.55  0.04]\n",
      "[0.55       0.55       0.40000001]\n"
     ]
    }
   ],
   "source": [
    "# decide what voxels to use  \n",
    "voxel_mask, voxel_index, voxel_roi, voxel_ncsnr, brain_nii_shape = roi_utils.get_voxel_roi_info(subject, volume_space)\n",
    "\n",
    "sessions = np.arange(0,up_to_sess)\n",
    "zscore_betas_within_sess = True\n",
    "# get all data and corresponding images, in two splits. always fixed set that gets left out\n",
    "trn_stim_data, trn_voxel_data, val_stim_data, val_voxel_data, \\\n",
    "        image_order, image_order_trn, image_order_val = nsd_utils.get_data_splits(subject, sessions=sessions, \\\n",
    "                                                             voxel_mask=voxel_mask, volume_space=volume_space, \\\n",
    "                                                              zscore_betas_within_sess=zscore_betas_within_sess, \\\n",
    "                                                              shuffle_images=shuffle_images, random_images=random_images, \\\n",
    "                                                                                         random_voxel_data=random_voxel_data)\n",
    "\n",
    "\n",
    "if 'gabor' in fitting_type or 'sketch_tokens' in fitting_type or 'pyramid' in fitting_type:\n",
    "    # For this model, the features are pre-computed, so we will just load them rather than passing in images.\n",
    "    # Going to pass the image indices (into 10,000 dim array) instead of images to fitting and val functions, \n",
    "    # which will tell which features to load.\n",
    "    trn_stim_data = image_order_trn\n",
    "    val_stim_data = image_order_val\n",
    "\n",
    "# More params for fitting\n",
    "holdout_size, lambdas = initialize_fitting.get_fitting_pars(trn_voxel_data, zscore_features, ridge=ridge)\n",
    "# Params for the spatial aspect of the model (possible pRFs)\n",
    "aperture_rf_range = 1.1\n",
    "aperture, models = initialize_fitting.get_prf_models(aperture_rf_range=aperture_rf_range)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43a6b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "_feature_extractor = sketch_token_features.sketch_token_feature_extractor(subject=subject, device=device,\\\n",
    "                 use_pca_feats = use_pca_st_feats, min_pct_var = min_pct_var, max_pc_to_retain = max_pc_to_retain, \\\n",
    "                 use_lda_feats = use_lda_st_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95690d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "flipping the models upside down to start w biggest pRFs\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "trn_size = 6122 (90.0%)\n",
      "Seeding random number generator: seed is 232204\n",
      "Initializing for fitting\n",
      "Clearing features from memory\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Loading pre-computed features from /user_data/mmhender/features/sketch_tokens/PCA/S1_PCA.npy\n",
      "Size of features array for first prf model with this image set is:\n",
      "(6803, 28)\n",
      "Final size of feature matrix is:\n",
      "(6803, 28)\n",
      "\n",
      "Fitting version 0 of 1: full_model, \n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Getting features for prf 1: [x,y,sigma] is [-0.49 -0.55 0.0400]\n",
      "Final size of feature matrix is:\n",
      "(6803, 24)\n",
      "\n",
      "Fitting version 0 of 1: full_model, \n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "---------------------------------------\n",
      "total time = 8.305824s\n",
      "total throughput = 0.000557s/voxel\n",
      "voxel throughput = 0.000167s/voxel\n",
      "setup throughput = 0.006646s/model\n",
      "Clearing features from memory\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print('\\nStarting training...\\n')\n",
    "if shuff_rnd_seed==0:\n",
    "    shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))       \n",
    "if debug:\n",
    "    print('flipping the models upside down to start w biggest pRFs')\n",
    "    models = np.flipud(models)\n",
    "\n",
    "# add an intercept\n",
    "add_bias=True\n",
    "# determines whether to shuffle before separating the nested heldout data for lambda and param selection. \n",
    "# always using true.\n",
    "shuffle=True \n",
    "best_losses, best_lambdas, best_params, best_train_holdout_preds, holdout_trial_order = \\\n",
    "                    fwrf_fit.fit_fwrf_model(trn_stim_data, trn_voxel_data, \\\n",
    "                                               _feature_extractor, models, \\\n",
    "                                               lambdas, zscore=zscore_features, add_bias=add_bias, \\\n",
    "                                               voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, \\\n",
    "                                               shuffle=shuffle, shuff_rnd_seed=shuff_rnd_seed, device=device, \\\n",
    "                                               dtype=fpX, debug=debug)\n",
    "trn_holdout_voxel_data_pred = best_train_holdout_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc50acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'plus' in fitting_type:\n",
    "    pc = []\n",
    "    for m in _feature_extractor.modules:           \n",
    "        if hasattr(m, 'pct_var_expl'):\n",
    "            pcm = [m.pct_var_expl, m.min_pct_var,  m.n_comp_needed]                  \n",
    "        else:\n",
    "            pcm = None\n",
    "        pc.append(pcm)\n",
    "else:\n",
    "    m = _feature_extractor\n",
    "    if hasattr(m, 'pct_var_expl'):\n",
    "        pc = [m.pct_var_expl, m.min_pct_var,  m.n_comp_needed]\n",
    "    else:\n",
    "        pc = None\n",
    "\n",
    "partial_masks, partial_version_names = _feature_extractor.get_partial_versions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9836a26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving to /user_data/mmhender/imStat/model_fits/S01/sketch_tokens_pca/Oct-04-2021_2223_03_DEBUG/all_fit_params\n",
      "\n",
      "\n",
      "Saved training results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sys.stdout.flush()\n",
    "val_cc=None\n",
    "val_r2=None\n",
    "train_cc=None\n",
    "train_r2=None\n",
    "stack_result=None\n",
    "stack_result_lo=None\n",
    "partial_models_used_for_stack=None\n",
    "\n",
    "save_all(fn2save, fitting_type)   \n",
    "print('\\nSaved training results\\n')        \n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d503c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to start validation\n",
      "Clearing features from memory\n",
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Loading pre-computed features from /user_data/mmhender/features/sketch_tokens/PCA/S1_PCA.npy\n",
      "Size of features array for first prf model with this image set is:\n",
      "(697, 28)\n",
      "Final size of feature matrix is:\n",
      "(697, 28)\n",
      "Getting features for prf 1: [x,y,sigma] is [-0.49 -0.55 0.0400]\n",
      "Final size of feature matrix is:\n",
      "(697, 24)\n",
      "Clearing features from memory\n",
      "Getting predictions for voxels [0-99] of 14913\n",
      "\n",
      "Evaluating version 0 of 1: full_model\n",
      "Includes 100 features\n",
      "number of zeros:\n",
      "76\n",
      "size of weights is:\n",
      "torch.Size([100, 100])\n",
      "Getting predictions for voxels [100-199] of 14913\n",
      "\n",
      "Evaluating version 0 of 1: full_model\n",
      "Includes 100 features\n",
      "number of zeros:\n",
      "72\n",
      "size of weights is:\n",
      "torch.Size([100, 100])\n",
      "Getting predictions for voxels [200-299] of 14913\n",
      "\n",
      "Saving to /user_data/mmhender/imStat/model_fits/S01/sketch_tokens_pca/Oct-04-2021_2223_03_DEBUG/all_fit_params\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print('about to start validation')\n",
    "sys.stdout.flush()\n",
    "\n",
    "val_cc, val_r2, val_voxel_data_pred  = fwrf_predict.validate_fwrf_model(best_params, models, val_voxel_data, \\\n",
    "                                                                    val_stim_data, _feature_extractor, \\\n",
    "                       sample_batch_size=sample_batch_size, voxel_batch_size=voxel_batch_size, debug=debug, dtype=fpX)\n",
    "\n",
    "save_all(fn2save, fitting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54c8c44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
