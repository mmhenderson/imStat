{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020379e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#device: 0\n",
      "Found device:\n",
      "cpu:0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "import skimage.io as skio\n",
    "from skimage.util.shape import view_as_windows\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats  \n",
    "import scipy.stats\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "import torch\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import warnings\n",
    "import tqdm\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import argparse\n",
    "\n",
    "from utils import default_paths, nsd_utils, texture_utils\n",
    "from model_fitting import initialize_fitting\n",
    "from feature_extraction import fwrf_features\n",
    "\n",
    "try:\n",
    "    device = initialize_fitting.init_cuda()\n",
    "except:\n",
    "    device = 'cpu:0'\n",
    "print('Found device:')\n",
    "print(device)\n",
    "\n",
    "class bent_gabor_feature_bank():\n",
    "    \n",
    "    def __init__(self, freq_values=None, bend_values=None, orient_values=None, \\\n",
    "                 image_size=128, device=None):\n",
    "        \n",
    "        self.image_size = image_size;\n",
    "        if device is None:\n",
    "            self.device = 'cpu:0'\n",
    "        else:\n",
    "            self.device = device\n",
    " \n",
    "        self.__set_kernel_params__(freq_values, bend_values, orient_values)\n",
    "        self.__generate_kernels__()\n",
    "        \n",
    "    def __set_kernel_params__(self, freq_values, bend_values, orient_values):\n",
    "        \n",
    "        \"\"\"\n",
    "        Set some default params for the banana kernels.\n",
    "        sigmaXbend:  sigma for the bent gaussian in x-direction\n",
    "        sigmaYbend:  sigma for the bent gaussian in y-direction\n",
    "        xA_shift:    center shift in x direction\n",
    "        yA_shift:    center shift in y direction   \n",
    "        \n",
    "        freq_values: freq of filters, cyc/image\n",
    "        orient_values: orientation of filters, 0-2pi\n",
    "        bend_values: control bending of filters\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sigmaXbend = 2;\n",
    "#         self.sigmaXbend = 3;\n",
    "        self.sigmaYbend = 6;\n",
    "        self.kernel_size = self.image_size\n",
    "        self.xA_shift   = 0\n",
    "        self.yA_shift   = 0\n",
    "        \n",
    "        if freq_values is None:\n",
    "            self.freq_values = [64, 32, 16, 8]\n",
    "        else:\n",
    "            self.freq_values = freq_values\n",
    "            \n",
    "        nyquist = 0.5*self.kernel_size\n",
    "        if any(np.array(self.freq_values)>nyquist):\n",
    "            raise ValueError('for image of size %d x %d, must have freqs < %.2f'%\\\n",
    "                            (self.kernel_size, self.kernel_size, nyquist))\n",
    "        self.kA = np.array(self.freq_values)*2*np.pi / self.kernel_size\n",
    "        self.scale_values = np.log(2*np.pi/self.kA)/np.log(np.sqrt(2))\n",
    "        \n",
    "        if orient_values is None:\n",
    "            self.orient_values = np.linspace(0,2*np.pi, 9)[0:8]\n",
    "        else:\n",
    "            self.orient_values = orient_values\n",
    "        if bend_values is None:\n",
    "            self.bend_values = [0, 0.02,0.07,0.10,0.18,0.45]\n",
    "        else:\n",
    "            self.bend_values = bend_values\n",
    "            \n",
    "        print('freq values')\n",
    "        print(self.freq_values)\n",
    "        print('scale values')\n",
    "        print(self.scale_values)\n",
    "        print('bend values')\n",
    "        print(self.bend_values)\n",
    "        print('orient values')\n",
    "        print(self.orient_values)\n",
    "\n",
    "    def __make_bananakernel__(self, kA, bA, alphaA, is_curved):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generate banana wavelet kernels.  The kernels\n",
    "        can be used to filter a image to quantify curvatures.\n",
    "\n",
    "        kA:          scale param, length of the wave vector K\n",
    "                     kA =  2*np.pi/((np.sqrt(2))**scale)\n",
    "                     filter frequency: (cycle/object) = kA*kernel_size / (2*pi)\n",
    "        bA:          bending value b (arbitrary, roughly between 0-0.5)\n",
    "        alphaA:      direction of the wave vector (i.e. orientation in rad)\n",
    "        is_curved:   Are we making a curved gabor? If false, making a sharp angle detector.\n",
    "                     Note if bA==0, then these are the same. \n",
    "\n",
    "        return SpaceKernel, FreqKernel\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        assert not (isinstance(bA, complex))\n",
    "       \n",
    "        kernel_size = self.kernel_size\n",
    "        if kernel_size%2 !=0:\n",
    "            kernel_size = kernel_size + 1\n",
    "        [xA, yA] = np.meshgrid(np.arange(-kernel_size/2, kernel_size/2,1),np.arange(-kernel_size/2, kernel_size/2,1)) \n",
    "        xA = xA - self.xA_shift\n",
    "        yA = yA - self.yA_shift\n",
    "\n",
    "        xRotL = np.cos(alphaA)*xA + np.sin(alphaA)*yA \n",
    "        yRotL = np.cos(alphaA)*yA - np.sin(alphaA)*xA\n",
    "\n",
    "        if is_curved:\n",
    "            # make a curved \"banana\" gabor.\n",
    "            scale = np.log(2*np.pi/kA)/np.log(np.sqrt(2))\n",
    "            xRotBendL = xRotL + bA/scale * (yRotL)**2\n",
    "        else:\n",
    "            # otherwise making a sharp angle detector, use abs instead of squaring.\n",
    "            # adjusting the constant here to make the bA values ~similar across curved/angle filters.\n",
    "            xRotBendL = xRotL + bA*4 * np.abs(yRotL)\n",
    "            \n",
    "        yRotBendL = yRotL\n",
    "\n",
    "        \"\"\"make the DC free\"\"\" \n",
    "        tmpgaussPartA = np.exp(-0.5*(kA)**2*((xRotBendL/self.sigmaXbend)**2 + (yRotBendL/(self.sigmaYbend))**2))\n",
    "        tmprealteilL  = 1*tmpgaussPartA*(np.cos(kA*xRotBendL) - 0)\n",
    "        tmpimagteilL  = 1*tmpgaussPartA*(np.sin(kA*xRotBendL) - 0)\n",
    "\n",
    "        numeratorRealL = np.sum(tmprealteilL)\n",
    "        numeratorImagL = np.sum(tmpimagteilL)\n",
    "        denominatorL   = np.sum(tmpgaussPartA)\n",
    "\n",
    "        DCValueAnalysis = np.exp(-0.5 * self.sigmaXbend * self.sigmaXbend)\n",
    "        if denominatorL==0:\n",
    "            DCPartRealA = DCValueAnalysis\n",
    "            DCPartImagA = 0\n",
    "        else:    \n",
    "            DCPartRealA = numeratorRealL/denominatorL\n",
    "            DCPartImagA = numeratorImagL/denominatorL\n",
    "            if DCPartRealA < DCValueAnalysis:\n",
    "                DCPartRealA = DCValueAnalysis\n",
    "                DCPartImagA = 0\n",
    "\n",
    "        \"\"\"generate a space kernel\"\"\" \n",
    "        preFactorA = kA**2\n",
    "        gaussPartA = np.exp(-0.5*(kA)**2*((xRotBendL/self.sigmaXbend)**2 + (yRotBendL/(self.sigmaYbend))**2))\n",
    "        realteilL  = preFactorA*gaussPartA*(np.cos(kA*xRotBendL) - DCPartRealA)\n",
    "        imagteilL  = preFactorA*gaussPartA*(np.sin(kA*xRotBendL) - DCPartImagA)\n",
    "\n",
    "        \"\"\"normalize the kernel\"\"\"  \n",
    "        normRealL   = np.sqrt(np.sum(realteilL**2))\n",
    "        normImagL   = np.sqrt(np.sum(imagteilL**2))\n",
    "        normFactorL = kA**2\n",
    "\n",
    "        total_std = normRealL + normImagL\n",
    "        if total_std == 0:\n",
    "            total_std = 10**20\n",
    "        norm_realteilL = realteilL*normFactorL/(0.5*total_std)\n",
    "        norm_imagteilL = imagteilL*normFactorL/(0.5*total_std)\n",
    "        \n",
    "        space_kernel = norm_realteilL + norm_imagteilL*1j\n",
    "        freq_kernel = np.fft.ifft2(space_kernel)\n",
    "        \n",
    "        return space_kernel, freq_kernel\n",
    " \n",
    "    def __generate_kernels__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Make the bank of filters.\n",
    "        \"\"\"\n",
    "        \n",
    "        n_scales = len(self.scale_values)\n",
    "        n_orients = len(self.orient_values)\n",
    "        n_bends = len(self.bend_values)\n",
    "        \n",
    "        curv_freq_kernels,rect_freq_kernels,lin_freq_kernels, \\\n",
    "            curv_space,rect_space,lin_space = [],[],[],[],[],[]\n",
    "        \n",
    "        curv_kernel_pars = np.zeros((n_scales*(n_bends-1)*n_orients, 4))\n",
    "        rect_kernel_pars = np.zeros((n_scales*(n_bends-1)*n_orients, 4))\n",
    "        lin_kernel_pars = np.zeros((n_scales*n_orients, 4))\n",
    "        \n",
    "        ci=-1; ri=-1; li=-1\n",
    "            \n",
    "        for is_curved in [True, False]:\n",
    "\n",
    "            for kA, bA, alphaA in itertools.product(self.kA, self.bend_values, self.orient_values):\n",
    "\n",
    "                space_kernel, freq_kernel = self.__make_bananakernel__(kA, bA, alphaA, is_curved)\n",
    "\n",
    "                if bA == 0:\n",
    "                    if not is_curved:\n",
    "                        # the linear kernels each get defined twice (once with is_curv=True and False)\n",
    "                        # only counting one occurence of each.\n",
    "                        lin_freq_kernels.append(freq_kernel)\n",
    "                        lin_space.append(space_kernel.real) \n",
    "                        li+=1\n",
    "                        lin_kernel_pars[li,:] = [kA, bA, alphaA, is_curved]\n",
    "                    else:\n",
    "                        continue\n",
    "                elif is_curved:\n",
    "                    # this is a curved banana filter\n",
    "                    curv_freq_kernels.append(freq_kernel)\n",
    "                    curv_space.append(space_kernel.real)\n",
    "                    ci+=1\n",
    "                    curv_kernel_pars[ci,:] = [kA, bA, alphaA, is_curved]\n",
    "                else:\n",
    "                    # this is a second-order rectilinear filter\n",
    "                    rect_freq_kernels.append(freq_kernel)\n",
    "                    rect_space.append(space_kernel.real)\n",
    "                    ri+=1\n",
    "                    rect_kernel_pars[ri,:] = [kA, bA, alphaA, is_curved]\n",
    "                    \n",
    "\n",
    "        self.kernels = {'curv_freq':curv_freq_kernels, 'curv_space':curv_space,\n",
    "                        'rect_freq':rect_freq_kernels, 'rect_space':rect_space, \n",
    "                        'lin_freq':lin_freq_kernels, 'lin_space':lin_space}\n",
    "        self.rect_kernel_pars = rect_kernel_pars\n",
    "        self.curv_kernel_pars = curv_kernel_pars\n",
    "        self.lin_kernel_pars = lin_kernel_pars\n",
    "        self.n_rect_filters = self.rect_kernel_pars.shape[0]\n",
    "        self.n_curv_filters = self.curv_kernel_pars.shape[0]      \n",
    "        self.n_lin_filters = self.lin_kernel_pars.shape[0]\n",
    "        \n",
    "    def plot_kernel_bends(self, ori_ind=0, scale_ind=0):\n",
    "\n",
    "        rect_kernel_pars = self.rect_kernel_pars\n",
    "        curv_kernel_pars = self.curv_kernel_pars\n",
    "        lin_kernel_pars = self.lin_kernel_pars\n",
    "        rect_spat_kernel_list = self.kernels['rect_space']\n",
    "        curv_spat_kernel_list = self.kernels['curv_space']\n",
    "        lin_spat_kernel_list = self.kernels['lin_space']\n",
    "\n",
    "        plt.figure(figsize=(20,12))\n",
    "        npx = 3;\n",
    "        npy = len(self.bend_values)\n",
    "\n",
    "        ori = self.orient_values[ori_ind]\n",
    "        sc = self.kA[scale_ind]\n",
    "\n",
    "        kk2plot = np.where((rect_kernel_pars[:,2]==ori) & (rect_kernel_pars[:,0]==sc))[0]\n",
    "        for ki, kk in enumerate(kk2plot):\n",
    "            plt.subplot(npx, npy, ki+1)\n",
    "            plt.pcolormesh(rect_spat_kernel_list[kk])\n",
    "            plt.axis('square')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.axis('off')\n",
    "            plt.title('bend=%.2f'%(rect_kernel_pars[kk,1]))\n",
    "\n",
    "        kk2plot = np.where((curv_kernel_pars[:,2]==ori) & (curv_kernel_pars[:,0]==sc))[0]\n",
    "        for ki, kk in enumerate(kk2plot):\n",
    "            plt.subplot(npx, npy,ki+npy+1)\n",
    "            plt.pcolormesh(curv_spat_kernel_list[kk])\n",
    "            plt.axis('square')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.axis('off')\n",
    "            plt.title('bend=%.2f'%(curv_kernel_pars[kk,1]))\n",
    "\n",
    "        kk2plot = np.where((lin_kernel_pars[:,2]==ori) & (lin_kernel_pars[:,0]==sc))[0]\n",
    "        for ki, kk in enumerate(kk2plot):\n",
    "            plt.subplot(npx, npy ,ki+npy*2+1)\n",
    "            plt.pcolormesh(lin_spat_kernel_list[kk])\n",
    "            plt.axis('square')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.axis('off')\n",
    "            plt.title('bend=%.2f'%(lin_kernel_pars[kk,1]))\n",
    "\n",
    "        plt.suptitle('ori=%.2f rad, freq=%.2f cyc/im'%(ori, self.freq_values[scale_ind]))\n",
    "        \n",
    "    def filter_image_batch(self, image_batch, which_kernels='curv'):\n",
    "        \n",
    "        \n",
    "        if which_kernels=='curv':\n",
    "            kernel_list = self.kernels['curv_freq']\n",
    "        elif which_kernels=='rect':\n",
    "            kernel_list = self.kernels['rect_freq']\n",
    "        elif which_kernels=='linear':\n",
    "            kernel_list = self.kernels['lin_freq']\n",
    "        else:\n",
    "            raise ValueError('which_kernels must be one of [curv, rect, linear]')\n",
    "\n",
    "        \"\"\"image x, image y, kernel dimension, all images (4D array)\"\"\"\n",
    "        all_kernels = np.dstack(kernel_list)\n",
    "        \n",
    "        \"\"\"calculate kernel norm for normalization\"\"\"\n",
    "        all_kernels_power =  np.einsum('ijk,ijk->k',np.abs(all_kernels),np.abs(all_kernels))\n",
    "        all_kernels_power =  np.sqrt(all_kernels_power)\n",
    "\n",
    "        \"\"\"stack fft image list to a 3d array\"\"\"\n",
    "        image_batch_fft = np.fft.fft2(image_batch, axes=(0,1))\n",
    "        \n",
    "        all_conved_images = np.abs(np.fft.ifft2(image_batch_fft[:,:,np.newaxis,:]*all_kernels[:,:,:,np.newaxis],axes=(0,1)))\n",
    "        all_conved_images = np.power(all_conved_images,1/2) ## power correction\n",
    "        all_conved_images = all_conved_images/all_kernels_power[np.newaxis, np.newaxis,:,np.newaxis]\n",
    "    \n",
    "        return np.fft.fftshift(all_conved_images, axes=(0,1))\n",
    "    \n",
    "    \n",
    "    def filter_image_batch_pytorch(self, image_batch, which_kernels='curv', to_numpy=True):\n",
    "\n",
    "        if which_kernels=='curv':\n",
    "            kernel_list = self.kernels['curv_freq']\n",
    "        elif which_kernels=='rect':\n",
    "            kernel_list = self.kernels['rect_freq']\n",
    "        elif which_kernels=='linear':\n",
    "            kernel_list = self.kernels['lin_freq']\n",
    "        elif which_kernels=='all':\n",
    "            kernel_list = self.kernels['curv_freq']+self.kernels['rect_freq']+self.kernels['lin_freq']\n",
    "        else:\n",
    "            raise ValueError('which_kernels must be one of [curv, rect, linear, all]')\n",
    "\n",
    "        # stack all the filters together, [self.kernel_size, self.kernel_size, n_filters]\n",
    "        # and send to specified device.\n",
    "        all_kernels = np.dstack(kernel_list)\n",
    "        all_kernels_tensor = torch.complex(torch.Tensor(np.real(all_kernels)), \\\n",
    "                                           torch.Tensor(np.imag(all_kernels)))\n",
    "        \n",
    "        # Compute power of each kernel, will use to normalize the convolution result.\n",
    "        all_kernels_power =  torch.sum(torch.sum(torch.pow(torch.abs(all_kernels_tensor), 2), \\\n",
    "                                                 axis=0), axis=0)\n",
    "        all_kernels_power =  torch.sqrt(all_kernels_power)\n",
    "\n",
    "        # send image batch to device [self.image_size, self.image_size, n_images]\n",
    "        image_batch_tensor = torch.Tensor(image_batch).to(self.device)\n",
    "        # get frequency domain representation of images\n",
    "        image_batch_fft = torch.fft.fftn(image_batch_tensor, dim=(0,1))\n",
    "\n",
    "        # apply the filters by multiplying all at once\n",
    "        mult = image_batch_fft.view([self.image_size, self.image_size,1,-1]) * \\\n",
    "                all_kernels_tensor.view([self.image_size, self.image_size,-1,1])\n",
    "        # back to spatial domain \n",
    "        all_conved_images = torch.abs(torch.fft.ifftn(mult,dim=(0,1)))\n",
    "        # power correction\n",
    "        all_conved_images = torch.pow(all_conved_images,1/2) \n",
    "        all_conved_images = all_conved_images/ \\\n",
    "                    all_kernels_power.view([1,1,all_kernels_power.shape[0],1])\n",
    "        \n",
    "        # shift back to original spatial configuration\n",
    "        all_conved_images = torch.fft.fftshift(all_conved_images, dim=(0,1))\n",
    "\n",
    "        if to_numpy:\n",
    "            all_conved_images = all_conved_images.detach().cpu().numpy()\n",
    "            \n",
    "        return all_conved_images\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "daff6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from model_fitting import initialize_fitting \n",
    "from utils import texture_utils\n",
    "\n",
    "\n",
    "prf_models = initialize_fitting.get_prf_models(5)\n",
    "n_prfs = prf_models.shape[0]\n",
    "\n",
    "mm = 0\n",
    "image_size=[240,240]\n",
    "\n",
    "bboxes = np.array([ texture_utils.get_bbox_from_prf(prf_models[mm,:], \\\n",
    "                                   image_size, n_prf_sd_out=2, \\\n",
    "                                   min_pix=None, verbose=False, \\\n",
    "                                   force_square=True) \\\n",
    "                for mm in range(n_prfs) ])\n",
    "\n",
    "bboxes_unique, unique_inds = np.unique(bboxes, axis=0, return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f970c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_inds = np.flip(np.sort(unique_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85ae97bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1292, 1288, 1284, 1280, 1134, 1132, 1131, 1130, 1128, 1127, 1126,\n",
       "       1123, 1122, 1121, 1120, 1118, 1116, 1115, 1114, 1112, 1111, 1110,\n",
       "       1108, 1107, 1106, 1105, 1104, 1100, 1099, 1096, 1095, 1092, 1091,\n",
       "       1089, 1088,  975,  974,  973,  972,  971,  970,  969,  968,  967,\n",
       "        966,  965,  964,  963,  962,  961,  960,  959,  958,  957,  956,\n",
       "        955,  954,  953,  952,  951,  950,  949,  948,  947,  946,  945,\n",
       "        944,  943,  942,  941,  940,  939,  938,  937,  936,  935,  934,\n",
       "        933,  932,  931,  930,  929,  928,  927,  926,  925,  924,  923,\n",
       "        922,  921,  920,  919,  918,  917,  916,  915,  914,  913,  912,\n",
       "        911,  910,  909,  908,  907,  906,  905,  904,  903,  902,  901,\n",
       "        900,  899,  898,  897,  896,  895,  894,  893,  892,  891,  890,\n",
       "        889,  888,  887,  886,  885,  884,  882,  880,  879,  878,  876,\n",
       "        875,  874,  872,  871,  870,  869,  868,  864,  863,  860,  859,\n",
       "        856,  855,  853,  852,  820,  819,  818,  817,  816,  815,  814,\n",
       "        813,  812,  811,  810,  809,  808,  807,  806,  805,  804,  803,\n",
       "        802,  801,  800,  799,  798,  797,  795,  794,  793,  791,  790,\n",
       "        789,  787,  786,  785,  783,  782,  781,  780,  779,  778,  777,\n",
       "        776,  775,  774,  773,  772,  771,  770,  769,  768,  767,  766,\n",
       "        765,  764,  763,  762,  761,  760,  759,  758,  757,  756,  755,\n",
       "        754,  753,  752,  751,  750,  749,  748,  747,  746,  745,  744,\n",
       "        743,  742,  741,  740,  739,  738,  737,  736,  735,  734,  733,\n",
       "        732,  731,  730,  729,  728,  727,  726,  725,  724,  723,  722,\n",
       "        721,  720,  719,  718,  717,  716,  715,  714,  713,  712,  711,\n",
       "        710,  709,  708,  707,  706,  705,  704,  703,  702,  701,  700,\n",
       "        699,  698,  697,  696,  695,  694,  693,  692,  691,  690,  689,\n",
       "        688,  672,  671,  670,  669,  668,  667,  666,  665,  664,  663,\n",
       "        662,  661,  660,  659,  658,  657,  656,  655,  654,  653,  652,\n",
       "        651,  650,  649,  648,  647,  646,  645,  644,  643,  642,  641,\n",
       "        640,  639,  638,  637,  636,  635,  634,  633,  632,  631,  630,\n",
       "        629,  628,  627,  626,  625,  624,  623,  622,  621,  620,  619,\n",
       "        618,  617,  616,  615,  614,  613,  612,  611,  610,  609,  608,\n",
       "        607,  606,  605,  604,  603,  602,  601,  600,  599,  598,  597,\n",
       "        596,  595,  594,  593,  592,  591,  590,  589,  588,  587,  586,\n",
       "        585,  584,  583,  582,  581,  580,  579,  578,  577,  576,  575,\n",
       "        574,  573,  572,  571,  570,  569,  568,  567,  566,  565,  564,\n",
       "        563,  562,  561,  560,  559,  558,  557,  556,  555,  554,  553,\n",
       "        552,  551,  550,  549,  548,  547,  546,  545,  544,  528,  527,\n",
       "        526,  525,  524,  523,  522,  521,  520,  519,  518,  517,  516,\n",
       "        515,  514,  513,  512,  511,  510,  509,  508,  507,  506,  505,\n",
       "        504,  503,  502,  501,  500,  499,  498,  497,  496,  495,  494,\n",
       "        493,  492,  491,  490,  489,  488,  487,  486,  485,  484,  483,\n",
       "        482,  481,  480,  479,  478,  477,  476,  475,  474,  473,  472,\n",
       "        471,  470,  469,  468,  467,  466,  465,  464,  463,  462,  461,\n",
       "        460,  459,  458,  457,  456,  455,  454,  453,  452,  451,  450,\n",
       "        449,  448,  447,  446,  445,  444,  443,  442,  441,  440,  439,\n",
       "        438,  437,  436,  435,  434,  433,  432,  431,  430,  429,  428,\n",
       "        427,  426,  425,  424,  423,  422,  421,  420,  419,  418,  417,\n",
       "        416,  415,  414,  413,  412,  396,  395,  394,  393,  392,  391,\n",
       "        390,  389,  388,  387,  386,  385,  384,  383,  382,  381,  380,\n",
       "        379,  378,  377,  376,  375,  374,  373,  372,  371,  370,  369,\n",
       "        368,  367,  366,  365,  364,  363,  362,  361,  360,  359,  358,\n",
       "        357,  356,  355,  354,  353,  352,  351,  350,  349,  348,  347,\n",
       "        346,  345,  344,  343,  342,  341,  340,  339,  338,  337,  336,\n",
       "        335,  334,  333,  332,  331,  330,  329,  328,  327,  326,  325,\n",
       "        324,  323,  322,  321,  320,  319,  318,  317,  316,  315,  314,\n",
       "        313,  312,  311,  310,  309,  308,  307,  306,  305,  304,  303,\n",
       "        302,  301,  300,  299,  298,  297,  296,  295,  294,  293,  292,\n",
       "        291,  290,  289,  288,  287,  286,  285,  284,  283,  282,  281,\n",
       "        280,  264,  263,  262,  261,  260,  259,  258,  257,  256,  255,\n",
       "        254,  253,  252,  251,  250,  249,  248,  247,  246,  245,  244,\n",
       "        243,  242,  241,  240,  239,  238,  237,  236,  235,  234,  233,\n",
       "        232,  231,  230,  229,  228,  227,  226,  225,  224,  223,  222,\n",
       "        221,  220,  219,  218,  217,  216,  215,  214,  213,  212,  211,\n",
       "        210,  209,  208,  207,  206,  205,  204,  203,  202,  201,  200,\n",
       "        199,  198,  197,  196,  195,  194,  193,  192,  191,  190,  189,\n",
       "        188,  187,  186,  185,  184,  183,  182,  181,  180,  179,  178,\n",
       "        177,  176,  175,  174,  173,  172,  171,  170,  169,  168,  167,\n",
       "        166,  165,  164,  163,  162,  161,  160,  159,  158,  157,  156,\n",
       "        155,  154,  153,  152,  151,  150,  149,  148,  132,  131,  130,\n",
       "        129,  128,  127,  126,  125,  124,  123,  122,  121,  120,  119,\n",
       "        118,  117,  116,  115,  114,  113,  112,  111,  110,  109,  108,\n",
       "        107,  106,  105,  104,  103,  102,  101,  100,   99,   98,   97,\n",
       "         96,   95,   94,   93,   92,   91,   90,   89,   88,   87,   86,\n",
       "         85,   84,   83,   82,   81,   80,   79,   78,   77,   76,   75,\n",
       "         74,   73,   72,   71,   70,   69,   68,   67,   66,   65,   64,\n",
       "         63,   62,   61,   60,   59,   58,   57,   56,   55,   54,   53,\n",
       "         52,   51,   50,   49,   48,   47,   46,   45,   44,   43,   42,\n",
       "         41,   40,   39,   38,   37,   36,   35,   34,   33,   32,   31,\n",
       "         30,   29,   28,   27,   26,   25,   24,   23,   22,   21,   20,\n",
       "         19,   18,   17,   16,    0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5ed30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_inds = unique_inds[np.flip(np.argsort(bboxes_unique[:,1]-bboxes_unique[:,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f0b0294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 237, 237, 237, 237, 236, 236, 236, 236, 233])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes[unique_inds[0:10],1] - bboxes[unique_inds[0:10],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "544d4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = bboxes[np.flip(np.argsort(bboxes[:,1]-bboxes[:,0])),:]\n",
    "n_prfs = bboxes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f113a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "437983f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 240,   0, 240],\n",
       "       [  3, 240,   1, 238],\n",
       "       [  0, 237,   1, 238],\n",
       "       ...,\n",
       "       [111, 129,   0,  18],\n",
       "       [111, 129, 222, 240],\n",
       "       [  0,  18, 110, 128]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0e47d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  18, 110, 128],\n",
       "       [  0,  23, 108, 131],\n",
       "       [  0,  29,   0,  29],\n",
       "       ...,\n",
       "       [216, 237, 216, 237],\n",
       "       [217, 240, 109, 132],\n",
       "       [222, 240, 111, 129]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes np.unique(bbox, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d747cba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110, 131, 110, 131],\n",
       "       [110, 131, 110, 131],\n",
       "       [110, 131, 110, 131],\n",
       "       ...,\n",
       "       [  0, 240,   0, 240],\n",
       "       [  0, 240,   0, 240],\n",
       "       [  0, 240,   0, 240]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb887000",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = bent_gabor_feature_bank(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa376ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "thing = torch.Tensor(np.ones((10,20,10)))\n",
    "thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a96b3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = np.random.normal(0,1,[100,100,200])\n",
    "time = time.time\n",
    "ans = np.mean(np.mean(thing, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2eea1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = np.random.normal(0,1,[128,128,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e1e24822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "output1 = np.concatenate([bank.filter_image_batch_pytorch(image_batch, k) for k in ['curv','rect', 'linear']], axis=2)\n",
    "elapsed = time.time() - st\n",
    "print('elapsed time = %.5f s'%elapsed)\n",
    "st = time.time()\n",
    "output2 = bank.filter_image_batch_pytorch(image_batch, 'all')\n",
    "elapsed = time.time() - st\n",
    "print('elapsed time = %.5f s'%elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "347bd1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time = 54.49722 s\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "output3 = np.concatenate([bank.filter_image_batch(image_batch, k) for k in ['curv','rect', 'linear']], axis=2)\n",
    "elapsed = time.time() - st\n",
    "print('elapsed time = %.5f s'%elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "80a141bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 128, 352, 50), (128, 128, 352, 50))"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.shape, output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "19f98093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.dtype, output2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "de9d9c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4696233, 1.4214585, 1.7884996, 2.476495 , 0.7059956, 1.3420668,\n",
       "       1.8813096, 2.1318772, 2.8678038, 2.6955152, 1.8448137, 1.6807752,\n",
       "       2.3423147, 1.7749122, 2.268266 , 1.711766 , 2.5058978, 2.2039583,\n",
       "       0.6841866, 1.3269516, 2.5777104, 1.5785817, 1.0995805, 2.1393645,\n",
       "       2.17551  , 1.4904385, 1.6286892, 2.0808933, 1.0770144, 1.4902999,\n",
       "       2.4968717, 3.195699 , 2.496212 , 1.8734933, 2.2282205, 2.0609915,\n",
       "       1.793022 , 1.2400877, 2.4840724, 2.538421 , 3.2831697, 1.8803866,\n",
       "       2.2383482, 2.0741968, 1.4740773, 1.7631953, 1.6768072, 3.549436 ,\n",
       "       1.4978232, 0.9511576], dtype=float32)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1[100,120,300,:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ef50e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4696233, 1.4214585, 1.7884996, 2.476495 , 0.7059956, 1.3420668,\n",
       "       1.8813096, 2.1318772, 2.8678038, 2.6955152, 1.8448137, 1.6807752,\n",
       "       2.3423147, 1.7749122, 2.268266 , 1.711766 , 2.5058978, 2.2039583,\n",
       "       0.6841866, 1.3269516, 2.5777104, 1.5785817, 1.0995805, 2.1393645,\n",
       "       2.17551  , 1.4904385, 1.6286892, 2.0808933, 1.0770144, 1.4902999,\n",
       "       2.4968717, 3.195699 , 2.496212 , 1.8734933, 2.2282205, 2.0609915,\n",
       "       1.793022 , 1.2400877, 2.4840724, 2.538421 , 3.2831697, 1.8803866,\n",
       "       2.2383482, 2.0741968, 1.4740773, 1.7631953, 1.6768072, 3.549436 ,\n",
       "       1.4978232, 0.9511576], dtype=float32)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[100,120,300,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7c522a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time = 0.77986 s\n",
      "elapsed time = 2.77879 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "output1 = bank.filter_image_batch_pytorch(image_batch, 'rect')\n",
    "elapsed = time.time() - st\n",
    "print('elapsed time = %.5f s'%elapsed)\n",
    "st = time.time()\n",
    "output2 = bank.filter_image_batch(image_batch, 'rect')\n",
    "elapsed = time.time() - st\n",
    "print('elapsed time = %.5f s'%elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9777d17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 160, 5)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ec930256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "826fb944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7d09b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2784, 0.2287, 0.2413, 0.1713, 0.1855])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1[100,120,10,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e180915d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27844459, 0.22866219, 0.24127039, 0.17133451, 0.18545024])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[100,120,10,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5cd12d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_list = bank.kernels['curv_freq']\n",
    " \n",
    "\"\"\"image x, image y, kernel dimension, all images (4D array)\"\"\"\n",
    "all_kernels = np.dstack(kernel_list)\n",
    "\n",
    "\"\"\"calculate kernel norm for normalization\"\"\"\n",
    "all_kernels_power =  np.einsum('ijk,ijk->k',np.abs(all_kernels),np.abs(all_kernels))\n",
    "all_kernels_power =  np.sqrt(all_kernels_power)\n",
    "all_kernels_power_1 = all_kernels_power\n",
    "\n",
    "\n",
    "\"\"\"stack fft image list to a 3d array\"\"\"\n",
    "image_batch_fft = np.fft.fft2(image_batch, axes=(0,1))\n",
    "\n",
    "mult = image_batch_fft[:,:,np.newaxis,:]*all_kernels[:,:,:,np.newaxis]\n",
    "\n",
    "all_conved_images = np.abs(np.fft.ifft2(mult,axes=(0,1)))\n",
    "# all_conved_images_1 = all_conved_images\n",
    "all_conved_images = np.power(all_conved_images,1/2) ## power correction\n",
    "all_conved_images_1 = all_conved_images\n",
    "# all_conved_images = all_conved_images/all_kernels_power[np.newaxis, np.newaxis,:,np.newaxis]\n",
    "\n",
    "# all_conved_images_1 = all_conved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "790ae1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02727183, 0.02727721, 0.02727183, 0.02727721, 0.02727183,\n",
       "       0.02727721, 0.02727266, 0.02727722, 0.02727266, 0.02727722])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kernels_power_1[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "24da4de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0273, 0.0273, 0.0273, 0.0273, 0.0273, 0.0273, 0.0273, 0.0273, 0.0273,\n",
       "        0.0273])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kernels_power_2[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "afc1328e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.93472890e-09-3.40413453e-10j,  1.77749642e-09-1.50342876e-09j,\n",
       "        3.93845074e-09-5.78986695e-09j,  4.38945932e-09+4.00415532e-09j,\n",
       "       -6.78794118e-09+3.18103287e-09j])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_1[10,90,50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3f134159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9347e-09-3.4041e-10j,  1.7775e-09-1.5034e-09j,\n",
       "         3.9385e-09-5.7899e-09j,  4.3895e-09+4.0042e-09j,\n",
       "        -6.7879e-09+3.1810e-09j])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_2[10,90,50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "39d99690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00593715, 0.00647518, 0.00165913, 0.00410518, 0.00667207])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conved_images_1[50,100,80,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7b033685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0059, 0.0065, 0.0017, 0.0041, 0.0067])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conved_images_2[50,100,80,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0f1720a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conved_images_2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c5e87702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5250e-05, 4.1928e-05, 2.7527e-06, 1.6853e-05, 4.4517e-05])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conved_images_2[50,100,80,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79dee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "08b62e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stack all the filters together, [self.kernel_size, self.kernel_size, n_filters]\n",
    "# and send to specified device.\n",
    "all_kernels = np.dstack(kernel_list)\n",
    "all_kernels_tensor = torch.complex(torch.Tensor(np.real(all_kernels)), \\\n",
    "                                   torch.Tensor(np.imag(all_kernels)))\n",
    "\n",
    "# Compute power of each kernel, will use to normalize the convolution result.\n",
    "all_kernels_power =  torch.sum(torch.sum(torch.pow(torch.abs(all_kernels_tensor), 2), axis=0), axis=0)\n",
    "all_kernels_power =  torch.sqrt(all_kernels_power)\n",
    "all_kernels_power_2 = all_kernels_power\n",
    "\n",
    "# send image batch to device [self.image_size, self.image_size, n_images]\n",
    "image_batch_tensor = torch.Tensor(image_batch).to(bank.device)\n",
    "# get frequency domain representation of images\n",
    "image_batch_fft = torch.fft.fftn(image_batch_tensor, dim=(0,1))\n",
    "\n",
    "# apply the filters by multiplying all at once\n",
    "mult = image_batch_fft.view([bank.image_size, bank.image_size,1,-1]) * \\\n",
    "        all_kernels_tensor.view([bank.image_size, bank.image_size,-1,1])\n",
    "# # back to spatial domain \n",
    "all_conved_images = torch.abs(torch.fft.ifftn(mult,dim=(0,1)))\n",
    "# all_conved_images_2 = all_conved_images\n",
    "# # power correction\n",
    "all_conved_images = torch.pow(all_conved_images,1/2) \n",
    "# all_conved_images_2 = all_conved_images\n",
    "# all_conved_images = all_conved_images/ \\\n",
    "#             all_kernels_power.view([1,1,all_kernels_power.shape[0],1])\n",
    "all_conved_images_2 = all_conved_images\n",
    "# all_conved_images_2 = all_conved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "31d75a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.+6.j])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing = 5+6j\n",
    "thing = np.array([thing])\n",
    "thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c4cc18d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(npz.array([thing]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6b3ed520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.+6.j])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = torch.complex(torch.Tensor(np.real(thing)), torch.Tensor(np.imag(thing)))\n",
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "97dbe99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.8102])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6e7b806f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.81024968])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8bffd5f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (numpy.ndarray, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-2fa5571c0f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (numpy.ndarray, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "torch.Tensor(thing, dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbb22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels = np.random.normal(0,1,[40,40,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c0175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.5405043 , 40.97954212, 39.59402806, 40.80134468, 39.94954381])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kernels_power =  np.einsum('ijk,ijk->k',np.abs(all_kernels),np.abs(all_kernels))\n",
    "all_kernels_power =  np.sqrt(all_kernels_power)\n",
    "all_kernels_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1a1295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.5405043 , 40.97954212, 39.59402806, 40.80134468, 39.94954381])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kernels_power = np.sum(np.sum(all_kernels**2, axis=0), axis=0)\n",
    "all_kernels_power =  np.sqrt(all_kernels_power)\n",
    "all_kernels_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ebc5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40.5405, 40.9795, 39.5940, 40.8013, 39.9495])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kernels_torch = torch.Tensor(all_kernels).to('cpu:0')\n",
    "all_kernels_power =  torch.sum(torch.sum(torch.pow(all_kernels_torch, 2), axis=0), axis=0)\n",
    "all_kernels_power =  torch.sqrt(all_kernels_power)\n",
    "all_kernels_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a287d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = np.random.normal(0,1,[40,40,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5c1f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch_fft = np.fft.fft2(image_batch, axes=(0,1))\n",
    "       \n",
    "all_kernels_power = np.sum(np.sum(all_kernels**2, axis=0), axis=0)\n",
    "all_kernels_power =  np.sqrt(all_kernels_power)\n",
    "\n",
    "all_conved_images = np.abs(np.fft.ifft2(image_batch_fft[:,:,np.newaxis,:]*all_kernels[:,:,:,np.newaxis],axes=(0,1)))\n",
    "all_conved_images = np.power(all_conved_images,1/2) ## power correction\n",
    "all_conved_images = all_conved_images/all_kernels_power[np.newaxis, np.newaxis,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c037041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01810492, 0.01245891],\n",
       "       [0.00791344, 0.0263366 ],\n",
       "       [0.03090774, 0.02566644],\n",
       "       [0.02327567, 0.0121277 ],\n",
       "       [0.01799749, 0.02118772]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conved_images[20,20,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c3335fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch_torch = torch.Tensor(image_batch).to('cpu:0')\n",
    "image_batch_fft = torch.fft.fftn(image_batch_torch, dim=(0,1))\n",
    "        \n",
    "all_kernels_torch = torch.Tensor(all_kernels).to('cpu:0')\n",
    "all_kernels_power =  torch.sum(torch.sum(torch.pow(all_kernels_torch, 2), axis=0), axis=0)\n",
    "all_kernels_power =  torch.sqrt(all_kernels_power)\n",
    "\n",
    "mult = image_batch_fft.view([image_batch_fft.shape[0],image_batch_fft.shape[1],1,-1]) * \\\n",
    "        all_kernels_torch.view([all_kernels_torch.shape[0], all_kernels_torch.shape[1],-1,1])\n",
    "all_conved_images = torch.abs(torch.fft.ifftn(mult,dim=(0,1)))\n",
    "all_conved_images = torch.pow(all_conved_images,1/2) ## power correction\n",
    "all_conved_images = all_conved_images/ \\\n",
    "            all_kernels_power.view([1,1,all_kernels_power.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89caa707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0181, 0.0125],\n",
       "        [0.0079, 0.0263],\n",
       "        [0.0309, 0.0257],\n",
       "        [0.0233, 0.0121],\n",
       "        [0.0180, 0.0212]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conved_images[20,20,:,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
