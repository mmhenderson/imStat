{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3a3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "import skimage.transform\n",
    "\n",
    "# import custom modules\n",
    "code_dir = '/user_data/mmhender/imStat/code/'\n",
    "sys.path.append(code_dir)\n",
    "from feature_extraction import texture_statistics_gabor,  bdcn_features, sketch_token_features\n",
    "from feature_extraction import texture_statistics_pyramid\n",
    "from utils import nsd_utils, roi_utils\n",
    "\n",
    "bdcn_path = '/user_data/mmhender/toolboxes/BDCN/'\n",
    "\n",
    "from model_fitting import initialize_fitting, merge_features, fwrf_fit, fwrf_predict\n",
    "\n",
    "fpX = np.float32\n",
    "device = 'cpu:0'\n",
    "# device = initialize_fitting.init_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3754e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_type='sketch_tokens'\n",
    "do_avg_pool=True\n",
    "do_stack=True\n",
    "subject=1\n",
    "volume_space = True\n",
    "up_to_sess = 10\n",
    "n_ori = 4\n",
    "n_sf = 4\n",
    "nonlin_fn = False\n",
    "padding_mode = 'circular';\n",
    "group_all_hl_feats = True; \\\n",
    "sample_batch_size = 50; voxel_batch_size = 100; \\\n",
    "zscore_features = True; ridge = True; \\\n",
    "shuffle_images = False; random_images = False; random_voxel_data = False; \\\n",
    "do_fitting = True; do_val = True; do_varpart = True; date_str = None;\n",
    "shuff_rnd_seed = 0; \n",
    "\n",
    "\n",
    "debug = True; \\\n",
    "\n",
    "\n",
    "do_pca_pyr_hl = False; use_pca_st_feats=False; use_lda_st_feats=False;\n",
    "use_lda_animacy_st_feats=False;\n",
    "min_pct_var = 99; max_pc_to_retain = 400; map_ind = -1; \\\n",
    "n_prf_sd_out = 2; mult_patch_by_prf = True; \\\n",
    "downsample_factor = 1.0; do_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229e3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stamp: Oct-11-2021_1837_58\n",
      "\n",
      "Will save final output file to /user_data/mmhender/imStat/model_fits/S01/sketch_tokens_stacked/Oct-11-2021_1837_58_DEBUG/\n",
      "\n",
      "\n",
      "Volume space: ROI defs are located at: /lab_data/tarrlab/common/datasets/NSD/nsddata/ppdata/subj01/func1pt8mm/roi\n",
      "\n",
      "3794 voxels of overlap between kastner and prf definitions, using prf defs\n",
      "unique values in retino labels:\n",
      "[-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18. 19. 20. 21. 22. 23. 24. 25.]\n",
      "0 voxels of overlap between face and place definitions, using place defs\n",
      "unique values in categ labels:\n",
      "[-1.  0. 26. 27. 28. 30. 31. 32. 33.]\n",
      "1535 voxels are defined (differently) in both retinotopic areas and category areas\n",
      "Including all voxels that are defined within nsdgeneral mask, in addition to roi labels.\n",
      "\n",
      "18947 voxels are defined across all areas, and will be used for analysis\n",
      "\n",
      "Loading numerical label/name mappings for all ROIs:\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'VO1', 'VO2', 'PHC1', 'PHC2', 'TO2', 'TO1', 'LO2', 'LO1', 'V3B', 'V3A', 'IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'SPL1', 'FEF']\n",
      "[1, 2, 3, 4, 5]\n",
      "['OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces']\n",
      "[1, 2, 3]\n",
      "['OPA', 'PPA', 'RSC']\n",
      "\n",
      "Sizes of all defined ROIs in this subject:\n",
      "Region V1 has 2392 voxels. Includes subregions:\n",
      "['V1v', 'V1d']\n",
      "Region V2 has 2096 voxels. Includes subregions:\n",
      "['V2v', 'V2d']\n",
      "Region V3 has 1674 voxels. Includes subregions:\n",
      "['V3v', 'V3d']\n",
      "Region hV4 has 721 voxels. Includes subregions:\n",
      "['hV4']\n",
      "Region VO1-2 has 482 voxels. Includes subregions:\n",
      "['VO1', 'VO2']\n",
      "Region PHC1-2 has 382 voxels. Includes subregions:\n",
      "['PHC1', 'PHC2']\n",
      "Region LO1-2 has 488 voxels. Includes subregions:\n",
      "['LO2', 'LO1']\n",
      "Region TO1-2 has 339 voxels. Includes subregions:\n",
      "['TO2', 'TO1']\n",
      "Region V3ab has 965 voxels. Includes subregions:\n",
      "['V3B', 'V3A']\n",
      "Region IPS0-5 has 2155 voxels. Includes subregions:\n",
      "['IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5']\n",
      "Region SPL1 has 164 voxels. Includes subregions:\n",
      "['SPL1']\n",
      "Region FEF has 72 voxels. Includes subregions:\n",
      "['FEF']\n",
      "\n",
      "\n",
      "Region OFA has 355 voxels.\n",
      "Region FFA-1 has 484 voxels.\n",
      "Region FFA-2 has 310 voxels.\n",
      "Region mTL-faces has 0 voxels.\n",
      "Region aTL-faces has 159 voxels.\n",
      "Region OPA has 1611 voxels.\n",
      "Region PPA has 1033 voxels.\n",
      "Region RSC has 566 voxels.\n",
      "Loading data for sessions:\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "Data is located in: /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR...\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session01.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.264, sigma = 1.408\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session02.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.119, sigma = 1.289\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session03.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.333, sigma = 1.383\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session04.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.085, sigma = 1.255\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session05.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.193, sigma = 1.420\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session06.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.336, sigma = 1.494\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session07.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.202, sigma = 1.491\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session08.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.233, sigma = 1.471\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session09.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.273, sigma = 1.510\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session10.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.185, sigma = 1.510\n",
      "\n",
      "Size of full data set [nTrials x nVoxels] is:\n",
      "(7500, 18947)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if date_str==0:\n",
    "    date_str = None\n",
    "\n",
    "if do_fitting==False and date_str is None:\n",
    "    raise ValueError('if you want to start midway through the process (--do_fitting=False), then specify the date when training result was saved (--date_str).')\n",
    "\n",
    "if do_fitting==True and date_str is not None:\n",
    "    raise ValueError('if you want to do fitting from scratch (--do_fitting=True), specify --date_str=None (rather than entering a date)')\n",
    "\n",
    "if do_fitting==False and (do_pca_pyr_hl or do_pca_st or do_pca_bdcn):\n",
    "    raise ValueError('Cannot start midway through the process (--do_fitting=False) when doing pca, because the pca weight matrix is not saved in between trn/val.')\n",
    "\n",
    "if 'pyramid' in fitting_type:\n",
    "    model_name = initialize_fitting.get_pyramid_model_name(ridge, n_ori, n_sf, do_pca_hl = do_pca_pyr_hl)\n",
    "#         feature_types_exclude = []\n",
    "    feature_types_exclude = ['pixel']\n",
    "    name1 = 'pyramid_texture'\n",
    "\n",
    "elif 'gabor_texture' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_texture_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = []\n",
    "    name1 = 'gabor_texture'\n",
    "\n",
    "elif 'gabor_solo' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_solo_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = ['pixel', 'simple_feature_means', 'autocorrs', 'crosscorrs']\n",
    "    name1 = 'gabor_solo'\n",
    "\n",
    "elif 'bdcn' in fitting_type:\n",
    "    model_name = initialize_fitting.get_bdcn_model_name(do_pca_bdcn, map_ind)   \n",
    "    name1 = 'bdcn'\n",
    "\n",
    "elif 'sketch_tokens' in fitting_type:\n",
    "    if use_pca_st_feats:\n",
    "        # not allowing both of these to be true\n",
    "        use_lda_st_feats = False\n",
    "        use_lda_animacy_st_feats = False\n",
    "    model_name = initialize_fitting.get_sketch_tokens_model_name(use_pca_st_feats, \\\n",
    "                                                                 use_lda_st_feats, use_lda_animacy_st_feats)   \n",
    "    name1 = 'sketch_tokens'\n",
    "\n",
    "else:\n",
    "    raise ValueError('your string for fitting_type was not recognized')\n",
    "\n",
    "if 'plus_sketch_tokens' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_sketch_tokens_model_name(use_pca_st_feats, use_lda_st_feats, use_lda_animacy_st_feats)   \n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "elif 'plus_bdcn' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_bdcn_model_name(do_pca_bdcn, map_ind)\n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "\n",
    "if do_stack:\n",
    "    model_name += '_stacked'\n",
    "\n",
    "output_dir, fn2save = initialize_fitting.get_save_path(subject, volume_space, model_name, shuffle_images, random_images, random_voxel_data, debug, date_str)\n",
    "\n",
    "# decide what voxels to use  \n",
    "voxel_mask, voxel_index, voxel_roi, voxel_ncsnr, brain_nii_shape = roi_utils.get_voxel_roi_info(subject, volume_space, include_all=True)\n",
    "\n",
    "sessions = np.arange(0,up_to_sess)\n",
    "zscore_betas_within_sess = True\n",
    "# get all data and corresponding images, in two splits. always fixed set that gets left out\n",
    "trn_stim_data, trn_voxel_data, val_stim_data, val_voxel_data, \\\n",
    "        image_order, image_order_trn, image_order_val = nsd_utils.get_data_splits(subject, \\\n",
    "                                  sessions=sessions, image_inds_only = True, \\\n",
    "                                  voxel_mask=voxel_mask, volume_space=volume_space, \\\n",
    "                                  zscore_betas_within_sess=zscore_betas_within_sess, \\\n",
    "                              shuffle_images=shuffle_images, random_images=random_images, \\\n",
    "                                random_voxel_data=random_voxel_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a6c9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_precomputed_prfs(fitting_type):\n",
    "    \n",
    "    if fitting_type=='sketch_tokens':\n",
    "        prf_params_fn = '/user_data/mmhender/imStat/model_fits/S01/sketch_tokens/Oct-11-2021_1756_51/all_fit_params'\n",
    "    else:\n",
    "        raise ValueError('trying to load pre-computed prfs, but prf params are not yet computed for this model')\n",
    "\n",
    "    print('Loading pre-computed pRF estimates for all voxels from %s'%prf_params_fn)\n",
    "    out = torch.load(prf_params_fn)\n",
    "    best_model_each_voxel = out['best_params'][5][:,0]\n",
    "    \n",
    "    return best_model_each_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecb70c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed pRF estimates for all voxels from /user_data/mmhender/imStat/model_fits/S01/sketch_tokens/Oct-11-2021_1756_51/all_fit_params\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18947,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_each_voxel = load_precomputed_prfs(fitting_type)\n",
    "best_model_each_voxel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d904fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2594ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible lambda values are:\n",
      "[1.0000000e+00 4.2169652e+00 1.7782795e+01 7.4989418e+01 3.1622775e+02\n",
      " 1.3335215e+03 5.6234131e+03 2.3713736e+04 1.0000000e+05]\n",
      "most extreme RF positions:\n",
      "[-0.55 -0.55  0.04]\n",
      "[0.55       0.55       0.40000001]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trn_stim_data = image_order_trn\n",
    "val_stim_data = image_order_val\n",
    "\n",
    "# More params for fitting\n",
    "holdout_size, lambdas = initialize_fitting.get_fitting_pars(trn_voxel_data, zscore_features, ridge=ridge)\n",
    "# Params for the spatial aspect of the model (possible pRFs)\n",
    "aperture_rf_range = 1.1\n",
    "aperture, models = initialize_fitting.get_prf_models(aperture_rf_range=aperture_rf_range)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ad4aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_feature_extractor = sketch_token_feature_extractor(subject=subject, device=device,\\\n",
    "             use_pca_feats = use_pca_st_feats, min_pct_var = min_pct_var, max_pc_to_retain = max_pc_to_retain, \\\n",
    "             use_lda_feats = use_lda_st_feats, use_lda_animacy_feats = use_lda_animacy_st_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "294f6cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = <class 'numpy.float32'>\n",
      "device = cpu:0\n",
      "trn_size = 6122 (90.0%)\n",
      "Seeding random number generator: seed is 591711\n",
      "Initializing for fitting\n",
      "Clearing features from memory\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Loading pre-computed features from /user_data/mmhender/features/sketch_tokens/S1_features_each_prf.h5py\n",
      "Took 10.28832 seconds to load file\n",
      "Size of features array for this image set is:\n",
      "(6803, 151, 5)\n",
      "Final size of feature matrix is:\n",
      "(6803, 151)\n",
      "\n",
      "Fitting version 0 of 1: full_model, \n",
      "fitting model    0 of 875 , voxel batch 189 of 190\n",
      "Getting features for prf 1: [x,y,sigma] is [-0.49 -0.55 0.0400]\n",
      "Final size of feature matrix is:\n",
      "(6803, 151)\n",
      "\n",
      "Fitting version 0 of 1: full_model, \n",
      "fitting model    1 of 875 , voxel batch 189 of 190\n",
      "---------------------------------------\n",
      "total time = 48.436377s\n",
      "total throughput = 0.002556s/voxel\n",
      "voxel throughput = 0.001961s/voxel\n",
      "setup throughput = 0.012891s/model\n",
      "Clearing features from memory\n"
     ]
    }
   ],
   "source": [
    "# add an intercept\n",
    "add_bias=True\n",
    "# determines whether to shuffle before separating the nested heldout data for lambda and param selection. \n",
    "# always using true.\n",
    "shuffle=True \n",
    "shuff_rnd_seed = 591711\n",
    "best_losses, best_lambdas, best_params, best_train_holdout_preds, holdout_trial_order = \\\n",
    "                    fit_fwrf_model(trn_stim_data, trn_voxel_data, \\\n",
    "                                           _feature_extractor, models, \\\n",
    "                                           lambdas, best_model_each_voxel = None, \\\n",
    "                                            zscore=zscore_features, add_bias=add_bias, \\\n",
    "                                           voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, \\\n",
    "                                           shuffle=shuffle, shuff_rnd_seed=shuff_rnd_seed, device=device, \\\n",
    "                                           dtype=fpX, debug=debug)\n",
    "\n",
    "trn_holdout_voxel_data_pred = best_train_holdout_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fee90846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 18944, 18945, 18946]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(best_params[5]>-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "90d0a2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     3, ..., 18944, 18945, 18946])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(best_params[1][:,0,0]>0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4c7b96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 18936, 18937, 18938])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(best_params[5]==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ddf596af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2829,  4535,  8732, 13191, 17529]),)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(best_model_each_voxel==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "82e001cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['best_params'][5][[415,13191,17529]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "411f0aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f73b4862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[5][[415,13191,17529]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a34da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed pRF estimates for all voxels from /user_data/mmhender/imStat/model_fits/S01/sketch_tokens/Oct-11-2021_1756_51/all_fit_params\n"
     ]
    }
   ],
   "source": [
    "if fitting_type=='sketch_tokens':\n",
    "    prf_params_fn = '/user_data/mmhender/imStat/model_fits/S01/sketch_tokens/Oct-11-2021_1756_51/all_fit_params'\n",
    "else:\n",
    "    raise ValueError('trying to load pre-computed prfs, but prf params are not yet computed for this model')\n",
    "\n",
    "print('Loading pre-computed pRF estimates for all voxels from %s'%prf_params_fn)\n",
    "out = torch.load(prf_params_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1df243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as I\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import numpy_utils, torch_utils, texture_utils\n",
    "\n",
    "\"\"\"\n",
    "General code for fitting a 'feature weighted receptive field' model to fmri data - looping over many candidate pRF \n",
    "models for each voxel, find a set of weights that best predict its responses based on feature space of interest.\n",
    "Can work for many different types of feature spaces, feature extraction implemented with nn.Module.\n",
    "\n",
    "Original source of some of this code is the github repository:\n",
    "https://github.com/styvesg/nsd\n",
    "It was modified by MH to work for this project.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _cofactor_fn_cpu(_x, lambdas):\n",
    "    '''\n",
    "    Generating a matrix needed to solve ridge regression model for each lambda value.\n",
    "    Ridge regression (Tikhonov) solution is :\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    This func will return (X^T*X + I*lambda)^-1 * X^T. \n",
    "    So once we have that, can just multiply by training data (Y) to get weights.\n",
    "    returned size is [nLambdas x nFeatures x nTrials]\n",
    "    This version makes sure that the torch inverse operation is done on the cpu, and in floating point-64 precision.\n",
    "    Otherwise get bad results for small lambda values. This seems to be a torch-specific bug, noted around May 2021.\n",
    "    \n",
    "    '''\n",
    "    device_orig = _x.device\n",
    "    type_orig = _x.dtype\n",
    "    # switch to this specific format which works with inverse\n",
    "    _x = _x.to('cpu').to(torch.float64)\n",
    "    _f = torch.stack([(torch.mm(torch.t(_x), _x) + torch.eye(_x.size()[1], device='cpu', dtype=torch.float64) * l).inverse() for l in lambdas], axis=0) \n",
    "    \n",
    "    # [#lambdas, #feature, #feature] \n",
    "    cof = torch.tensordot(_f, _x, dims=[[2],[1]]) # [#lambdas, #feature, #sample]\n",
    "    \n",
    "    # put back to whatever way it was before, so that we can continue with other operations as usual\n",
    "    return cof.to(device_orig).to(type_orig)\n",
    "\n",
    "\n",
    "\n",
    "def _loss_fn(_cofactor, _vtrn, _xout, _vout):\n",
    "    '''\n",
    "    Calculate loss given \"cofactor\" from cofactor_fn, training data, held-out design matrix, held out data.\n",
    "    returns weights (betas) based on equation\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    also returns loss for these weights w the held out data. SSE is loss func here.\n",
    "    '''\n",
    "\n",
    "    _beta = torch.tensordot(_cofactor, _vtrn, dims=[[2], [0]]) # [#lambdas, #feature, #voxel]\n",
    "    _pred = torch.tensordot(_xout, _beta, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "    _loss = torch.sum(torch.pow(_vout[:,None,:] - _pred, 2), dim=0) # [#lambdas, #voxels]\n",
    "    return _beta, _loss, _pred\n",
    "\n",
    "\n",
    "\n",
    "def fit_fwrf_model(images, voxel_data, _feature_extractor, prf_models, lambdas, best_model_each_voxel=None,\\\n",
    "                   zscore=False, add_bias=False, voxel_batch_size=100, holdout_size=100, \\\n",
    "                       shuffle=True, shuff_rnd_seed=0, device=None, dtype=np.float32, debug=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Solve for encoding model weights using ridge regression.\n",
    "    Inputs:\n",
    "        images: the training images, [n_trials x 1 x height x width]\n",
    "            OR for models where features were pre-computed, this is a list of indices [n_trials,] into the 10,000 long feature array.\n",
    "        voxel_data: the training voxel data, [n_trials x n_voxels]\n",
    "        _feature_extractor_fn: module that maps from images to model features\n",
    "        prf_models: the list of possible pRFs to test, columns are [x, y, sigma]\n",
    "        lambdas: ridge lambda parameters to test\n",
    "        zscore: want to zscore each column of feature matrix before fitting?\n",
    "        add_bias: add a column of ones to feature matrix, for an additive bias?\n",
    "        voxel_batch_size: how many voxels to use at a time for model fitting\n",
    "        holdout_size: how many training trials to hold out for computing loss/lambda selection?\n",
    "        shuffle: do we shuffle training data order before holding trials out?      \n",
    "        shuff_rnd_seed: if we do shuffle training data (shuffle=True), what random seed to use? if zero, choose a new random seed in this code.\n",
    "        device: what device to use? cpu/cuda\n",
    "        debug: want to run a shortened version of this, to test it?\n",
    "    Outputs:\n",
    "        best_losses: loss value for each voxel (with best pRF and best lambda), eval on held out set\n",
    "        best_lambdas: best lambda for each voxel (chosen based on loss w held out set)\n",
    "        best_params: \n",
    "            [0] best pRF for each voxel [x,y,sigma]\n",
    "            [1] best weights for each voxel/feature\n",
    "            [2] if add_bias=True, best bias value for each voxel\n",
    "            [3] if zscore=True, the mean of each feature before z-score\n",
    "            [4] if zscore=True, the std of each feature before z-score\n",
    "            [5] index of the best pRF for each voxel (i.e. index of row in \"prf_models\")\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device=torch.device('cpu:0')\n",
    "\n",
    "    print ('dtype = %s' % dtype)\n",
    "    print ('device = %s' % device)\n",
    "\n",
    "    n_trials = len(images)\n",
    "    n_prfs = len(prf_models)\n",
    "    n_voxels = voxel_data.shape[1]   \n",
    "\n",
    "    # Get train/holdout splits.\n",
    "    # Held-out data here is used for lamdba selection.\n",
    "    # This is the inner part of nested cross-validation; there is another portion of data ('val') which never enters this function.\n",
    "    trn_size = n_trials - holdout_size\n",
    "    assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "    print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "    order = np.arange(len(voxel_data), dtype=int)\n",
    "    if shuffle:\n",
    "        if shuff_rnd_seed==0:\n",
    "            print('Computing a new random seed')\n",
    "            shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "        print('Seeding random number generator: seed is %d'%shuff_rnd_seed)\n",
    "        np.random.seed(shuff_rnd_seed)\n",
    "        np.random.shuffle(order)\n",
    "        \n",
    "    images = images[order]\n",
    "    \n",
    "    train_trial_order = order[:trn_size]\n",
    "    holdout_trial_order = order[trn_size:]\n",
    "\n",
    "    trn_data = copy.deepcopy(voxel_data[train_trial_order,:])\n",
    "    out_data = copy.deepcopy(voxel_data[holdout_trial_order,:])\n",
    "    \n",
    "    \n",
    "    # Here is where any model-specific additional initialization steps are done\n",
    "    # Includes initializing pca params arrays, if doing pca\n",
    "    if len(images.shape)>1:\n",
    "        image_size = images.shape[2:4]\n",
    "    else:\n",
    "        image_size = None\n",
    "    _feature_extractor.init_for_fitting(image_size, prf_models, dtype)\n",
    "    max_features = _feature_extractor.max_features\n",
    "\n",
    "    # Decide whether to do any \"partial\" versions of the models (leaving out subsets of features)\n",
    "    # Purpose is for variance partition\n",
    "    masks, partial_version_names = _feature_extractor.get_partial_versions()\n",
    "    n_partial_versions = len(partial_version_names) # will be one if skipping varpart\n",
    "    if add_bias:\n",
    "        masks = np.concatenate([masks, np.ones([masks.shape[0],1])], axis=1) # always include intercept \n",
    "    masks = np.transpose(masks)\n",
    "    # masks is [n_features_total (including intercept) x n_partial_versions]\n",
    "\n",
    "    # Initialize arrays to store model fitting params\n",
    "    best_w_params = np.zeros(shape=(n_voxels, max_features ,n_partial_versions), dtype=dtype)\n",
    "    best_prf_models = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)   \n",
    "    best_lambdas = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)\n",
    "    best_losses = np.full(fill_value=np.inf, shape=(n_voxels,n_partial_versions), dtype=dtype)\n",
    "\n",
    "    # Initialize arrays to store the trial-wise predictions (need these for stacking)\n",
    "    # Using JUST the held out trials here so the errors are always cross-validated\n",
    "    best_train_holdout_preds = np.zeros(shape=(n_voxels, holdout_size, n_partial_versions), dtype=dtype)\n",
    "\n",
    "    # Additional params that are optional\n",
    "    if add_bias:\n",
    "        best_w_params = np.concatenate([best_w_params, np.zeros(shape=(n_voxels,1,n_partial_versions), dtype=dtype)], axis=1)\n",
    "\n",
    "    if zscore:\n",
    "        features_mean = np.zeros(shape=(n_voxels, max_features), dtype=dtype)\n",
    "        features_std  = np.zeros(shape=(n_voxels, max_features), dtype=dtype)\n",
    "    else:\n",
    "        features_mean = None\n",
    "        features_std = None\n",
    "\n",
    "    start_time = time.time()\n",
    "    vox_loop_time = 0\n",
    "\n",
    "    print ('---------------------------------------\\n')\n",
    "    \n",
    "    with torch.no_grad(): # make sure local gradients are off to save memory\n",
    "        \n",
    "        # Looping over prf_models (here prf_models are different spatial RF definitions)\n",
    "        for m,(x,y,sigma) in enumerate(prf_models):\n",
    "            if debug and m>1:\n",
    "                break\n",
    "                \n",
    "            print('\\nGetting features for prf %d: [x,y,sigma] is [%.2f %.2f %.4f]'%(m, prf_models[m,0],  prf_models[m,1],  prf_models[m,2]))\n",
    "\n",
    "            t = time.time()            \n",
    "\n",
    "            # Get features for the desired pRF, across all trn set image  \n",
    "            # Features is size [ntrials x nfeatures]\n",
    "            # nfeatures may be less than max_features, because max_features is the largest number possible for any pRF.\n",
    "            # feature_inds_defined is length max_features, and tells which of the features in max_features are includes in features.\n",
    "            features, feature_inds_defined = _feature_extractor(images, (x,y,sigma), m, fitting_mode=True)\n",
    "            features = features.detach().cpu().numpy() \n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "\n",
    "            n_features_actual = features.shape[1]\n",
    "            \n",
    "            if zscore:  \n",
    "                features_m = np.mean(features, axis=0, keepdims=True) #[:trn_size]\n",
    "                features_s = np.std(features, axis=0, keepdims=True) + 1e-6          \n",
    "                features -= features_m\n",
    "                features /= features_s    \n",
    "\n",
    "            if add_bias:\n",
    "                features = np.concatenate([features, np.ones(shape=(len(features), 1), dtype=dtype)], axis=1)\n",
    "                feature_inds_defined = np.concatenate((feature_inds_defined, [True]), axis=0)\n",
    "                \n",
    "            trn_features = features[:trn_size,:]\n",
    "            out_features = features[trn_size:,:]\n",
    "            \n",
    "            \n",
    "            # Going to keep track of whether current prf is better than running best, for each voxel.\n",
    "            # This is for the full model only.\n",
    "            # Will use this to make sure for each partial model, we end up saving the params for the prf that was best w full model.\n",
    "            if best_model_each_voxel is None:\n",
    "                full_model_improved = np.zeros((n_voxels,),dtype=bool)\n",
    "                voxels_to_fit = np.arange(0, n_voxels)\n",
    "            else:\n",
    "                voxels_to_fit = np.where(best_model_each_voxel==m)[0]\n",
    "            \n",
    "            if len(voxels_to_fit)==0:\n",
    "                print('No voxels have this pRF saved as their best model, skipping it.')\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            n_voxels_to_fit = len(voxels_to_fit)            \n",
    "            n_voxel_batches = int(np.ceil(n_voxels_to_fit/voxel_batch_size))\n",
    "\n",
    "            \n",
    "            # Looping over versions of model w different features set to zero (variance partition)\n",
    "            for pp in range(n_partial_versions):\n",
    "\n",
    "                print('\\nFitting version %d of %d: %s, '%(pp, n_partial_versions, partial_version_names[pp]))\n",
    "\n",
    "                # nonzero_inds_full is length max_features (or max_features+1 if bias=True)\n",
    "                # same size as the final params matrices will be.\n",
    "                nonzero_inds_full = np.logical_and(masks[:,pp], feature_inds_defined)             \n",
    "                # nonzero_inds_full is restricted to just indices that are defined for this prf - ie same size as features.\n",
    "                nonzero_inds_short = masks[feature_inds_defined,pp]==1\n",
    "        \n",
    "                # Send matrices to gpu    \n",
    "                _xtrn = torch_utils._to_torch(trn_features[:, nonzero_inds_short], device=device)\n",
    "                _xout = torch_utils._to_torch(out_features[:, nonzero_inds_short], device=device)   \n",
    "\n",
    "                # Do part of the matrix math involved in ridge regression optimization out of the loop, \n",
    "                # because this part will be same for all the voxels.\n",
    "                _cof = _cofactor_fn_cpu(_xtrn, lambdas = lambdas) \n",
    "\n",
    "                # Now looping over batches of voxels (only reason is because can't store all in memory at same time)\n",
    "                vox_start = time.time()\n",
    "\n",
    "                for vi in range(n_voxel_batches):\n",
    "                    \n",
    "                    vinds = np.arange(voxel_batch_size*vi, np.min([voxel_batch_size*(vi+1), n_voxels_to_fit]))\n",
    "                    rv = voxels_to_fit[vinds]\n",
    "                    lv = len(vinds)\n",
    "\n",
    "                    sys.stdout.write('\\rfitting model %4d of %-4d, voxel batch %d of %d'%(m, n_prfs, vi, n_voxel_batches))\n",
    "                    if best_model_each_voxel is not None:\n",
    "                        print(vinds)\n",
    "                        print(rv)\n",
    "                    \n",
    "                    # Send matrices to gpu\n",
    "                    _vtrn = torch_utils._to_torch(trn_data[:,rv], device=device)\n",
    "                    _vout = torch_utils._to_torch(out_data[:,rv], device=device)\n",
    "\n",
    "                    # Here is where optimization happens - relatively simple matrix math inside loss fn.\n",
    "                    _betas, _loss, _pred_out = _loss_fn(_cof, _vtrn, _xout, _vout) #   [#lambda, #feature, #voxel, ], [#lambda, #voxel], [trials x lambdas x voxels]\n",
    "                    # Keep trial-by-trial predictions for each held-out set trial (need for stacking)\n",
    "                    pred_out = torch_utils.get_value(_pred_out) \n",
    "                \n",
    "                    # choose best lambda value and the loss that went with it.\n",
    "                    _loss_values, _lambda_index = torch.min(_loss, dim=0)\n",
    "                    loss_values, lambda_index = torch_utils.get_value(_loss_values), torch_utils.get_value(_lambda_index)\n",
    "                    betas = torch_utils.get_value(_betas)\n",
    "                    \n",
    "                    if best_model_each_voxel is None:\n",
    "                        \n",
    "                        if pp==0:\n",
    "\n",
    "                            # comparing this loss to the other prf_models for each voxel (e.g. the other RF position/sizes)\n",
    "                            assert(partial_version_names[pp]=='full_model' or partial_version_names[pp]=='full_combined_model')               \n",
    "                            imp = loss_values<best_losses[rv,pp]\n",
    "                            full_model_improved[rv] = imp\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            # for the partial models we don't actually care which pRF was best for the partial model itself,\n",
    "                            # just using which pRF is best for the full model. This way pRF is always the same even when \n",
    "                            # leaving a set of features out.\n",
    "                            imp = full_model_improved[rv]\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        imp = np.ones((lv,))==1\n",
    "\n",
    "                    if np.sum(imp)>0:\n",
    "\n",
    "                        # for whichever voxels had improvement relative to previous prf_models, save parameters now\n",
    "                        # this means we won't have to save all params for all prf_models, just best.\n",
    "                        arv = np.array(rv)[imp]\n",
    "\n",
    "                        lambda_inds = lambda_index[imp]\n",
    "                        best_lambdas[arv,pp] = lambda_inds\n",
    "                        best_losses[arv,pp] = loss_values[imp]                        \n",
    "                        best_prf_models[arv,pp] = m\n",
    "                        if zscore and pp==0:\n",
    "                            \n",
    "                            # only need to update the mean/std if we're working with the full model, because those will be same for all partial versions.\n",
    "                            fmean_tmp = copy.deepcopy(features_mean[arv,:])\n",
    "                            fstd_tmp = copy.deepcopy(features_std[arv,:])\n",
    "                            fmean_tmp[:,nonzero_inds_full[0:-1]] = features_m[0,nonzero_inds_short[0:-1]] # broadcast over updated voxels\n",
    "                            fmean_tmp[:,~nonzero_inds_full[0:-1]] = 0.0\n",
    "                            fstd_tmp[:,nonzero_inds_full[0:-1]] = features_s[0,nonzero_inds_short[0:-1]] # broadcast over updated voxels\n",
    "                            fstd_tmp[:,~nonzero_inds_full[0:-1]] = 0.0\n",
    "                            features_mean[arv,:] = fmean_tmp\n",
    "                            features_std[arv,:] = fstd_tmp\n",
    "                            \n",
    "                        # taking the weights associated with the best lambda value\n",
    "                        # remember that they won't fill entire matrix, rest of values stay at zero\n",
    "                        best_w_tmp = copy.deepcopy(best_w_params[arv,:,pp])\n",
    "                        best_w_tmp[:,nonzero_inds_full] = numpy_utils.select_along_axis(betas[:,:,imp], lambda_inds, \\\n",
    "                                                                                        run_axis=2, choice_axis=0).T\n",
    "                        best_w_tmp[:,~nonzero_inds_full] = 0.0 # make sure to fill zeros here\n",
    "                        best_w_params[arv,:,pp] = best_w_tmp\n",
    "                        \n",
    "                        # Save the trialwise predictions for all trials in their original order.\n",
    "                        # Choosing predictions from whichever lambda was best.\n",
    "                        best_train_holdout_preds[arv,:,pp] = numpy_utils.select_along_axis(pred_out[:,:,imp], \\\n",
    "                                                                               lambda_inds, run_axis=2, choice_axis=1).T;\n",
    "\n",
    "                vox_loop_time += (time.time() - vox_start)\n",
    "                elapsed = (time.time() - vox_start)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    # Print information about how fitting went...\n",
    "    total_time = time.time() - start_time\n",
    "    inv_time = total_time - vox_loop_time\n",
    "    return_params = [best_w_params[:,0:max_features,:],]\n",
    "    if add_bias:\n",
    "        return_params += [best_w_params[:,-1,:],]\n",
    "    else: \n",
    "        return_params += [None,]\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('total throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    print ('voxel throughput = %fs/voxel' % (vox_loop_time / n_voxels))\n",
    "    print ('setup throughput = %fs/model' % (inv_time / n_prfs))\n",
    "    \n",
    "    # This step clears the big feature maps for training data from feature extractor (no longer needed)\n",
    "    _feature_extractor.clear_big_features()\n",
    "    \n",
    "    best_params = [prf_models[best_prf_models],]+return_params+[features_mean, features_std]+[best_prf_models]\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return best_losses, best_lambdas, best_params, best_train_holdout_preds, holdout_trial_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92502995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import torch\n",
    "import time\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import decomposition\n",
    "\n",
    "from utils import prf_utils, torch_utils, texture_utils, default_paths\n",
    "sketch_token_feat_path = default_paths.sketch_token_feat_path\n",
    "\n",
    "class sketch_token_feature_extractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, subject, device,\\\n",
    "                 use_pca_feats = False, min_pct_var = 99, max_pc_to_retain = 100, \\\n",
    "                 use_lda_feats = False, use_lda_animacy_feats = False):\n",
    "        \n",
    "        super(sketch_token_feature_extractor, self).__init__()\n",
    "        \n",
    "        self.subject = subject\n",
    "        \n",
    "        self.use_pca_feats = use_pca_feats\n",
    "        self.use_lda_feats = use_lda_feats\n",
    "        self.use_lda_animacy_feats = use_lda_animacy_feats\n",
    "        \n",
    "        if self.use_pca_feats:\n",
    "            self.n_features = 151\n",
    "            self.use_lda_feats = False # only allow one of these to be true\n",
    "            self.use_lda_animacy_feats = False\n",
    "            self.features_file = os.path.join(sketch_token_feat_path, 'PCA', 'S%d_PCA.npy'%(subject))     \n",
    "        elif self.use_lda_animacy_feats:\n",
    "            self.n_features = 1\n",
    "            self.use_pca_feats = False\n",
    "            self.use_lda_feats = False\n",
    "            self.features_file = os.path.join(sketch_token_feat_path, 'LDA','S%d_LDA_animacy.npy'%subject)\n",
    "        elif self.use_lda_feats:\n",
    "            self.n_features = 11\n",
    "            self.use_pca_feats = False\n",
    "            self.use_lda_animacy_feats = False\n",
    "            self.features_file = os.path.join(sketch_token_feat_path, 'LDA', 'S%d_LDA.npy'%(subject))     \n",
    "        else:\n",
    "            self.n_features = 151\n",
    "            self.features_file = os.path.join(sketch_token_feat_path, 'S%d_features_each_prf.h5py'%(subject))\n",
    "            \n",
    "        if not os.path.exists(self.features_file):\n",
    "            raise RuntimeError('Looking at %s for precomputed features, not found.'%self.features_file)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        if self.use_pca_feats:\n",
    "            self.min_pct_var = min_pct_var\n",
    "            self.max_pc_to_retain = np.min([self.n_features, max_pc_to_retain])\n",
    "        else:\n",
    "            self.min_pct_var = None\n",
    "            self.max_pc_to_retain = None  \n",
    "            \n",
    "        self.do_varpart=False # only one set of features in this model for now, not doing variance partition\n",
    "        self.features_each_prf = None\n",
    "        \n",
    "    def init_for_fitting(self, image_size, models, dtype):\n",
    "\n",
    "        \"\"\"\n",
    "        Additional initialization operations which can only be done once we know image size and\n",
    "        desired set of candidate prfs.\n",
    "        \"\"\"\n",
    "        \n",
    "        print('Initializing for fitting')\n",
    "\n",
    "        if self.use_pca_feats:\n",
    "            self.max_features = self.max_pc_to_retain        \n",
    "        else:\n",
    "            self.max_features = self.n_features\n",
    "       \n",
    "        self.clear_big_features()\n",
    "        \n",
    "    def get_partial_versions(self):\n",
    "\n",
    "        if not hasattr(self, 'max_features'):\n",
    "            raise RuntimeError('need to run init_for_fitting first')\n",
    "           \n",
    "        partial_version_names = ['full_model']\n",
    "        masks = np.ones([1,self.max_features])\n",
    "\n",
    "        return masks, partial_version_names\n",
    "\n",
    "    def load_precomputed_features(self, image_inds):\n",
    "        \n",
    "        print('Loading pre-computed features from %s'%self.features_file)\n",
    "        t = time.time()\n",
    "           \n",
    "        if self.use_pca_feats:\n",
    "            \n",
    "            # loading pre-computed pca features, and deciding here how many features to include in model.\n",
    "            pc_result = np.load(self.features_file, allow_pickle=True).item()\n",
    "            scores_each_prf = pc_result['scores']\n",
    "            ev_each_prf = pc_result['ev']\n",
    "            n_pcs_avail = scores_each_prf[0].shape[1]\n",
    "            n_feat_each_prf = [np.where(np.cumsum(ev)>self.min_pct_var)[0][0] \\\n",
    "                               if np.size(np.where(np.cumsum(ev)>self.min_pct_var))>0 \\\n",
    "                               else n_pcs_avail for ev in ev_each_prf]\n",
    "            n_feat_each_prf = [np.min([nf, self.max_pc_to_retain]) for nf in n_feat_each_prf]\n",
    "            self.features_each_prf = [scores_each_prf[mm][image_inds,0:n_feat_each_prf[mm]] \\\n",
    "                                      for mm in range(len(scores_each_prf))]           \n",
    "            print('Size of features array for first prf model with this image set is:')\n",
    "            print(self.features_each_prf[0].shape)\n",
    "            \n",
    "#         elif self.use_lda_animacy_feats:\n",
    "            \n",
    "#             n_prfs = 875\n",
    "#             features_each_prf = np.zeros((len(image_inds), self.n_features, n_prfs))\n",
    "#             for mm in range(n_prfs):\n",
    "#                 fn2load = self.features_file.split('.')[0][0:-1] + '%d'%mm + '.csv'\n",
    "#                 print('loading from %s'%fn2load)\n",
    "#                 lda_result = pd.read_csv(fn2load, index_col = 0)               \n",
    "#                 labels = np.array(lda_result['has_animate'])\n",
    "#                 features_each_prf[:,:,mm] = labels[image_inds]               \n",
    "#             self.features_each_prf = features_each_prf\n",
    "#             assert(self.features_each_prf.shape[1]==self.max_features)\n",
    "#             print('Size of features array for this image set is:')\n",
    "#             print(self.features_each_prf.shape)\n",
    "            \n",
    "        elif self.use_lda_feats or self.use_lda_animacy_feats:\n",
    "            \n",
    "            # loading pre-computed linear discriminant analysis features\n",
    "            lda_result = np.load(self.features_file, allow_pickle=True).item()\n",
    "            scores_each_prf = lda_result['scores']\n",
    "\n",
    "            self.features_each_prf = np.moveaxis(np.array([scores_each_prf[mm][image_inds,:] \\\n",
    "                          for mm in range(len(scores_each_prf))]), [0,1,2], [2,0,1])\n",
    "            assert(self.features_each_prf.shape[1]==self.max_features)\n",
    "            print('Size of features array for this image set is:')\n",
    "            print(self.features_each_prf.shape)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Loading raw sketch tokens features.\n",
    "            with h5py.File(self.features_file, 'r') as data_set:\n",
    "                values = np.copy(data_set['/features'][:,:,0:5])\n",
    "                data_set.close() \n",
    "            elapsed = time.time() - t\n",
    "            print('Took %.5f seconds to load file'%elapsed)\n",
    "\n",
    "            self.features_each_prf = values[image_inds,:,:]\n",
    "        \n",
    "            print('Size of features array for this image set is:')\n",
    "            print(self.features_each_prf.shape)\n",
    "        \n",
    "    def clear_big_features(self):\n",
    "        \n",
    "        print('Clearing features from memory')\n",
    "        self.features_each_prf = None \n",
    "    \n",
    "    def forward(self, image_inds, prf_params, prf_model_index, fitting_mode = True):\n",
    "        \n",
    "        if self.features_each_prf is None:\n",
    "            self.load_precomputed_features(image_inds)\n",
    "        \n",
    "        if self.use_pca_feats:\n",
    "            features = self.features_each_prf[prf_model_index]\n",
    "        else:\n",
    "            features = self.features_each_prf[:,:,prf_model_index]\n",
    "        \n",
    "        assert(features.shape[0]==len(image_inds))\n",
    "        print('Final size of feature matrix is:')\n",
    "        print(features.shape)\n",
    "        \n",
    "        features = torch_utils._to_torch(features, self.device)\n",
    "        \n",
    "        feature_inds_defined = np.zeros((self.max_features,), dtype=bool)\n",
    "        feature_inds_defined[0:features.shape[1]] = 1\n",
    "            \n",
    "        return features, feature_inds_defined\n",
    "     \n",
    "    \n",
    "def get_features_each_prf(features_file, models, mult_patch_by_prf=True, do_avg_pool=True, \\\n",
    "                          batch_size=100, aperture=1.0, debug=False, device=None):\n",
    "    \"\"\"\n",
    "    Extract the portion of the feature maps corresponding to each prf in 'models'\n",
    "    Start with loading the feature maps h5py file (generated by get_st_features.m)\n",
    "    Save smaller features as an h5py file [n_images x n_features x n_prfs]\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cpu:0'\n",
    "        \n",
    "    with h5py.File(features_file, 'r') as data_set:\n",
    "        ds_size = data_set['/features'].shape\n",
    "    n_images = ds_size[3]\n",
    "    n_features = ds_size[0]\n",
    "    map_resolution = ds_size[1]\n",
    "    n_prfs = models.shape[0]\n",
    "    features_each_prf = np.zeros((n_images, n_features, n_prfs))\n",
    "    n_batches = int(np.ceil(n_images/batch_size))\n",
    "\n",
    "    for bb in range(n_batches):\n",
    "\n",
    "        if debug and bb>1:\n",
    "            continue\n",
    "\n",
    "        batch_inds = np.arange(batch_size * bb, np.min([batch_size * (bb+1), n_images]))\n",
    "\n",
    "        print('Loading features for images [%d - %d]'%(batch_inds[0], batch_inds[-1]))\n",
    "        st = time.time()\n",
    "        with h5py.File(features_file, 'r') as data_set:\n",
    "            # Note this order is reversed from how it was saved in matlab originally.\n",
    "            # The dimensions go [features x h x w x images]\n",
    "            # Luckily h and w are swapped matlab to python anyway, so can just switch the first and last.\n",
    "            values = np.copy(data_set['/features'][:,:,:,batch_inds])\n",
    "            data_set.close()  \n",
    "        fmaps_batch = np.moveaxis(values, [0,1,2,3],[3,1,2,0])\n",
    "\n",
    "        elapsed = time.time() - st\n",
    "        print('Took %.5f sec to load feature maps'%elapsed)\n",
    "\n",
    "        maps_full_field = torch_utils._to_torch(fmaps_batch, device=device)\n",
    "\n",
    "        for mm in range(n_prfs):\n",
    "\n",
    "            if debug and mm>1:\n",
    "                continue\n",
    "\n",
    "            prf_params = models[mm,:]\n",
    "            x,y,sigma = prf_params\n",
    "            print('Getting features for pRF [x,y,sigma]:')\n",
    "            print([x,y,sigma])\n",
    "            n_pix = map_resolution\n",
    "\n",
    "             # Define the RF for this \"model\" version\n",
    "            prf = torch_utils._to_torch(prf_utils.make_gaussian_mass(x, y, sigma, n_pix, size=aperture, \\\n",
    "                                      dtype=np.float32)[2], device=device)\n",
    "            minval = torch.min(prf)\n",
    "            maxval = torch.max(prf-minval)\n",
    "            prf_scaled = (prf - minval)/maxval\n",
    "\n",
    "            if mult_patch_by_prf:         \n",
    "                # This effectively restricts the spatial location, so no need to crop\n",
    "                maps = maps_full_field * prf_scaled.view([1,map_resolution,map_resolution,1])\n",
    "            else:\n",
    "                # This is a coarser way of choosing which spatial region to look at\n",
    "                # Crop the patch +/- n SD away from center\n",
    "                n_pf_sd_out = 2\n",
    "                bbox = texture_utils.get_bbox_from_prf(prf_params, prf.shape, n_prf_sd_out, min_pix=None, verbose=False, force_square=False)\n",
    "                print('bbox to crop is:')\n",
    "                print(bbox)\n",
    "                maps = maps_full_field[:,bbox[0]:bbox[1], bbox[2]:bbox[3],:]\n",
    "\n",
    "            if do_avg_pool:\n",
    "                features_batch = torch.mean(maps, dim=(1,2))\n",
    "            else:\n",
    "                features_batch = torch.max(maps, dim=(1,2))\n",
    "                \n",
    "            print('model %d, min/max of features in batch: [%s, %s]'%(mm, torch.min(features_batch), torch.max(features_batch))) \n",
    "\n",
    "            features_each_prf[batch_inds,:,mm] = torch_utils.get_value(features_batch)\n",
    "                      \n",
    "    return features_each_prf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
