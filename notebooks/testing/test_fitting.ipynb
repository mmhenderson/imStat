{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4832c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "import skimage.transform\n",
    "\n",
    "# import custom modules\n",
    "code_dir = '/user_data/mmhender/imStat/code/'\n",
    "sys.path.append(code_dir)\n",
    "from feature_extraction import texture_statistics_gabor, texture_statistics_pyramid, bdcn_features, sketch_token_features\n",
    "from utils import nsd_utils, roi_utils\n",
    "\n",
    "bdcn_path = '/user_data/mmhender/toolboxes/BDCN/'\n",
    "\n",
    "from model_fitting import initialize_fitting, merge_features, fwrf_fit, fwrf_predict\n",
    "\n",
    "fpX = np.float32\n",
    "device = 'cpu:0'\n",
    "# device = initialize_fitting.init_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d88f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_type='pyramid_texture'\n",
    "do_avg_pool=True\n",
    "subject=1\n",
    "volume_space = True\n",
    "up_to_sess = 1\n",
    "n_ori = 4\n",
    "n_sf = 4\n",
    "nonlin_fn = False\n",
    "padding_mode = 'circular';\n",
    "group_all_hl_feats = True; \\\n",
    "sample_batch_size = 50; voxel_batch_size = 100; \\\n",
    "zscore_features = True; ridge = True; \\\n",
    "shuffle_images = False; random_images = False; random_voxel_data = False; \\\n",
    "do_fitting = True; do_val = True; do_varpart = True; date_str = None;\n",
    "shuff_rnd_seed = 0; debug = True; \\\n",
    "do_pca = False; min_pct_var = 99; max_pc_to_retain = 400; map_ind = -1; \\\n",
    "n_prf_sd_out = 2; mult_patch_by_prf = True; \\\n",
    "downsample_factor = 1.0; do_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879dc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stamp: Sep-21-2021_2203_43\n",
      "\n",
      "Will save final output file to /user_data/mmhender/imStat/model_fits/S01/texture_pyramid_ridge_4ori_4sf/Sep-21-2021_2203_43_DEBUG/\n",
      "\n",
      "\n",
      "Volume space: ROI defs are located at: /lab_data/tarrlab/common/datasets/NSD/nsddata/ppdata/subj01/func1pt8mm/roi\n",
      "\n",
      "3794 voxels of overlap between kastner and prf definitions, using prf defs\n",
      "unique values in retino labels:\n",
      "[-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18. 19. 20. 21. 22. 23. 24. 25.]\n",
      "0 voxels of overlap between face and place definitions, using place defs\n",
      "unique values in categ labels:\n",
      "[-1.  0. 26. 27. 28. 30. 31. 32. 33.]\n",
      "1535 voxels are defined (differently) in both retinotopic areas and category areas\n",
      "\n",
      "14913 voxels are defined across all areas, and will be used for analysis\n",
      "\n",
      "Loading numerical label/name mappings for all ROIs:\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'VO1', 'VO2', 'PHC1', 'PHC2', 'TO2', 'TO1', 'LO2', 'LO1', 'V3B', 'V3A', 'IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'SPL1', 'FEF']\n",
      "[1, 2, 3, 4, 5]\n",
      "['OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces']\n",
      "[1, 2, 3]\n",
      "['OPA', 'PPA', 'RSC']\n",
      "\n",
      "Sizes of all defined ROIs in this subject:\n",
      "Region V1 has 2392 voxels. Includes subregions:\n",
      "['V1v', 'V1d']\n",
      "Region V2 has 2096 voxels. Includes subregions:\n",
      "['V2v', 'V2d']\n",
      "Region V3 has 1674 voxels. Includes subregions:\n",
      "['V3v', 'V3d']\n",
      "Region hV4 has 721 voxels. Includes subregions:\n",
      "['hV4']\n",
      "Region VO1-2 has 482 voxels. Includes subregions:\n",
      "['VO1', 'VO2']\n",
      "Region PHC1-2 has 382 voxels. Includes subregions:\n",
      "['PHC1', 'PHC2']\n",
      "Region LO1-2 has 488 voxels. Includes subregions:\n",
      "['LO2', 'LO1']\n",
      "Region TO1-2 has 339 voxels. Includes subregions:\n",
      "['TO2', 'TO1']\n",
      "Region V3ab has 965 voxels. Includes subregions:\n",
      "['V3B', 'V3A']\n",
      "Region IPS0-5 has 2155 voxels. Includes subregions:\n",
      "['IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5']\n",
      "Region SPL1 has 164 voxels. Includes subregions:\n",
      "['SPL1']\n",
      "Region FEF has 72 voxels. Includes subregions:\n",
      "['FEF']\n",
      "\n",
      "\n",
      "Region OFA has 355 voxels.\n",
      "Region FFA-1 has 484 voxels.\n",
      "Region FFA-2 has 310 voxels.\n",
      "Region mTL-faces has 0 voxels.\n",
      "Region aTL-faces has 159 voxels.\n",
      "Region OPA has 1611 voxels.\n",
      "Region PPA has 1033 voxels.\n",
      "Region RSC has 566 voxels.\n",
      "\n",
      "Loading images for subject 1\n",
      "\n",
      "image data size: (10000, 3, 227, 227) , dtype: uint8 , value range: 0 255\n",
      "Loading data for sessions:\n",
      "[1]\n",
      "Data is located in: /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR...\n",
      "Loading from /lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session01.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.237, sigma = 1.391\n",
      "\n",
      "Size of full data set [nTrials x nVoxels] is:\n",
      "(750, 14913)\n"
     ]
    }
   ],
   "source": [
    "if 'pyramid' in fitting_type:\n",
    "    model_name = initialize_fitting.get_pyramid_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = []        \n",
    "    name1 = 'pyramid_texture'\n",
    "\n",
    "elif 'gabor_texture' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_texture_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = []\n",
    "    name1 = 'gabor_texture'\n",
    "\n",
    "elif 'gabor_solo' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_solo_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = ['pixel', 'simple_feature_means', 'autocorrs', 'crosscorrs']\n",
    "    name1 = 'gabor_solo'\n",
    "\n",
    "elif 'bdcn' in fitting_type:\n",
    "    model_name = initialize_fitting.get_bdcn_model_name(do_pca, map_ind)   \n",
    "    name1 = 'bdcn'\n",
    "\n",
    "elif 'sketch_tokens' in fitting_type:\n",
    "    model_name = initialize_fitting.get_sketch_tokens_model_name(do_pca)   \n",
    "    name1 = 'sketch_tokens'\n",
    "\n",
    "else:\n",
    "    raise ValueError('your string for fitting_type was not recognized')\n",
    "\n",
    "if 'plus_sketch_tokens' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_sketch_tokens_model_name(do_pca)\n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "elif 'plus_bdcn' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_bdcn_model_name(do_pca, map_ind)\n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "\n",
    "\n",
    "output_dir, fn2save = initialize_fitting.get_save_path(subject, volume_space, model_name, shuffle_images, random_images, random_voxel_data, debug, date_str)\n",
    "\n",
    "# decide what voxels to use  \n",
    "voxel_mask, voxel_index, voxel_roi, voxel_ncsnr, brain_nii_shape = roi_utils.get_voxel_roi_info(subject, volume_space)\n",
    "\n",
    "sessions = np.arange(0,up_to_sess)\n",
    "zscore_betas_within_sess = True\n",
    "# get all data and corresponding images, in two splits. always fixed set that gets left out\n",
    "trn_stim_data, trn_voxel_data, val_stim_data, val_voxel_data, \\\n",
    "        image_order, image_order_trn, image_order_val = nsd_utils.get_data_splits(subject, sessions=sessions, \\\n",
    "                                                                     voxel_mask=voxel_mask, volume_space=volume_space, \\\n",
    "                                                                      zscore_betas_within_sess=zscore_betas_within_sess, \\\n",
    "                                                                      shuffle_images=shuffle_images, random_images=random_images, \\\n",
    "                                                                                         random_voxel_data=random_voxel_data)\n",
    "\n",
    "\n",
    "if 'gabor' in fitting_type or 'sketch_tokens' in fitting_type or 'pyramid' in fitting_type:\n",
    "    # For this model, the features are pre-computed, so we will just load them rather than passing in images.\n",
    "    # Going to pass the image indices (into 10,000 dim array) instead of images to fitting and val functions, \n",
    "    # which will tell which features to load.\n",
    "    trn_stim_data = image_order_trn\n",
    "    val_stim_data = image_order_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3074361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible lambda values are:\n",
      "[1.0000000e+00 4.2169652e+00 1.7782795e+01 7.4989418e+01 3.1622775e+02\n",
      " 1.3335215e+03 5.6234131e+03 2.3713736e+04 1.0000000e+05]\n",
      "most extreme RF positions:\n",
      "[-0.55 -0.55  0.04]\n",
      "[0.55       0.55       0.40000001]\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "# More params for fitting\n",
    "holdout_size, lambdas = initialize_fitting.get_fitting_pars(trn_voxel_data, zscore_features, ridge=ridge)\n",
    "# Params for the spatial aspect of the model (possible pRFs)\n",
    "aperture_rf_range = 1.1\n",
    "aperture, models = initialize_fitting.get_prf_models(aperture_rf_range=aperture_rf_range)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7628aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature types to exclude from the model:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "do_pca_pyr_hl = True\n",
    "do_pca_st = True\n",
    "\n",
    "group_all_hl_feats = True\n",
    "feature_types_exclude =[]\n",
    "# Set up the pyramid\n",
    "compute_features = False\n",
    "_fmaps_fn = steerable_pyramid_extractor(pyr_height = n_sf, n_ori = n_ori)\n",
    "# Initialize the \"texture\" model which builds on first level feature maps\n",
    "_feature_extractor1 = texture_feature_extractor(_fmaps_fn,sample_batch_size=sample_batch_size, \\\n",
    "                  subject=subject, feature_types_exclude=feature_types_exclude, n_prf_sd_out=n_prf_sd_out, \\\n",
    "                                               aperture=aperture, do_varpart = do_varpart, \\\n",
    "                              group_all_hl_feats = group_all_hl_feats, compute_features = compute_features, \\\n",
    "                               do_pca_hl=do_pca_pyr_hl, min_pct_var = min_pct_var, max_pc_to_retain = max_pc_to_retain, \\\n",
    "                               device=device)\n",
    "# feature_info = [_feature_extractor.feature_column_labels, _feature_extractor.feature_types_include]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c797fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_resolution = 227\n",
    "_feature_extractor2 = sketch_token_features.sketch_token_feature_extractor(subject, device, map_resolution=map_resolution, \\\n",
    "                                                                           aperture = aperture, \\\n",
    "                                                     n_prf_sd_out = n_prf_sd_out, \\\n",
    "                               batch_size=sample_batch_size, mult_patch_by_prf=mult_patch_by_prf, do_avg_pool = do_avg_pool,\\\n",
    "                                           do_pca = do_pca_st, min_pct_var = min_pct_var, max_pc_to_retain = max_pc_to_retain)\n",
    "_feature_extractor = merge_features.combined_feature_extractor([_feature_extractor1, _feature_extractor2], \\\n",
    "                                                                   [name1,'sketch_tokens'], do_varpart = do_varpart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d023ac95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a08119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=2\n",
    "_feature_extractor1.init_for_fitting((240,240), models, dtype=np.float32)\n",
    "feats1, defined1 = _feature_extractor1(val_stim_data, models[mm], mm, fitting_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5f67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing for fitting\n",
      "Initializing arrays for PCA params\n",
      "Clearing features from memory\n",
      "Loading pre-computed features from /user_data/mmhender/features/sketch_tokens/S1_features_each_prf.h5py\n",
      "Took 19.29789 seconds to load file\n",
      "Size of features array for this image set is:\n",
      "(62, 151, 875)\n",
      "Preparing for PCA: original dims of features:\n",
      "(62, 151)\n",
      "Running PCA...\n",
      "Retaining 1 components to expl 99 pct var\n",
      "Final size of feature matrix is:\n",
      "(62, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mm=2\n",
    "_feature_extractor2.init_for_fitting((240,240), models, dtype=np.float32)\n",
    "feats2, defined2 = _feature_extractor2(val_stim_data, models[mm], mm, fitting_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f247e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing for fitting\n",
      "Initializing arrays for PCA params\n",
      "Clearing precomputed features from memory.\n",
      "Initializing for fitting\n",
      "Initializing arrays for PCA params\n",
      "Clearing features from memory\n",
      "Loading pre-computed features for models [0 - 49] from /user_data/mmhender/features/pyramid_texture/S1_features_each_prf_4ori_4sf.h5py\n",
      "Took 95.55682 seconds to load file\n",
      "Index into batch for prf 2: 2\n",
      "Size of features array for this image set and prf is:\n",
      "(62, 641)\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Running PCA on higher-level features...\n",
      "Preparing for PCA: original dims of features:\n",
      "(62, 592)\n",
      "Running PCA...\n",
      "Retaining 2 components to expl 99 pct var\n",
      "Final size of features concatenated is [62 x 51]\n",
      "Loading pre-computed features from /user_data/mmhender/features/sketch_tokens/S1_features_each_prf.h5py\n",
      "Took 20.38642 seconds to load file\n",
      "Size of features array for this image set is:\n",
      "(62, 151, 875)\n",
      "Preparing for PCA: original dims of features:\n",
      "(62, 151)\n",
      "Running PCA...\n",
      "Retaining 1 components to expl 99 pct var\n",
      "Final size of feature matrix is:\n",
      "(62, 1)\n"
     ]
    }
   ],
   "source": [
    "mm=2\n",
    "_feature_extractor.init_for_fitting((240,240), models, dtype=np.float32)\n",
    "feats, defined = _feature_extractor(val_stim_data, models[mm], mm, fitting_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b966d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index into batch for prf 2: 2\n",
      "Size of features array for this image set and prf is:\n",
      "(62, 641)\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Running PCA on higher-level features...\n",
      "Preparing for PCA: original dims of features:\n",
      "(62, 592)\n",
      "Applying pre-computed PCA matrix...\n",
      "Final size of features concatenated is [62 x 51]\n",
      "Preparing for PCA: original dims of features:\n",
      "(62, 151)\n",
      "Applying pre-computed PCA matrix...\n",
      "Final size of feature matrix is:\n",
      "(62, 1)\n"
     ]
    }
   ],
   "source": [
    "feats, defined = _feature_extractor(val_stim_data, models[mm], mm, fitting_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbce3a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4aba5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_feature_extractor.modules[0].max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd1cdb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_feature_extractor.modules[1].max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f540bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = []\n",
    "for m in _feature_extractor.modules:           \n",
    "    if hasattr(m, 'pct_var_expl'):\n",
    "        pcm = [m.pct_var_expl, m.min_pct_var,  m.n_comp_needed]                  \n",
    "    else:\n",
    "        pcm = None\n",
    "    pc.append(pcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dad74a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        , 98.06194   , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.7108457 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.49869698, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "288fa34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1239e-01,  4.9881e-03,  3.6118e-02,  ..., -1.7653e+02,\n",
       "         -1.7898e+01, -7.5757e-05],\n",
       "        [ 3.7503e-02,  6.5405e-03,  2.0029e+00,  ..., -1.8690e+02,\n",
       "         -1.1006e+01,  1.4115e-04],\n",
       "        [ 2.0118e-01,  4.4240e-03,  1.1431e+00,  ..., -1.7151e+02,\n",
       "         -1.0463e+01,  2.8603e-05],\n",
       "        ...,\n",
       "        [ 1.5854e-02,  5.0241e-05,  1.2342e+00,  ...,  1.2241e+03,\n",
       "          6.5767e+00, -3.6620e-04],\n",
       "        [ 2.7447e-01,  1.8736e-02,  1.6470e+00,  ..., -2.3180e+01,\n",
       "         -1.4085e+01,  3.3083e-04],\n",
       "        [ 5.7150e-02,  1.9648e-05,  2.8961e+00,  ..., -1.9614e+02,\n",
       "         -1.2480e+01, -4.2701e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((feats, feats2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad53c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index into batch for prf 2: 2\n",
      "Size of features array for this image set and prf is:\n",
      "(62, 641)\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Running PCA on higher-level features...\n",
      "Preparing for PCA: original dims of features:\n",
      "(62, 592)\n",
      "Applying pre-computed PCA matrix...\n",
      "Final size of features concatenated is [62 x 51]\n"
     ]
    }
   ],
   "source": [
    "feats, defined = _feature_extractor(val_stim_data, models[mm], mm, fitting_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "860f337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 641)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_feature_extractor.modules[0].get_partial_versions()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cfea0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(defined==False)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83e8d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _feature_extractor.n_comp_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c89f771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(_feature_extractor, 'pct_kdfvar_expl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
