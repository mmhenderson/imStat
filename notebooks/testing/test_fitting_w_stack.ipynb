{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d4ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "import skimage.transform\n",
    "\n",
    "# import custom modules\n",
    "code_dir = '/Users/margarethenderson/Box Sync/imStat/code/'\n",
    "sys.path.append(code_dir)\n",
    "from feature_extraction import texture_statistics_gabor, texture_statistics_pyramid, sketch_token_features\n",
    "from utils import nsd_utils, roi_utils, default_paths\n",
    "\n",
    "from model_fitting import initialize_fitting, arg_parser, merge_features, fwrf_fit, fwrf_predict\n",
    "\n",
    "fpX = np.float32\n",
    "device = 'cpu:0'\n",
    "# device = initialize_fitting.init_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11add83a-9553-4c5a-adb0-e0224ecd99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing fitting code\n",
    "fitting_type='pyramid_texture'\n",
    "do_avg_pool=True\n",
    "subject=1\n",
    "volume_space = True\n",
    "up_to_sess = 1\n",
    "n_ori = 4\n",
    "n_sf = 4\n",
    "nonlin_fn = False\n",
    "padding_mode = 'circular';\n",
    "group_all_hl_feats = True; \\\n",
    "sample_batch_size = 50; voxel_batch_size = 100; \\\n",
    "zscore_features = True; ridge = True; \\\n",
    "shuffle_images = False; random_images = False; random_voxel_data = False; \\\n",
    "do_fitting = True; do_val = True; do_varpart = True; date_str = None;\n",
    "shuff_rnd_seed = 0; debug = True; \\\n",
    "do_pca_pyr_hl=False; do_pca_st=False; do_pca_st=False;  \n",
    "min_pct_var = 99; max_pc_to_retain = 400; map_ind = -1; \\\n",
    "n_prf_sd_out = 2; mult_patch_by_prf = True; \\\n",
    "downsample_factor = 1.0; do_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b2d1d3-441d-4d9d-8344-72b91ba529ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(default_paths.nsd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499d4327-d9b7-48c8-a44f-0b9a0e711a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stamp: Sep-24-2021_1914_28\n",
      "\n",
      "Will save final output file to /Users/margarethenderson/Box Sync/imStat/model_fits/S01/texture_pyramid_ridge_4ori_4sf/Sep-24-2021_1914_28_DEBUG/\n",
      "\n",
      "\n",
      "Volume space: ROI defs are located at: /Users/margarethenderson/Box Sync/nsd_betas_for_testing/nsddata/ppdata/subj01/func1pt8mm/roi\n",
      "\n",
      "3794 voxels of overlap between kastner and prf definitions, using prf defs\n",
      "unique values in retino labels:\n",
      "[-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18. 19. 20. 21. 22. 23. 24. 25.]\n",
      "0 voxels of overlap between face and place definitions, using place defs\n",
      "unique values in categ labels:\n",
      "[-1.  0. 26. 27. 28. 30. 31. 32. 33.]\n",
      "1535 voxels are defined (differently) in both retinotopic areas and category areas\n",
      "\n",
      "14913 voxels are defined across all areas, and will be used for analysis\n",
      "\n",
      "Loading numerical label/name mappings for all ROIs:\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'VO1', 'VO2', 'PHC1', 'PHC2', 'TO2', 'TO1', 'LO2', 'LO1', 'V3B', 'V3A', 'IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'SPL1', 'FEF']\n",
      "[1, 2, 3, 4, 5]\n",
      "['OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces']\n",
      "[1, 2, 3]\n",
      "['OPA', 'PPA', 'RSC']\n",
      "\n",
      "Sizes of all defined ROIs in this subject:\n",
      "Region V1 has 2392 voxels. Includes subregions:\n",
      "['V1v', 'V1d']\n",
      "Region V2 has 2096 voxels. Includes subregions:\n",
      "['V2v', 'V2d']\n",
      "Region V3 has 1674 voxels. Includes subregions:\n",
      "['V3v', 'V3d']\n",
      "Region hV4 has 721 voxels. Includes subregions:\n",
      "['hV4']\n",
      "Region VO1-2 has 482 voxels. Includes subregions:\n",
      "['VO1', 'VO2']\n",
      "Region PHC1-2 has 382 voxels. Includes subregions:\n",
      "['PHC1', 'PHC2']\n",
      "Region LO1-2 has 488 voxels. Includes subregions:\n",
      "['LO2', 'LO1']\n",
      "Region TO1-2 has 339 voxels. Includes subregions:\n",
      "['TO2', 'TO1']\n",
      "Region V3ab has 965 voxels. Includes subregions:\n",
      "['V3B', 'V3A']\n",
      "Region IPS0-5 has 2155 voxels. Includes subregions:\n",
      "['IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5']\n",
      "Region SPL1 has 164 voxels. Includes subregions:\n",
      "['SPL1']\n",
      "Region FEF has 72 voxels. Includes subregions:\n",
      "['FEF']\n",
      "\n",
      "\n",
      "Region OFA has 355 voxels.\n",
      "Region FFA-1 has 484 voxels.\n",
      "Region FFA-2 has 310 voxels.\n",
      "Region mTL-faces has 0 voxels.\n",
      "Region aTL-faces has 159 voxels.\n",
      "Region OPA has 1611 voxels.\n",
      "Region PPA has 1033 voxels.\n",
      "Region RSC has 566 voxels.\n",
      "\n",
      "Loading images for subject 1\n",
      "\n",
      "image data size: (10000, 3, 227, 227) , dtype: uint8 , value range: 0 255\n",
      "Loading data for sessions:\n",
      "[1]\n",
      "Data is located in: /Users/margarethenderson/Box Sync/nsd_betas_for_testing/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR...\n",
      "Loading from /Users/margarethenderson/Box Sync/nsd_betas_for_testing/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session01.nii.gz...\n",
      "Raw data:\n",
      "float64 -32768.0 32767.0 (750, 81, 104, 83)\n",
      "Adjusted data (divided by 300):\n",
      "float32 -109.22667 109.223335 (750, 699192)\n",
      "z-scoring beta weights within this session...\n",
      "mean = 1.237, sigma = 1.391\n",
      "\n",
      "Size of full data set [nTrials x nVoxels] is:\n",
      "(750, 14913)\n"
     ]
    }
   ],
   "source": [
    "if 'pyramid' in fitting_type:\n",
    "    model_name = initialize_fitting.get_pyramid_model_name(ridge, n_ori, n_sf, do_pca_hl = do_pca_pyr_hl)\n",
    "    feature_types_exclude = []        \n",
    "    name1 = 'pyramid_texture'\n",
    "\n",
    "elif 'gabor_texture' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_texture_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = []\n",
    "    name1 = 'gabor_texture'\n",
    "\n",
    "elif 'gabor_solo' in fitting_type:        \n",
    "    model_name = initialize_fitting.get_gabor_solo_model_name(ridge, n_ori, n_sf)\n",
    "    feature_types_exclude = ['pixel', 'simple_feature_means', 'autocorrs', 'crosscorrs']\n",
    "    name1 = 'gabor_solo'\n",
    "\n",
    "elif 'bdcn' in fitting_type:\n",
    "    model_name = initialize_fitting.get_bdcn_model_name(do_pca_bdcn, map_ind)   \n",
    "    name1 = 'bdcn'\n",
    "\n",
    "elif 'sketch_tokens' in fitting_type:\n",
    "    model_name = initialize_fitting.get_sketch_tokens_model_name(do_pca_st)   \n",
    "    name1 = 'sketch_tokens'\n",
    "\n",
    "else:\n",
    "    raise ValueError('your string for fitting_type was not recognized')\n",
    "\n",
    "if 'plus_sketch_tokens' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_sketch_tokens_model_name(do_pca)\n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "elif 'plus_bdcn' in fitting_type:\n",
    "    model_name2 = initialize_fitting.get_bdcn_model_name(do_pca, map_ind)\n",
    "    model_name = model_name + '_plus_' + model_name2\n",
    "\n",
    "\n",
    "output_dir, fn2save = initialize_fitting.get_save_path(subject, volume_space, model_name, shuffle_images, random_images, random_voxel_data, debug, date_str)\n",
    "\n",
    "# decide what voxels to use  \n",
    "voxel_mask, voxel_index, voxel_roi, voxel_ncsnr, brain_nii_shape = roi_utils.get_voxel_roi_info(subject, volume_space)\n",
    "\n",
    "sessions = np.arange(0,up_to_sess)\n",
    "zscore_betas_within_sess = True\n",
    "# get all data and corresponding images, in two splits. always fixed set that gets left out\n",
    "trn_stim_data, trn_voxel_data, val_stim_data, val_voxel_data, \\\n",
    "        image_order, image_order_trn, image_order_val = nsd_utils.get_data_splits(subject, sessions=sessions, \\\n",
    "                                                                     voxel_mask=voxel_mask, volume_space=volume_space, \\\n",
    "                                                                      zscore_betas_within_sess=zscore_betas_within_sess, \\\n",
    "                                                                      shuffle_images=shuffle_images, random_images=random_images, \\\n",
    "                                                                                         random_voxel_data=random_voxel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b728c99-a5d0-4b5a-b9d4-f27ed9b41306",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stim_data = image_order_trn\n",
    "val_stim_data = image_order_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "35ceccea-fe2c-4fcd-a32a-20823d2705ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible lambda values are:\n",
      "[1.0000000e+00 4.2169652e+00 1.7782795e+01 7.4989418e+01 3.1622775e+02\n",
      " 1.3335215e+03 5.6234131e+03 2.3713736e+04 1.0000000e+05]\n",
      "most extreme RF positions:\n",
      "[-0.55 -0.55  0.04]\n",
      "[0.55       0.55       0.40000001]\n",
      "Feature types to exclude from the model:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# More params for fitting\n",
    "holdout_size, lambdas = initialize_fitting.get_fitting_pars(trn_voxel_data, zscore_features, ridge=ridge)\n",
    "# Params for the spatial aspect of the model (possible pRFs)\n",
    "aperture_rf_range = 1.1\n",
    "aperture, models = initialize_fitting.get_prf_models(aperture_rf_range=aperture_rf_range)    \n",
    "    \n",
    "group_all_hl_feats = True\n",
    "# default_paths.pyramid_texture_feat_path = os.path.join(default_paths.root, 'features/pyramid_texture/')\n",
    "# Set up the pyramid\n",
    "compute_features = False\n",
    "_fmaps_fn = texture_statistics_pyramid.steerable_pyramid_extractor(pyr_height = n_sf, n_ori = n_ori)\n",
    "# Initialize the \"texture\" model which builds on first level feature maps\n",
    "_feature_extractor = texture_statistics_pyramid.texture_feature_extractor(_fmaps_fn,sample_batch_size=sample_batch_size, \\\n",
    "                              subject=subject, feature_types_exclude=feature_types_exclude, n_prf_sd_out=n_prf_sd_out,\\\n",
    "                              aperture=aperture, do_varpart = False, \\\n",
    "                              group_all_hl_feats = group_all_hl_feats, compute_features = compute_features, \\\n",
    "                              do_pca_hl = do_pca_pyr_hl, min_pct_var = min_pct_var, max_pc_to_retain = max_pc_to_retain, \\\n",
    "                                                                          device=device)\n",
    "feature_info = [_feature_extractor.feature_column_labels, _feature_extractor.feature_types_include]\n",
    "\n",
    "map_resolution = 227\n",
    "_feature_extractor2 = sketch_token_features.sketch_token_feature_extractor(subject, device, map_resolution=map_resolution, \\\n",
    "                                                                           aperture = aperture, \\\n",
    "                                                     n_prf_sd_out = n_prf_sd_out, \\\n",
    "                               batch_size=sample_batch_size, mult_patch_by_prf=mult_patch_by_prf, do_avg_pool = do_avg_pool,\\\n",
    "                                           do_pca = do_pca_st, min_pct_var = min_pct_var, max_pc_to_retain = max_pc_to_retain)\n",
    "_feature_extractor = merge_features.combined_feature_extractor([_feature_extractor, _feature_extractor2], \\\n",
    "                                                                   [name1,'sketch_tokens'], do_varpart = do_varpart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "5615b632-66cf-489f-b95a-fbffee96a728",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "need to run init_for_fitting first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p7/6vfjxk7s22s4sk08ckdd7xlh0000gn/T/ipykernel_45147/771722112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_feature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_partial_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Box Sync/imStat/code/feature_extraction/texture_statistics_pyramid.py\u001b[0m in \u001b[0;36mget_partial_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to run init_for_fitting first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mn_feature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_group_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: need to run init_for_fitting first"
     ]
    }
   ],
   "source": [
    "_feature_extractor.modules[0].get_partial_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f0f0bd0a-d6b3-4a7b-9466-ff2dc5e18107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[texture_feature_extractor(\n",
       "   (fmaps_fn): steerable_pyramid_extractor()\n",
       " ),\n",
       " sketch_token_feature_extractor()]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_feature_extractor.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ef3031d7-d156-4cf6-b306-449ab4ab7569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = <class 'numpy.float32'>\n",
      "device = cpu:0\n",
      "trn_size = 619 (90.0%)\n",
      "Seeding random number generator: seed is 291125\n",
      "Initializing for fitting\n",
      "Clearing precomputed features from memory.\n",
      "Initializing for fitting\n",
      "Clearing features from memory\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Loading pre-computed features for models [0 - 49] from /Users/margarethenderson/Box Sync/features/pyramid_texture/S1_features_each_prf_4ori_4sf.h5py\n",
      "Took 20.41089 seconds to load file\n",
      "Index into batch for prf 0: 0\n",
      "Size of features array for this image set and prf is:\n",
      "(688, 641)\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Loading pre-computed features from /Users/margarethenderson/Box Sync/features/sketch_tokens/S1_features_each_prf.h5py\n",
      "Took 37.45039 seconds to load file\n",
      "Size of features array for this image set is:\n",
      "(688, 151, 875)\n",
      "Final size of feature matrix is:\n",
      "(688, 151)\n",
      "\n",
      "Fitting version 0 of 3: full_combined_model, \n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Fitting version 1 of 3: just_pyramid_texture, \n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Fitting version 2 of 3: just_sketch_tokens, \n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Getting features for prf 1: [x,y,sigma] is [-0.49 -0.55 0.0400]\n",
      "Index into batch for prf 1: 1\n",
      "Size of features array for this image set and prf is:\n",
      "(688, 641)\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Final size of feature matrix is:\n",
      "(688, 151)\n",
      "\n",
      "Fitting version 0 of 3: full_combined_model, \n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Fitting version 1 of 3: just_pyramid_texture, \n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Fitting version 2 of 3: just_sketch_tokens, \n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "---------------------------------------\n",
      "total time = 96.391770s\n",
      "total throughput = 0.006464s/voxel\n",
      "voxel throughput = 0.002211s/voxel\n",
      "setup throughput = 0.072477s/model\n",
      "Clearing precomputed features from memory.\n",
      "Clearing features from memory\n"
     ]
    }
   ],
   "source": [
    "# add an intercept\n",
    "add_bias=True\n",
    "# determines whether to shuffle before separating the nested heldout data for lambda and param selection. \n",
    "# always using true.\n",
    "shuffle=True \n",
    "best_losses, best_lambdas, best_params, best_train_preds = fit_fwrf_model(trn_stim_data, trn_voxel_data, _feature_extractor, models, \\\n",
    "                                               lambdas, zscore=zscore_features, add_bias=add_bias, \\\n",
    "                                               voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, \\\n",
    "                                               shuffle=shuffle, shuff_rnd_seed=shuff_rnd_seed, device=device, \\\n",
    "                                               dtype=fpX, debug=debug)\n",
    "\n",
    "trn_voxel_data_pred = best_train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "fdf49dc3-d49e-45a6-a759-65bf99db027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing precomputed features from memory.\n",
      "Clearing features from memory\n",
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Loading pre-computed features for models [0 - 49] from /Users/margarethenderson/Box Sync/features/pyramid_texture/S1_features_each_prf_4ori_4sf.h5py\n",
      "Took 17.59987 seconds to load file\n",
      "Index into batch for prf 0: 0\n",
      "Size of features array for this image set and prf is:\n",
      "(62, 641)\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Loading pre-computed features from /Users/margarethenderson/Box Sync/features/sketch_tokens/S1_features_each_prf.h5py\n",
      "Took 39.82360 seconds to load file\n",
      "Size of features array for this image set is:\n",
      "(62, 151, 875)\n",
      "Final size of feature matrix is:\n",
      "(62, 151)\n",
      "Getting features for prf 1: [x,y,sigma] is [-0.49 -0.55 0.0400]\n",
      "Index into batch for prf 1: 1\n",
      "Size of features array for this image set and prf is:\n",
      "(62, 641)\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Final size of feature matrix is:\n",
      "(62, 151)\n",
      "Clearing precomputed features from memory.\n",
      "Clearing features from memory\n",
      "Getting predictions for voxels [0-99] of 14913\n",
      "\n",
      "Evaluating version 0 of 3: full_combined_model\n",
      "Includes 792 features\n",
      "number of zeros:\n",
      "0\n",
      "size of weights is:\n",
      "torch.Size([100, 792])\n",
      "\n",
      "Evaluating version 1 of 3: just_pyramid_texture\n",
      "Includes 641 features\n",
      "number of zeros:\n",
      "0\n",
      "size of weights is:\n",
      "torch.Size([100, 641])\n",
      "\n",
      "Evaluating version 2 of 3: just_sketch_tokens\n",
      "Includes 151 features\n",
      "number of zeros:\n",
      "0\n",
      "size of weights is:\n",
      "torch.Size([100, 151])\n",
      "Getting predictions for voxels [100-199] of 14913\n",
      "\n",
      "Evaluating version 0 of 3: full_combined_model\n",
      "Includes 792 features\n",
      "number of zeros:\n",
      "0\n",
      "size of weights is:\n",
      "torch.Size([100, 792])\n",
      "\n",
      "Evaluating version 1 of 3: just_pyramid_texture\n",
      "Includes 641 features\n",
      "number of zeros:\n",
      "0\n",
      "size of weights is:\n",
      "torch.Size([100, 641])\n",
      "\n",
      "Evaluating version 2 of 3: just_sketch_tokens\n",
      "Includes 151 features\n",
      "number of zeros:\n",
      "0\n",
      "size of weights is:\n",
      "torch.Size([100, 151])\n",
      "Getting predictions for voxels [200-299] of 14913\n"
     ]
    }
   ],
   "source": [
    "val_cc, val_r2, val_voxel_data_pred = validate_fwrf_model(best_params, models, val_voxel_data, val_stim_data, _feature_extractor, \\\n",
    "                               sample_batch_size=sample_batch_size, voxel_batch_size=voxel_batch_size, debug=debug, dtype=fpX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "38aff21f-8b88-4e18-b7a0-ef1c0a390ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets of features that are going into the stacking analysis:\n",
      "['just_pyramid_texture', 'just_sketch_tokens']\n"
     ]
    }
   ],
   "source": [
    "partial_masks, partial_version_names = _feature_extractor.get_partial_versions()\n",
    "partial_versions_use = []\n",
    "hasattr(_feature_extractor, 'module_names')\n",
    "for mm in range(len(_feature_extractor.module_names)):\n",
    "    this_module = np.where([(_feature_extractor.module_names[mm] in pp) for pp in partial_version_names])[0]\n",
    "    if len(this_module)>1:\n",
    "        # this means there are 'subsets' of features within this module that we will want to consider separately.\n",
    "        # so finding just the ones that we want here.\n",
    "        partial_versions_use += list(np.where([(_feature_extractor.module_names[mm] in pp and '_just' in pp and '_no_other_modules' in pp) \\\n",
    "                     for pp in partial_version_names])[0])\n",
    "    else:\n",
    "        partial_versions_use += list(this_module)\n",
    "print('Subsets of features that are going into the stacking analysis:')\n",
    "print([partial_version_names[pp] for pp in partial_versions_use])\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "04e87e3b-f2ed-41aa-8aaa-8a0b2ba51710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets of features that are going into the stacking analysis:\n",
      "['just_pyramid_texture', 'just_sketch_tokens']\n",
      "Running stacking, feat_use is:\n",
      "[0 1]\n",
      "Solving for stacking weights for voxel 0 of 14913\n",
      "Stacking weights matrix is size:\n",
      "(14913, 2)\n",
      "Solving for stacking weights for voxel 1 of 14913\n",
      "Computing performance of stacked models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margarethenderson/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/margarethenderson/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "stack_result, stack_result_lo, partial_models_use = run_stacking(_feature_extractor, \\\n",
    "                     trn_voxel_data, val_voxel_data, trn_voxel_data_pred, val_voxel_data_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "d1f15354-3770-4908-af7f-b255a8ff6a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_models_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50a06d-f06e-45ac-bb6e-a7e6385e8683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "879ee8ba-daa1-4d39-8dea-c7c330ea7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stacking(_feature_extractor, trn_voxel_data, val_voxel_data, trn_voxel_data_pred, val_voxel_data_pred):\n",
    "    \n",
    "    \n",
    "    n_voxels = trn_voxel_data.shape[1]\n",
    "\n",
    "    # To get the \"features\" to use for stacking - i'm using the \"partial models\" that are defined \n",
    "    # by the feature extractor. The first one is the full model, so we don't want to use that - just want \n",
    "    # the ones that include just a subset of the full feature space.\n",
    "    partial_masks, partial_version_names = _feature_extractor.get_partial_versions()\n",
    "    partial_models_use = []\n",
    "    hasattr(_feature_extractor, 'module_names')\n",
    "    for mm in range(len(_feature_extractor.module_names)):\n",
    "        this_module = np.where([(_feature_extractor.module_names[mm] in pp) for pp in partial_version_names])[0]\n",
    "        if len(this_module)>1:\n",
    "            # this means there are 'subsets' of features within this module that we will want to consider separately.\n",
    "            # so finding just the ones that we want here.\n",
    "            partial_models_use += list(np.where([(_feature_extractor.module_names[mm] in pp and '_just' in pp and '_no_other_modules' in pp) \\\n",
    "                         for pp in partial_version_names])[0])\n",
    "        else:\n",
    "            partial_models_use += list(this_module)\n",
    "    print('Subsets of features that are going into the stacking analysis:')\n",
    "    print([partial_version_names[pp] for pp in partial_models_use])\n",
    "\n",
    "    n_feature_groups = len(partial_models_use)\n",
    "\n",
    "    # Creating a list where each element is predictions for one of the partial models - these will be \n",
    "    # the 'features' elements input to stacking code.\n",
    "    preds_train = [trn_voxel_data_pred[:,:,pp].T for pp in partial_models_use]\n",
    "    preds_val = [val_voxel_data_pred[:,:,pp] for pp in partial_models_use]\n",
    "    # Compute trial-wise training errors\n",
    "    # each element of err is [ntrials x nvoxels]\n",
    "    train_err = [trn_voxel_data - trn_voxel_data_pred[:,:,pp].T for pp in partial_models_use]\n",
    "\n",
    "    # Also computing the performance of each of the partial versions on training set data.\n",
    "    # this is sort of a sanity check that things are working, since the performance of the partial models\n",
    "    # should roughly predict what the stacking weights will be.\n",
    "    train_r2 = np.array([get_r2(trn_voxel_data, trn_voxel_data_pred[:,:,pp].T, axis=0) \\\n",
    "                         for pp in range(len(partial_version_names))]).T\n",
    "    train_r2 = np.nan_to_num(train_r2)\n",
    "    train_cc = np.array([get_corrcoef(trn_voxel_data, trn_voxel_data_pred[:,:,pp].T, axis=0) \\\n",
    "                         for pp in range(len(partial_version_names))]).T\n",
    "    train_cc = np.nan_to_num(train_cc)\n",
    "\n",
    "    # First running stacking w all features included\n",
    "    feat_use = np.arange(0,n_feature_groups)\n",
    "    # Stack result will be a tuple including the stacking weights, performance.\n",
    "    stack_result = stacked_core(feat_use, train_err, train_data=trn_voxel_data,\\\n",
    "                     val_data = val_voxel_data, preds_train = preds_train, preds_val = preds_val,\\\n",
    "                     debug=debug);\n",
    "\n",
    "    # Then going to repeat it leaving out one feature group at a time\n",
    "    # This will only make sense to do there are more than 2 feature groups, otherwise it's just single models.\n",
    "    if n_feature_groups>2:   \n",
    "        stack_result_lo = dict()\n",
    "        for leave_one in range(n_feature_groups):\n",
    "            feat_use_lo = list(copy.deepcopy(feat_use))\n",
    "            feat_use_lo.remove(leave_one)\n",
    "            tmp = stacked_core(feat_use_lo, train_err, train_data=trn_voxel_data,\\\n",
    "                             val_data = val_voxel_data, preds_train = preds_train, preds_val = preds_val,\\\n",
    "                             debug=debug);\n",
    "            stack_result_lo[leave_one] = tmp\n",
    "    else:       \n",
    "        stack_result_lo = None\n",
    "\n",
    "\n",
    "    return stack_result, stack_result_lo, partial_models_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0b6353eb-a5c1-4667-8ec3-226a484ff935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1031163 , -0.08829378,  0.        , ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(stack_result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a03b5ce2-9040-4ed6-8ce7-2be9bac43e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import zscore\n",
    "from numpy.linalg import inv, svd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "import time\n",
    "from scipy.stats import zscore\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "solvers.options[\"show_progress\"] = False\n",
    "\n",
    "def stacked_core(feat_use, train_err, train_data, val_data, preds_train, preds_val, debug=False):\n",
    "    \"\"\"\n",
    "    Compute weights for stacking models (linearly combining predictions of multiple encoding models).\n",
    "    Outputs weights and performance of the stacked model.\n",
    "    Code from Ruogu Lin (modified slightly for this project).\n",
    "    \"\"\"\n",
    "    print('Running stacking, feat_use is:')\n",
    "    print(feat_use)\n",
    "    n_voxels = train_data.shape[1]\n",
    "    n_feature_groups = len(feat_use) # feat use is the sub-set of feature groups to stack.\n",
    "    n_trials_train = train_data.shape[0]\n",
    "    n_trials_val = preds_val[0].shape[0]\n",
    "        \n",
    "    dtype = train_data.dtype\n",
    "    stacked_pred_train = np.full(fill_value=0, shape=(n_trials_train, n_voxels), dtype=dtype)\n",
    "    stacked_pred_val = np.full(fill_value=0, shape=(n_trials_val, n_voxels), dtype=dtype)\n",
    "\n",
    "    # calculate error matrix for stacking\n",
    "    P = np.zeros((n_voxels, n_feature_groups, n_feature_groups))\n",
    "    idI = 0\n",
    "    for i in feat_use:\n",
    "        idJ = 0\n",
    "        for j in feat_use:\n",
    "            # err is the trialwise, voxelwise, error for each model.\n",
    "            # P will store the summed products of the error for each pair of models \n",
    "            # (if i=j, then it's the summed squared error).\n",
    "            P[:, idI, idJ] = np.mean(train_err[i] * train_err[j], 0)\n",
    "            idJ += 1\n",
    "        idI += 1\n",
    "\n",
    "    idI = 0\n",
    "    idJ = 0\n",
    "\n",
    "    # PROGRAMATICALLY SET THIS FROM THE NUMBER OF FEATURES\n",
    "    q = matrix(np.zeros((n_feature_groups)))\n",
    "    G = matrix(-np.eye(n_feature_groups, n_feature_groups))\n",
    "    h = matrix(np.zeros(n_feature_groups))\n",
    "    A = matrix(np.ones((1, n_feature_groups)))\n",
    "    b = matrix(np.ones(1))\n",
    "\n",
    "    # Stacking weights will be stored here\n",
    "    S = np.zeros((n_voxels, n_feature_groups))\n",
    "\n",
    "    for vv in range(0, n_voxels):\n",
    "        if debug and vv>1:\n",
    "            continue\n",
    "            \n",
    "        print('Solving for stacking weights for voxel %d of %d'%(vv, n_voxels))\n",
    "        PP = matrix(P[vv])\n",
    "        # solve for stacking weights for every voxel\n",
    "        # This essentially is minimizing the quantity x.T @ PP @ x, subject to the constraint that\n",
    "        # the elements of x have to be positive, and have to sum to 1. \n",
    "        # x will be the weights for the stacking model.\n",
    "        # Weights will be dependent on the error of each model individually (this is contained in PP).\n",
    "        S[vv, :] = np.array(solvers.qp(PP, q, G, h, A, b)[\"x\"]).reshape(n_feature_groups,)\n",
    "        if vv==0:\n",
    "            print('Stacking weights matrix is size:')\n",
    "            print(S.shape)\n",
    "            \n",
    "        # Combine the predictions from the individual feature spaces for voxel i\n",
    "        z = np.array([preds_val[feature_j][:, vv] for feature_j in feat_use])\n",
    "        # multiply the predictions by S[vv,:]\n",
    "        stacked_pred_val[:, vv] = np.dot(S[vv, :], z)\n",
    "        \n",
    "        # Same thing for the training trials\n",
    "        z = np.array([preds_train[feature_j][:, vv] for feature_j in feat_use])\n",
    "        stacked_pred_train[:, vv] = np.dot(S[vv, :], z)\n",
    "        \n",
    "    print('Computing performance of stacked models')\n",
    "    # Compute r2 of the stacked model for training data\n",
    "    stacked_r2_train = get_r2(stacked_pred_train, train_data, axis=0)\n",
    "    stacked_cc_train = get_corrcoef(stacked_pred_train, train_data, axis=0)\n",
    "    stacked_r2_train = np.nan_to_num(stacked_r2_train)\n",
    "    stacked_cc_train = np.nan_to_num(stacked_cc_train) \n",
    "    \n",
    "    # And for validation data\n",
    "    stacked_r2_val = get_r2(stacked_pred_val, val_data, axis=0)\n",
    "    stacked_cc_val = get_corrcoef(stacked_pred_val, val_data, axis=0)\n",
    "    stacked_r2_val = np.nan_to_num(stacked_r2_val)\n",
    "    stacked_cc_val = np.nan_to_num(stacked_cc_val) \n",
    "    \n",
    "    return S, stacked_r2_train, stacked_cc_train, stacked_r2_val, stacked_cc_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "57514a75-449e-4150-81ee-17c29f06c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as I\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import numpy_utils, torch_utils, texture_utils\n",
    "\n",
    "\"\"\"\n",
    "General code for fitting a 'feature weighted receptive field' model to fmri data - looping over many candidate pRF \n",
    "models for each voxel, find a set of weights that best predict its responses based on feature space of interest.\n",
    "Can work for many different types of feature spaces, feature extraction implemented with nn.Module.\n",
    "\n",
    "Original source of some of this code is the github repository:\n",
    "https://github.com/styvesg/nsd\n",
    "It was modified by MH to work for this project.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _cofactor_fn_cpu(_x, lambdas):\n",
    "    '''\n",
    "    Generating a matrix needed to solve ridge regression model for each lambda value.\n",
    "    Ridge regression (Tikhonov) solution is :\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    This func will return (X^T*X + I*lambda)^-1 * X^T. \n",
    "    So once we have that, can just multiply by training data (Y) to get weights.\n",
    "    returned size is [nLambdas x nFeatures x nTrials]\n",
    "    This version makes sure that the torch inverse operation is done on the cpu, and in floating point-64 precision.\n",
    "    Otherwise get bad results for small lambda values. This seems to be a torch-specific bug, noted around May 2021.\n",
    "    \n",
    "    '''\n",
    "    device_orig = _x.device\n",
    "    type_orig = _x.dtype\n",
    "    # switch to this specific format which works with inverse\n",
    "    _x = _x.to('cpu').to(torch.float64)\n",
    "    _f = torch.stack([(torch.mm(torch.t(_x), _x) + torch.eye(_x.size()[1], device='cpu', dtype=torch.float64) * l).inverse() for l in lambdas], axis=0) \n",
    "    \n",
    "    # [#lambdas, #feature, #feature] \n",
    "    cof = torch.tensordot(_f, _x, dims=[[2],[1]]) # [#lambdas, #feature, #sample]\n",
    "    \n",
    "    # put back to whatever way it was before, so that we can continue with other operations as usual\n",
    "    return cof.to(device_orig).to(type_orig)\n",
    "\n",
    "\n",
    "\n",
    "def _loss_fn(_cofactor, _vtrn, _xout, _vout):\n",
    "    '''\n",
    "    Calculate loss given \"cofactor\" from cofactor_fn, training data, held-out design matrix, held out data.\n",
    "    returns weights (betas) based on equation\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    also returns loss for these weights w the held out data. SSE is loss func here.\n",
    "    '''\n",
    "\n",
    "    _beta = torch.tensordot(_cofactor, _vtrn, dims=[[2], [0]]) # [#lambdas, #feature, #voxel]\n",
    "    _pred = torch.tensordot(_xout, _beta, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "    _loss = torch.sum(torch.pow(_vout[:,None,:] - _pred, 2), dim=0) # [#lambdas, #voxels]\n",
    "    return _beta, _loss\n",
    "\n",
    "\n",
    "\n",
    "def fit_fwrf_model(images, voxel_data, _feature_extractor, prf_models, lambdas, \\\n",
    "                   zscore=False, add_bias=False, voxel_batch_size=100, holdout_size=100, \\\n",
    "                       shuffle=True, shuff_rnd_seed=0, device=None, dtype=np.float32, debug=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Solve for encoding model weights using ridge regression.\n",
    "    Inputs:\n",
    "        images: the training images, [n_trials x 1 x height x width]\n",
    "            OR for models where features were pre-computed, this is a list of indices [n_trials,] into the 10,000 long feature array.\n",
    "        voxel_data: the training voxel data, [n_trials x n_voxels]\n",
    "        _feature_extractor_fn: module that maps from images to model features\n",
    "        prf_models: the list of possible pRFs to test, columns are [x, y, sigma]\n",
    "        lambdas: ridge lambda parameters to test\n",
    "        zscore: want to zscore each column of feature matrix before fitting?\n",
    "        add_bias: add a column of ones to feature matrix, for an additive bias?\n",
    "        voxel_batch_size: how many voxels to use at a time for model fitting\n",
    "        holdout_size: how many training trials to hold out for computing loss/lambda selection?\n",
    "        shuffle: do we shuffle training data order before holding trials out?      \n",
    "        shuff_rnd_seed: if we do shuffle training data (shuffle=True), what random seed to use? if zero, choose a new random seed in this code.\n",
    "        device: what device to use? cpu/cuda\n",
    "        debug: want to run a shortened version of this, to test it?\n",
    "    Outputs:\n",
    "        best_losses: loss value for each voxel (with best pRF and best lambda), eval on held out set\n",
    "        best_lambdas: best lambda for each voxel (chosen based on loss w held out set)\n",
    "        best_params: \n",
    "            [0] best pRF for each voxel [x,y,sigma]\n",
    "            [1] best weights for each voxel/feature\n",
    "            [2] if add_bias=True, best bias value for each voxel\n",
    "            [3] if zscore=True, the mean of each feature before z-score\n",
    "            [4] if zscore=True, the std of each feature before z-score\n",
    "            [5] index of the best pRF for each voxel (i.e. index of row in \"prf_models\")\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device=torch.device('cpu:0')\n",
    "\n",
    "    print ('dtype = %s' % dtype)\n",
    "    print ('device = %s' % device)\n",
    "\n",
    "    n_trials = len(images)\n",
    "    n_prfs = len(prf_models)\n",
    "    n_voxels = voxel_data.shape[1]   \n",
    "\n",
    "    # Get train/holdout splits.\n",
    "    # Held-out data here is used for lamdba selection.\n",
    "    # This is the inner part of nested cross-validation; there is another portion of data ('val') which never enters this function.\n",
    "    trn_size = n_trials - holdout_size\n",
    "    assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "    print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "    order = np.arange(len(voxel_data), dtype=int)\n",
    "    if shuffle:\n",
    "        if shuff_rnd_seed==0:\n",
    "            print('Computing a new random seed')\n",
    "            shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "        print('Seeding random number generator: seed is %d'%shuff_rnd_seed)\n",
    "        np.random.seed(shuff_rnd_seed)\n",
    "        np.random.shuffle(order)\n",
    "        \n",
    "    images = images[order]\n",
    "    voxel_data_shuff = copy.deepcopy(voxel_data)\n",
    "    voxel_data_shuff = voxel_data_shuff[order]  \n",
    "    trn_data = voxel_data_shuff[:trn_size]\n",
    "    out_data = voxel_data_shuff[trn_size:]\n",
    "\n",
    "    \n",
    "    # Here is where any model-specific additional initialization steps are done\n",
    "    # Includes initializing pca params arrays, if doing pca\n",
    "    if len(images.shape)>1:\n",
    "        image_size = images.shape[2:4]\n",
    "    else:\n",
    "        image_size = None\n",
    "    _feature_extractor.init_for_fitting(image_size, prf_models, dtype)\n",
    "    max_features = _feature_extractor.max_features\n",
    "\n",
    "    # Decide whether to do any \"partial\" versions of the models (leaving out subsets of features)\n",
    "    # Purpose is for variance partition\n",
    "    masks, partial_version_names = _feature_extractor.get_partial_versions()\n",
    "    n_partial_versions = len(partial_version_names) # will be one if skipping varpart\n",
    "    if add_bias:\n",
    "        masks = np.concatenate([masks, np.ones([masks.shape[0],1])], axis=1) # always include intercept \n",
    "    masks = np.transpose(masks)\n",
    "    # masks is [n_features_total (including intercept) x n_partial_versions]\n",
    "\n",
    "    # Initialize arrays to store model fitting params\n",
    "    best_w_params = np.zeros(shape=(n_voxels, max_features ,n_partial_versions), dtype=dtype)\n",
    "    best_prf_models = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)   \n",
    "    best_lambdas = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)\n",
    "    best_losses = np.full(fill_value=np.inf, shape=(n_voxels,n_partial_versions), dtype=dtype)\n",
    "\n",
    "    # Initialize arrays to store the trial-wise predictions (need these for stacking)\n",
    "    # Note that this is all training set trials - including the held out trials.\n",
    "    best_train_preds = np.zeros(shape=(n_voxels, n_trials, n_partial_versions), dtype=dtype)\n",
    "\n",
    "    # Additional params that are optional\n",
    "    if add_bias:\n",
    "        best_w_params = np.concatenate([best_w_params, np.zeros(shape=(n_voxels,1,n_partial_versions), dtype=dtype)], axis=1)\n",
    "\n",
    "    if zscore:\n",
    "        features_mean = np.zeros(shape=(n_voxels, max_features), dtype=dtype)\n",
    "        features_std  = np.zeros(shape=(n_voxels, max_features), dtype=dtype)\n",
    "    else:\n",
    "        features_mean = None\n",
    "        features_std = None\n",
    "\n",
    "    start_time = time.time()\n",
    "    vox_loop_time = 0\n",
    "\n",
    "    print ('---------------------------------------\\n')\n",
    "    \n",
    "    with torch.no_grad(): # make sure local gradients are off to save memory\n",
    "        \n",
    "        # Looping over prf_models (here prf_models are different spatial RF definitions)\n",
    "        for m,(x,y,sigma) in enumerate(prf_models):\n",
    "            if debug and m>1:\n",
    "                break\n",
    "                \n",
    "            print('\\nGetting features for prf %d: [x,y,sigma] is [%.2f %.2f %.4f]'%(m, prf_models[m,0],  prf_models[m,1],  prf_models[m,2]))\n",
    "\n",
    "            t = time.time()            \n",
    "\n",
    "            # Get features for the desired pRF, across all trn set image  \n",
    "            # Features is size [ntrials x nfeatures]\n",
    "            # nfeatures may be less than max_features, because max_features is the largest number possible for any pRF.\n",
    "            # feature_inds_defined is length max_features, and tells which of the features in max_features are includes in features.\n",
    "            features, feature_inds_defined = _feature_extractor(images, (x,y,sigma), m, fitting_mode=True)\n",
    "            features = features.detach().cpu().numpy() \n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "\n",
    "            n_features_actual = features.shape[1]\n",
    "            \n",
    "            if zscore:  \n",
    "                features_m = np.mean(features, axis=0, keepdims=True) #[:trn_size]\n",
    "                features_s = np.std(features, axis=0, keepdims=True) + 1e-6          \n",
    "                features -= features_m\n",
    "                features /= features_s    \n",
    "\n",
    "            if add_bias:\n",
    "                features = np.concatenate([features, np.ones(shape=(len(features), 1), dtype=dtype)], axis=1)\n",
    "                feature_inds_defined = np.concatenate((feature_inds_defined, [True]), axis=0)\n",
    "                \n",
    "            trn_features = features[:trn_size,:]\n",
    "            out_features = features[trn_size:,:]\n",
    "            \n",
    "            \n",
    "            # Going to keep track of whether current prf is better than running best, for each voxel.\n",
    "            # This is for the full model only.\n",
    "            # Will use this to make sure for each partial model, we end up saving the params for the prf that was best w full model.\n",
    "            full_model_improved = np.zeros((n_voxels,),dtype=bool)\n",
    "\n",
    "            # Looping over versions of model w different features set to zero (variance partition)\n",
    "            for pp in range(n_partial_versions):\n",
    "\n",
    "                print('\\nFitting version %d of %d: %s, '%(pp, n_partial_versions, partial_version_names[pp]))\n",
    "\n",
    "                # nonzero_inds_full is length max_features (or max_features+1 if bias=True)\n",
    "                # same size as the final params matrices will be.\n",
    "                nonzero_inds_full = np.logical_and(masks[:,pp], feature_inds_defined)             \n",
    "                # nonzero_inds_full is restricted to just indices that are defined for this prf - ie same size as features.\n",
    "                nonzero_inds_short = masks[feature_inds_defined,pp]==1\n",
    "        \n",
    "                # Send matrices to gpu    \n",
    "                _xtrn = torch_utils._to_torch(trn_features[:, nonzero_inds_short], device=device)\n",
    "                _xout = torch_utils._to_torch(out_features[:, nonzero_inds_short], device=device)   \n",
    "\n",
    "                # Do part of the matrix math involved in ridge regression optimization out of the loop, \n",
    "                # because this part will be same for all the voxels.\n",
    "                _cof = _cofactor_fn_cpu(_xtrn, lambdas = lambdas) \n",
    "\n",
    "                # Now looping over batches of voxels (only reason is because can't store all in memory at same time)\n",
    "                vox_start = time.time()\n",
    "                vi=-1\n",
    "                for rv,lv in numpy_utils.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "                    vi=vi+1\n",
    "                    sys.stdout.write('\\rfitting model %4d of %-4d, voxels [%6d:%-6d] of %d' % (m, n_prfs, rv[0], rv[-1], n_voxels))\n",
    "\n",
    "                    # Send matrices to gpu\n",
    "                    _vtrn = torch_utils._to_torch(trn_data[:,rv], device=device)\n",
    "                    _vout = torch_utils._to_torch(out_data[:,rv], device=device)\n",
    "\n",
    "                    # Here is where optimization happens - relatively simple matrix math inside loss fn.\n",
    "                    _betas, _loss = _loss_fn(_cof, _vtrn, _xout, _vout) #   [#lambda, #feature, #voxel, ], [#lambda, #voxel]\n",
    "                    \n",
    "                    # Get trial-by-trial predictions for each training set trial (need for stacking)\n",
    "                    _pred_train = torch.tensordot(_xtrn, _betas, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "                    _pred_out = torch.tensordot(_xout, _betas, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "                    pred_train = torch_utils.get_value(_pred_train)\n",
    "                    pred_out = torch_utils.get_value(_pred_out)\n",
    "                    # Going to combine the training and held out trials and re-create their original order here.\n",
    "                    preds_all_shuffled = np.concatenate((pred_train, pred_out), axis=0)\n",
    "                    preds_all_origorder = unshuffle(preds_all_shuffled, order) # [#samples x lambdas x voxels]\n",
    "    \n",
    "                    # Now have a set of weights (in betas) and a loss value for every voxel and every lambda. \n",
    "                    # goal is then to choose for each voxel, what is the best lambda and what weights went with that lambda.\n",
    "\n",
    "                    # choose best lambda value and the loss that went with it.\n",
    "                    _loss_values, _lambda_index = torch.min(_loss, dim=0)\n",
    "                    loss_values, lambda_index = torch_utils.get_value(_loss_values), torch_utils.get_value(_lambda_index)\n",
    "                    betas = torch_utils.get_value(_betas)\n",
    "                    pred = torch_utils.get_value(_pred)\n",
    "\n",
    "                    if pp==0:\n",
    "\n",
    "                        # comparing this loss to the other prf_models for each voxel (e.g. the other RF position/sizes)\n",
    "                        assert(partial_version_names[pp]=='full_model' or partial_version_names[pp]=='full_combined_model')               \n",
    "                        imp = loss_values<best_losses[rv,pp]\n",
    "                        full_model_improved[rv] = imp\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # for the partial models we don't actually care which was best for the partial model itself,\n",
    "                        # just care what was best for the full model\n",
    "                        imp = full_model_improved[rv]\n",
    "\n",
    "\n",
    "                    if np.sum(imp)>0:\n",
    "\n",
    "                        # for whichever voxels had improvement relative to previous prf_models, save parameters now\n",
    "                        # this means we won't have to save all params for all prf_models, just best.\n",
    "                        arv = np.array(rv)[imp]\n",
    "\n",
    "                        lambda_inds = lambda_index[imp]\n",
    "                        best_lambdas[arv,pp] = lambda_inds\n",
    "                        best_losses[arv,pp] = loss_values[imp]                        \n",
    "                        best_prf_models[arv,pp] = m\n",
    "                        if zscore and pp==0:\n",
    "                            \n",
    "                            # only need to update the mean/std if we're working with the full model, because those will be same for all partial versions.\n",
    "                            fmean_tmp = copy.deepcopy(features_mean[arv,:])\n",
    "                            fstd_tmp = copy.deepcopy(features_std[arv,:])\n",
    "                            fmean_tmp[:,nonzero_inds_full[0:-1]] = features_m[0,nonzero_inds_short[0:-1]] # broadcast over updated voxels\n",
    "                            fmean_tmp[:,~nonzero_inds_full[0:-1]] = 0.0\n",
    "                            fstd_tmp[:,nonzero_inds_full[0:-1]] = features_s[0,nonzero_inds_short[0:-1]] # broadcast over updated voxels\n",
    "                            fstd_tmp[:,~nonzero_inds_full[0:-1]] = 0.0\n",
    "                            features_mean[arv,:] = fmean_tmp\n",
    "                            features_std[arv,:] = fstd_tmp\n",
    "                            \n",
    "                        # taking the weights associated with the best lambda value\n",
    "                        # remember that they won't fill entire matrix, rest of values stay at zero\n",
    "                        best_w_tmp = copy.deepcopy(best_w_params[arv,:,pp])\n",
    "                        best_w_tmp[:,nonzero_inds_full] = numpy_utils.select_along_axis(betas[:,:,imp], lambda_inds, run_axis=2, choice_axis=0).T\n",
    "                        best_w_tmp[:,~nonzero_inds_full] = 0.0 # make sure to fill zeros here\n",
    "\n",
    "                        best_w_params[arv,:,pp] = best_w_tmp\n",
    "                        \n",
    "                        # Save the trialwise predictions for all trials in their original order.\n",
    "                        # Choosing predictions from whichever lambda was best.\n",
    "                        best_train_preds[arv,:,pp] = numpy_utils.select_along_axis(preds_all_origorder[:,:,imp], \\\n",
    "                                                                               lambda_inds, run_axis=2, choice_axis=1).T;\n",
    "\n",
    "#                         best_pred_tmp. =\n",
    "                \n",
    "                vox_loop_time += (time.time() - vox_start)\n",
    "                elapsed = (time.time() - vox_start)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    # Print information about how fitting went...\n",
    "    total_time = time.time() - start_time\n",
    "    inv_time = total_time - vox_loop_time\n",
    "    return_params = [best_w_params[:,0:max_features,:],]\n",
    "    if add_bias:\n",
    "        return_params += [best_w_params[:,-1,:],]\n",
    "    else: \n",
    "        return_params += [None,]\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('total throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    print ('voxel throughput = %fs/voxel' % (vox_loop_time / n_voxels))\n",
    "    print ('setup throughput = %fs/model' % (inv_time / n_prfs))\n",
    "    \n",
    "    # This step clears the big feature maps for training data from feature extractor (no longer needed)\n",
    "    _feature_extractor.clear_big_features()\n",
    "    \n",
    "    best_params = [prf_models[best_prf_models],]+return_params+[features_mean, features_std]+[best_prf_models]\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return best_losses, best_lambdas, best_params, best_train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2ed4bca2-1111-4528-80a3-aede16610eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import numpy_utils, torch_utils\n",
    "\n",
    "\n",
    "def validate_fwrf_model(best_params, prf_models, voxel_data, images, _feature_extractor, \\\n",
    "                                   sample_batch_size=100, voxel_batch_size=100, debug=False, dtype=np.float32):\n",
    "    \n",
    "    \"\"\" \n",
    "    Evaluate trained model, leaving out a subset of features at a time.\n",
    "    \"\"\"\n",
    "    \n",
    "    params = best_params\n",
    "    device = _feature_extractor.device\n",
    "    \n",
    "    n_trials, n_voxels = len(images), len(params[0])\n",
    "    n_prfs = prf_models.shape[0]\n",
    "    n_features = params[1].shape[1]  \n",
    "    n_voxels = np.shape(voxel_data)[1]\n",
    "\n",
    "    best_models, weights, bias, features_mt, features_st, best_model_inds = params\n",
    "    masks, partial_version_names = _feature_extractor.get_partial_versions()\n",
    "    masks = np.transpose(masks)    \n",
    "    n_features_max = _feature_extractor.max_features\n",
    "    n_partial_versions = len(partial_version_names)\n",
    "    \n",
    "    # val_cc is the correlation coefficient bw real and predicted responses across trials, for each voxel.\n",
    "    val_cc  = np.zeros(shape=(n_voxels, n_partial_versions), dtype=dtype)\n",
    "    val_r2 = np.zeros(shape=(n_voxels, n_partial_versions), dtype=dtype)\n",
    "\n",
    "    pred_models = np.full(fill_value=0, shape=(n_trials, n_features_max, n_prfs), dtype=dtype)\n",
    "    feature_inds_defined_each_prf = np.full(fill_value=0, shape=(n_features_max, n_prfs), dtype=bool)\n",
    "    \n",
    "    # Saving full trial-by-trial predictions for each voxel, each partial model.\n",
    "    # Need these for stacking.\n",
    "    pred_voxel_data = np.full(fill_value=0, shape=(n_trials, n_voxels, n_partial_versions), dtype=dtype)\n",
    "    \n",
    "    start_time = time.time()    \n",
    "    with torch.no_grad(): # make sure local gradients are off to save memory\n",
    "        \n",
    "        # First gather texture features for all pRFs.\n",
    "        \n",
    "        _feature_extractor.clear_big_features()\n",
    "        \n",
    "        for mm in range(n_prfs):\n",
    "            if mm>1 and debug:\n",
    "                break\n",
    "            print('Getting features for prf %d: [x,y,sigma] is [%.2f %.2f %.4f]'%(mm, prf_models[mm,0],  prf_models[mm,1],  prf_models[mm,2] ))\n",
    "            # all_feat_concat is size [ntrials x nfeatures]\n",
    "            # nfeatures may be less than n_features_max, because n_features_max is the largest number possible for any pRF.\n",
    "            # feature_inds_defined is length max_features, and tells which of the features in max_features are includes in features.\n",
    "            all_feat_concat, feature_inds_defined = _feature_extractor(images, prf_models[mm,:], mm, fitting_mode=False)\n",
    "            \n",
    "            pred_models[:,feature_inds_defined,mm] = torch_utils.get_value(all_feat_concat)\n",
    "            feature_inds_defined_each_prf[:,mm] = feature_inds_defined\n",
    "            \n",
    "        _feature_extractor.clear_big_features()\n",
    "        \n",
    "        vv=-1\n",
    "        ## Looping over voxels here in batches, will eventually go through all.\n",
    "        for rv, lv in numpy_utils.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "            vv=vv+1\n",
    "            print('Getting predictions for voxels [%d-%d] of %d'%(rv[0],rv[-1],n_voxels))\n",
    "\n",
    "            if vv>1 and debug:\n",
    "                break\n",
    "\n",
    "            # Looping over versions of model w different features set to zero (variance partition)\n",
    "            for pp in range(n_partial_versions):\n",
    "\n",
    "                print('\\nEvaluating version %d of %d: %s'%(pp, n_partial_versions, partial_version_names[pp]))\n",
    "\n",
    "                # masks describes the indices of the features that are included in this partial model\n",
    "                # n_features_max in length\n",
    "                features_to_use = masks[:,pp]==1\n",
    "                print('Includes %d features'%np.sum(features_to_use))\n",
    "\n",
    "                # [trials x features x voxels]\n",
    "                features_full = pred_models[:,:,best_model_inds[rv,pp]]\n",
    "                # Take out the relevant features now\n",
    "                features_full = features_full[:,features_to_use,:]\n",
    "                # Note there may be some zeros in this matrix, if we used fewer than the max number of features.\n",
    "                # But they are zero in weight matrix too, so turns out ok.\n",
    "\n",
    "                _weights = torch_utils._to_torch(weights[rv,:,pp], device=device)   \n",
    "                _weights = _weights[:, features_to_use]\n",
    "                _bias = torch_utils._to_torch(bias[rv,pp], device=device)\n",
    "\n",
    "                print('number of zeros:')\n",
    "                print(np.sum(features_full[0,:,0]==0))\n",
    "\n",
    "                print('size of weights is:')\n",
    "                print(_weights.shape)\n",
    "\n",
    "                if features_mt is not None:\n",
    "                    _features_m = torch_utils._to_torch(features_mt[rv,:], device=device)\n",
    "                    _features_m = _features_m[:,features_to_use]\n",
    "                if features_st is not None:\n",
    "                    _features_s = torch_utils._to_torch(features_st[rv,:], device=device)\n",
    "                    _features_s = _features_s[:,features_to_use]\n",
    "\n",
    "                pred_block = np.full(fill_value=0, shape=(n_trials, lv), dtype=dtype)\n",
    "\n",
    "                # Now looping over validation set trials in batches\n",
    "                for rt, lt in numpy_utils.iterate_range(0, n_trials, sample_batch_size):\n",
    "\n",
    "                    _features = torch_utils._to_torch(features_full[rt,:], device=device) # trials x features\n",
    "                    if features_mt is not None:    \n",
    "                        # features_m is [nvoxels x nfeatures] - need [trials x features x voxels]\n",
    "                        _features = _features - torch.tile(torch.unsqueeze(_features_m, dim=0), [_features.shape[0], 1, 1]).moveaxis([1],[2])\n",
    "\n",
    "                    if features_st is not None:\n",
    "                        _features = _features/torch.tile(torch.unsqueeze(_features_s, dim=0), [_features.shape[0], 1, 1]).moveaxis([1],[2])\n",
    "                        # if any entries in std are zero or nan, this gives bad result - fix these now.\n",
    "                        # these bad entries will also be zero in weights, so doesn't matter. just want to avoid nans.\n",
    "                        _features[torch.isnan(_features)] = 0.0 \n",
    "                        _features[torch.isinf(_features)] = 0.0\n",
    "                        \n",
    "                    # features is [#samples, #features, #voxels] - swap dims to [#voxels, #samples, features]\n",
    "                    _features = torch.transpose(torch.transpose(_features, 0, 2), 1, 2)\n",
    "                    # weights is [#voxels, #features]\n",
    "                    # _r will be [#voxels, #samples, 1] - then [#samples, #voxels]\n",
    "\n",
    "                    _r = torch.squeeze(torch.bmm(_features, torch.unsqueeze(_weights, 2)), dim=2).t() \n",
    "\n",
    "                    if _bias is not None:\n",
    "                        _r = _r + torch.tile(torch.unsqueeze(_bias, 0), [_r.shape[0],1])\n",
    "\n",
    "                    pred_block[rt] = torch_utils.get_value(_r) \n",
    "                \n",
    "                # Making sure to save these so that we can get stacking performance later.\n",
    "                pred_voxel_data[:,rv,pp] = pred_block\n",
    "                \n",
    "                # Now for this batch of voxels and this partial version of the model, measure performance.\n",
    "                val_cc[rv,pp] = get_corrcoef(voxel_data[:,rv], pred_block, axis=0)\n",
    "                val_r2[rv,pp] = get_r2(voxel_data[:,rv], pred_block, axis=0)\n",
    "\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    # any nans become zeros here.\n",
    "    val_cc = np.nan_to_num(val_cc)\n",
    "    val_r2 = np.nan_to_num(val_r2) \n",
    "    \n",
    "    return val_cc, val_r2, pred_voxel_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "1dd0b9b7-6537-41b6-aa8d-e9c356141529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving for stacking weights for voxel 0 of 14913\n",
      "Stacking weights matrix is size:\n",
      "(14913, 2)\n",
      "Solving for stacking weights for voxel 1 of 14913\n",
      "Computing performance of stacked models\n"
     ]
    }
   ],
   "source": [
    "train_data=trn_voxel_data; val_data = val_voxel_data;\n",
    "preds_val = [val_voxel_data_pred[:,:,pp] for pp in partial_models_use]\n",
    "a = stacked_core(feat_use, err, train_data, val_data, preds_train, preds_val, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d9c0789d-12d8-4dc8-b57c-1b90b17ec5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a, tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290ffc5-4b1b-4f85-b7bb-c3847e08542e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e0fa5cb7-1342-4823-9cc2-f951778a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pred, stacked_train_r2s_fold, S_average, S = stacked_core(\n",
    "    n_voxels,\n",
    "    feat_use,\n",
    "    err,\n",
    "    train_data,\n",
    "    preds_test,\n",
    "    preds_train,\n",
    "    test_ind,\n",
    "    ind_num,\n",
    "    stacked_pred,\n",
    "    stacked_train_r2s_fold,\n",
    "    S_average,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "13cb94f9-52df-4a8d-8b9b-bd45527d0d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04497046e-06, 9.99998955e-01])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fdde8076-54fa-457b-85fd-a4f0a1cca3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04497046e-06, 9.99998955e-01])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_average[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ce8b9683-9523-4237-98d6-7029ee17a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(feat_use)\n",
    "# calculate error matrix for stacking\n",
    "P = np.zeros((n_voxels, n_features, n_features))\n",
    "idI = 0\n",
    "for i in feat_use:\n",
    "    idJ = 0\n",
    "    for j in feat_use:\n",
    "        # err is the trialwise, voxelwise, error for each model.\n",
    "        # P will store the summed products of the error for each pair of models \n",
    "        # (if i=j, then it's the summed squared error).\n",
    "        P[:, idI, idJ] = np.mean(err[i] * err[j], 0)\n",
    "        idJ += 1\n",
    "    idI += 1\n",
    "\n",
    "idI = 0\n",
    "idJ = 0\n",
    "\n",
    "# PROGRAMATICALLY SET THIS FROM THE NUMBER OF FEATURES\n",
    "q = matrix(np.zeros((n_features)))\n",
    "G = matrix(-np.eye(n_features, n_features))\n",
    "h = matrix(np.zeros(n_features))\n",
    "A = matrix(np.ones((1, n_features)))\n",
    "b = matrix(np.ones(1))\n",
    "\n",
    "S = np.zeros((n_voxels, n_features))\n",
    "\n",
    "stacked_pred_train = np.zeros_like(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9a11b972-9938-4499-bce0-1222e61d9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "PP = matrix(P[i])\n",
    "# solve for stacking weights for every voxel\n",
    "# This essentially is minimizing the quantity x.T @ PP @ x, subject to the constraint that\n",
    "# the elements of x have to be positive, and have to sum to 1. \n",
    "# x will be the weights for the stacking model.\n",
    "# Weights will be dependent on the error of each model individually (this is contained in PP).\n",
    "S[i, :] = np.array(solvers.qp(PP, q, G, h, A, b)[\"x\"]).reshape(\n",
    "    n_features,\n",
    ")\n",
    "# Combine the predictions from the individual feature spaces for voxel i\n",
    "z = np.array([preds_test[feature_j][test_ind, i] for feature_j in feat_use])\n",
    "# multiply the predictions by S[i,:]\n",
    "stacked_pred[test_ind, i] = np.dot(S[i, :], z)\n",
    "# combine the training predictions from the individual feature spaces for voxel i\n",
    "z = np.array([preds_train[feature_j][:, i] for feature_j in feat_use])\n",
    "stacked_pred_train[:, i] = np.dot(S[i, :], z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "992884aa-7d92-4530-8475-5290471cabb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04497046e-06, 9.99998955e-01])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "36ec7980-9629-4416-b17e-18444d4a3b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 14913)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2fc44fdb-dc2b-4b76-a23d-09775786d09b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p7/6vfjxk7s22s4sk08ckdd7xlh0000gn/T/ipykernel_45147/432015394.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "16ef1020-98f9-44f4-a765-4776e62090b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margarethenderson/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/margarethenderson/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Compute r2 of the stacked model for training data\n",
    "stacked_r2_train = score_f(stacked_pred_train, train_data)\n",
    "stacked_cc_train = np.zeros_like(stacked_r2_train)\n",
    "for vv in range(n_voxels):\n",
    "    stacked_cc_train[vv] = np.corrcoef(stacked_pred_train[:,vv], trn_voxel_data[:,vv])[0,1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ec2b2120-805b-44f9-b940-660a6a176e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.random.normal(0,1,[3,10]).T\n",
    "actual = np.random.normal(0,1,[3,10]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c7e96625-4e4f-4fc4-b1f2-ca62d68f8198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.53964502])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate r2 for this fit.\n",
    "axis=0\n",
    "\n",
    "ssres = np.sum(np.power((predicted - actual),2), axis=axis);\n",
    "sstot = np.sum(np.power((actual - np.mean(actual)),2), axis=axis);\n",
    "r2 = 1-(ssres/sstot)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "92757ac1-896d-4b3a-9946-cfde07099f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_r2(actual,predicted,axis=0):\n",
    "    \"\"\"\n",
    "    This computes the coefficient of determination (R2).\n",
    "    Specify which axis to compute along (i.e. the trials/samples dimension)\n",
    "    \"\"\"\n",
    "    ssres = np.sum(np.power((predicted - actual),2), axis=axis);\n",
    "    sstot = np.sum(np.power((actual - np.mean(actual)),2), axis=axis);\n",
    "    r2 = 1-(ssres/sstot)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "def get_corrcoef(actual,predicted,axis=0,dtype=np.float32):\n",
    "    \"\"\"\n",
    "    This computes the linear correlation coefficient.\n",
    "    Specify which axis to compute along (i.e. the trials/samples dimension)\n",
    "    Assume input is 2D.\n",
    "    \"\"\"\n",
    "    assert(len(actual.shape)==2)\n",
    "    if axis==1:\n",
    "        actual = actual.T\n",
    "        predicted = predicted.T\n",
    "    vals_cc = np.full(fill_value=0, shape=(actual.shape[1],), dtype=dtype)\n",
    "    for vv in range(actual.shape[1]):\n",
    "        vals_cc[vv] = np.corrcoef(actual[:,vv], predicted[:,vv])[0,1] \n",
    "    return vals_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6720637-0879-4b94-bcb9-3e54c62ce647",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=trn_stim_data;\n",
    "voxel_data = trn_voxel_data;\n",
    "prf_models = models;\n",
    "zscore=zscore_features; add_bias=add_bias;\n",
    "dtype=fpX;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4eb5a437-d47d-44b3-9717-2634fa8ead19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = <class 'numpy.float32'>\n",
      "device = cpu:0\n",
      "trn_size = 619 (90.0%)\n",
      "Seeding random number generator: seed is 291125\n",
      "Initializing for fitting\n",
      "Clearing precomputed features from memory.\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if device is None:\n",
    "    device=torch.device('cpu:0')\n",
    "\n",
    "print ('dtype = %s' % dtype)\n",
    "print ('device = %s' % device)\n",
    "\n",
    "n_trials = len(images)\n",
    "n_prfs = len(prf_models)\n",
    "n_voxels = voxel_data.shape[1]   \n",
    "\n",
    "# Get train/holdout splits.\n",
    "# Held-out data here is used for lamdba selection.\n",
    "# This is the inner part of nested cross-validation; there is another portion of data ('val') which never enters this function.\n",
    "trn_size = n_trials - holdout_size\n",
    "assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "order = np.arange(len(voxel_data), dtype=int)\n",
    "if shuffle:\n",
    "    if shuff_rnd_seed==0:\n",
    "        print('Computing a new random seed')\n",
    "        shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "    print('Seeding random number generator: seed is %d'%shuff_rnd_seed)\n",
    "    np.random.seed(shuff_rnd_seed)\n",
    "    np.random.shuffle(order)\n",
    "images = images[order]\n",
    "voxel_data = voxel_data[order]  \n",
    "trn_data = voxel_data[:trn_size]\n",
    "out_data = voxel_data[trn_size:]\n",
    "\n",
    "\n",
    "# Here is where any model-specific additional initialization steps are done\n",
    "# Includes initializing pca params arrays, if doing pca\n",
    "if len(images.shape)>1:\n",
    "    image_size = images.shape[2:4]\n",
    "else:\n",
    "    image_size = None\n",
    "_feature_extractor.init_for_fitting(image_size, prf_models, dtype)\n",
    "max_features = _feature_extractor.max_features\n",
    "\n",
    "# Decide whether to do any \"partial\" versions of the models (leaving out subsets of features)\n",
    "# Purpose is for variance partition\n",
    "masks, partial_version_names = _feature_extractor.get_partial_versions()\n",
    "n_partial_versions = len(partial_version_names) # will be one if skipping varpart\n",
    "if add_bias:\n",
    "    masks = np.concatenate([masks, np.ones([masks.shape[0],1])], axis=1) # always include intercept \n",
    "masks = np.transpose(masks)\n",
    "# masks is [n_features_total (including intercept) x n_partial_versions]\n",
    "\n",
    "# Initialize arrays to store model fitting params\n",
    "best_w_params = np.zeros(shape=(n_voxels, max_features ,n_partial_versions), dtype=dtype)\n",
    "best_prf_models = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)   \n",
    "best_lambdas = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)\n",
    "best_losses = np.full(fill_value=np.inf, shape=(n_voxels,n_partial_versions), dtype=dtype)\n",
    "\n",
    "# Initialize arrays to store the trial-wise predictions (need these for stacking)\n",
    "# Note that this is all training set trials - including the held out trials.\n",
    "best_train_preds = np.zeros(shape=(n_voxels, n_trials, n_partial_versions), dtype=dtype)\n",
    "\n",
    "# Additional params that are optional\n",
    "if add_bias:\n",
    "    best_w_params = np.concatenate([best_w_params, np.zeros(shape=(n_voxels,1,n_partial_versions), dtype=dtype)], axis=1)\n",
    "\n",
    "if zscore:\n",
    "    features_mean = np.zeros(shape=(n_voxels, max_features), dtype=dtype)\n",
    "    features_std  = np.zeros(shape=(n_voxels, max_features), dtype=dtype)\n",
    "else:\n",
    "    features_mean = None\n",
    "    features_std = None\n",
    "\n",
    "start_time = time.time()\n",
    "vox_loop_time = 0\n",
    "\n",
    "print ('---------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fae64fca-1124-4ec9-9fef-3f65e15f3207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Loading pre-computed features for models [0 - 49] from /Users/margarethenderson/Box Sync/features/pyramid_texture/S1_features_each_prf_4ori_4sf.h5py\n",
      "Took 19.84153 seconds to load file\n",
      "Index into batch for prf 0: 0\n",
      "Size of features array for this image set and prf is:\n",
      "(688, 641)\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Final size of features concatenated is [688 x 641]\n"
     ]
    }
   ],
   "source": [
    "# Looping over prf_models (here prf_models are different spatial RF definitions)\n",
    "m=0\n",
    "(x,y,sigma) = prf_models[m]\n",
    " \n",
    "print('\\nGetting features for prf %d: [x,y,sigma] is [%.2f %.2f %.4f]'%(m, prf_models[m,0],  prf_models[m,1],  prf_models[m,2]))\n",
    "\n",
    "t = time.time()            \n",
    "\n",
    "# Get features for the desired pRF, across all trn set image  \n",
    "# Features is size [ntrials x nfeatures]\n",
    "# nfeatures may be less than max_features, because max_features is the largest number possible for any pRF.\n",
    "# feature_inds_defined is length max_features, and tells which of the features in max_features are includes in features.\n",
    "features, feature_inds_defined = _feature_extractor(images, (x,y,sigma), m, fitting_mode=True)\n",
    "features = features.detach().cpu().numpy() \n",
    "\n",
    "elapsed = time.time() - t\n",
    "\n",
    "n_features_actual = features.shape[1]\n",
    "\n",
    "if zscore:  \n",
    "    features_m = np.mean(features, axis=0, keepdims=True) #[:trn_size]\n",
    "    features_s = np.std(features, axis=0, keepdims=True) + 1e-6          \n",
    "    features -= features_m\n",
    "    features /= features_s    \n",
    "\n",
    "if add_bias:\n",
    "    features = np.concatenate([features, np.ones(shape=(len(features), 1), dtype=dtype)], axis=1)\n",
    "    feature_inds_defined = np.concatenate((feature_inds_defined, [True]), axis=0)\n",
    "\n",
    "trn_features = features[:trn_size,:]\n",
    "out_features = features[trn_size:,:]\n",
    "\n",
    "\n",
    "# Going to keep track of whether current prf is better than running best, for each voxel.\n",
    "# This is for the full model only.\n",
    "# Will use this to make sure for each partial model, we end up saving the params for the prf that was best w full model.\n",
    "full_model_improved = np.zeros((n_voxels,),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04607f53-0a30-4239-82ea-3a53b4c9a1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78b17bc6-017d-4b8a-9c13-99340a1949da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting version 0 of 3: full_model, \n",
      "fitting model    0 of 875 , voxels [     0:99    ] of 14913"
     ]
    }
   ],
   "source": [
    "pp=0\n",
    "print('\\nFitting version %d of %d: %s, '%(pp, n_partial_versions, partial_version_names[pp]))\n",
    "\n",
    "# nonzero_inds_full is length max_features (or max_features+1 if bias=True)\n",
    "# same size as the final params matrices will be.\n",
    "nonzero_inds_full = np.logical_and(masks[:,pp], feature_inds_defined)             \n",
    "# nonzero_inds_full is restricted to just indices that are defined for this prf - ie same size as features.\n",
    "nonzero_inds_short = masks[feature_inds_defined,pp]==1\n",
    "\n",
    "# Send matrices to gpu    \n",
    "_xtrn = torch_utils._to_torch(trn_features[:, nonzero_inds_short], device=device)\n",
    "_xout = torch_utils._to_torch(out_features[:, nonzero_inds_short], device=device)   \n",
    "\n",
    "# Do part of the matrix math involved in ridge regression optimization out of the loop, \n",
    "# because this part will be same for all the voxels.\n",
    "_cof = _cofactor_fn_cpu(_xtrn, lambdas = lambdas) \n",
    "\n",
    "# Now looping over batches of voxels (only reason is because can't store all in memory at same time)\n",
    "vox_start = time.time()\n",
    "vi=-1\n",
    "rv = np.arange(0,voxel_batch_size)\n",
    "lv = len(rv)\n",
    "#                 for rv,lv in numpy_utils.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "vi=vi+1\n",
    "sys.stdout.write('\\rfitting model %4d of %-4d, voxels [%6d:%-6d] of %d' % (m, n_prfs, rv[0], rv[-1], n_voxels))\n",
    "\n",
    "# Send matrices to gpu\n",
    "_vtrn = torch_utils._to_torch(trn_data[:,rv], device=device)\n",
    "_vout = torch_utils._to_torch(out_data[:,rv], device=device)\n",
    "\n",
    "# Here is where optimization happens - relatively simple matrix math inside loss fn.\n",
    "_betas, _loss = _loss_fn(_cof, _vtrn, _xout, _vout) #[#lambda, #feature, #voxel], [#lambda, #voxel]\n",
    "    \n",
    "# Now have a set of weights (in betas) and a loss value for every voxel and every lambda. \n",
    "# goal is then to choose for each voxel, what is the best lambda and what weights went with that lambda.\n",
    "# choose best lambda value and the loss that went with it.\n",
    "_loss_values, _lambda_index = torch.min(_loss, dim=0)\n",
    "loss_values, lambda_index = torch_utils.get_value(_loss_values), torch_utils.get_value(_lambda_index)\n",
    "betas = torch_utils.get_value(_betas)\n",
    "\n",
    "# Get trial-by-trial predictions for each training set trial (need for stacking)\n",
    "_pred_train = torch.tensordot(_xtrn, _betas, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "_pred_test = torch.tensordot(_xout, _betas, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "pred_train = torch_utils.get_value(_pred_train)\n",
    "pred_test = torch_utils.get_value(_pred_test)\n",
    "# Going to combine the training and held out trials and re-create their original order here.\n",
    "preds_all_shuffled = np.concatenate((pred_train, pred_test), axis=0)\n",
    "preds_all_origorder = unshuffle(preds_all_shuffled, order) # [#samples x lambdas x voxels]\n",
    " \n",
    "if pp==0:\n",
    "\n",
    "    # comparing this loss to the other prf_models for each voxel (e.g. the other RF position/sizes)\n",
    "    assert(partial_version_names[pp]=='full_model' or partial_version_names[pp]=='full_combined_model')               \n",
    "    imp = loss_values<best_losses[rv,pp]\n",
    "    full_model_improved[rv] = imp\n",
    "\n",
    "else:\n",
    "\n",
    "    # for the partial models we don't actually care which was best for the partial model itself,\n",
    "    # just care what was best for the full model\n",
    "    imp = full_model_improved[rv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "911fa58e-24ef-45d9-ba71-dc332c293afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.sum(imp)>0:\n",
    "\n",
    "    # for whichever voxels had improvement relative to previous prf_models, save parameters now\n",
    "    # this means we won't have to save all params for all prf_models, just best.\n",
    "    arv = np.array(rv)[imp]\n",
    "\n",
    "    lambda_inds = lambda_index[imp]\n",
    "    best_lambdas[arv,pp] = lambda_inds\n",
    "    best_losses[arv,pp] = loss_values[imp]                        \n",
    "    best_prf_models[arv,pp] = m\n",
    "    if zscore and pp==0:\n",
    "\n",
    "        # only need to update the mean/std if we're working with the full model, because those will be same for all partial versions.\n",
    "        fmean_tmp = copy.deepcopy(features_mean[arv,:])\n",
    "        fstd_tmp = copy.deepcopy(features_std[arv,:])\n",
    "        fmean_tmp[:,nonzero_inds_full[0:-1]] = features_m[0,nonzero_inds_short[0:-1]] # broadcast over updated voxels\n",
    "        fmean_tmp[:,~nonzero_inds_full[0:-1]] = 0.0\n",
    "        fstd_tmp[:,nonzero_inds_full[0:-1]] = features_s[0,nonzero_inds_short[0:-1]] # broadcast over updated voxels\n",
    "        fstd_tmp[:,~nonzero_inds_full[0:-1]] = 0.0\n",
    "        features_mean[arv,:] = fmean_tmp\n",
    "        features_std[arv,:] = fstd_tmp\n",
    "\n",
    "    # taking the weights associated with the best lambda value\n",
    "    # remember that they won't fill entire matrix, rest of values stay at zero\n",
    "    best_w_tmp = copy.deepcopy(best_w_params[arv,:,pp])\n",
    "    best_w_tmp[:,nonzero_inds_full] = numpy_utils.select_along_axis(betas[:,:,imp], lambda_inds, run_axis=2, choice_axis=0).T\n",
    "    best_w_tmp[:,~nonzero_inds_full] = 0.0 # make sure to fill zeros here\n",
    "\n",
    "    best_w_params[arv,:,pp] = best_w_tmp\n",
    "    \n",
    "    # Save the trialwise predictions for all trials in their original order.\n",
    "    # Choosing predictions from whichever lambda was best.\n",
    "    best_train_preds[arv,:,pp] = numpy_utils.select_along_axis(preds_all_origorder[:,:,imp], \\\n",
    "                                                           lambda_inds, run_axis=2, choice_axis=1).T;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8cb6669e-4b9a-466a-b1e4-b29e3865fe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 642, 100)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8998bf73-4df7-42e6-8472-68f043f1c3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 9, 100)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all_origorder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7388809b-4341-4d55-b0c8-b6d8f17984b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds_tmp = copy.deepcopy(best_train_preds[arv,:,pp])\n",
    "best_preds_tmp[:,:] = numpy_utils.select_along_axis(preds_all_origorder[:,:,imp], lambda_inds, run_axis=2, choice_axis=1).T;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1de1099f-8df0-45e2-9b26-d587d836a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_preds[arv,:,pp] = numpy_utils.select_along_axis(preds_all_origorder[:,:,imp], \\\n",
    "                                                           lambda_inds, run_axis=2, choice_axis=1).T;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0876b680-b8f3-42a5-bee7-0982c3e6c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 688)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_utils.select_along_axis(preds_all_origorder[:,:,imp], lambda_inds, run_axis=2, choice_axis=1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f7b2527-dff7-46cf-b9d5-f40649226c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 688)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e03f5ad2-2592-41ca-aca5-9ca42d9f25b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14913, 642, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_w_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72052c4c-7a23-430c-9248-545b161cf3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14913, 688, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8acd5491-d3c4-4c09-a295-0c0d28d77dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 9, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all_origorder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b5b1d553-5af1-44b7-9988-31f5df5c2aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 688)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dd9b9ee-f8a5-4e3d-9f83-243c9df3a5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2669742 , 0.26461464, 0.27132496, 0.24727994, 0.16866647,\n",
       "       0.08729514, 0.04442686, 0.02763834, 0.01381715], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[40,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fdf051f-77fa-4700-9c98-f303b48cbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_order = order;\n",
    "original_data = np.arange(0,n_trials);\n",
    "shuffled_data = original_data[shuf_order] # Shuffle the original data\n",
    "unshuffled_data = unshuffle(shuffled_data, order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbe9b9-2b94-4104-98d1-345480b64001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2dc6883-2b8d-4516-996c-761179d4856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unshuffle(shuffled_data, shuffle_order):\n",
    "    # Assumes that first dim of data is what needs to be unshuffled.\n",
    "    \n",
    "    unshuffle_order = np.zeros_like(shuffle_order);\n",
    "    unshuffle_order[shuffle_order] = np.arange(shuffled_data.shape[0])\n",
    "    unshuffled_data = shuffled_data[unshuffle_order] # Unshuffle the shuffled data\n",
    "\n",
    "    return unshuffled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20502ec8-be04-4319-9dbe-1ee3c894f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trial-by-trial predictions for each training set trial.\n",
    "_pred_train = torch.tensordot(_xtrn, _betas, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "_pred_test = torch.tensordot(_xout, _betas, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "pred_train = torch_utils.get_value(_pred_train)\n",
    "pred_test = torch_utils.get_value(_pred_test)\n",
    "\n",
    "# Going to combine the training and held out trials and re-create their original order here.\n",
    "pred_train = trn_data\n",
    "pred_test = out_data\n",
    "preds_all_shuffled = np.concatenate((pred_train, pred_test), axis=0)\n",
    "preds_all_origorder = numpy_utils.unshuffle(preds_all_shuffled, order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52f7e5-557c-4577-9f12-c288d0c6873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3ee849b-8963-4f5f-845f-88ef9a0c7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_size = 11 (13.8%)\n",
      "Seeding random number generator: seed is 291125\n"
     ]
    }
   ],
   "source": [
    "voxel_data = np.random.normal(0,1,(80,4))\n",
    "voxel_data_orig = copy.deepcopy(voxel_data)\n",
    "images = np.random.normal(0,1,(80,6))\n",
    "n_trials = len(images)\n",
    "n_voxels = voxel_data.shape[1]   \n",
    "\n",
    "# Get train/holdout splits.\n",
    "# Held-out data here is used for lamdba selection.\n",
    "# This is the inner part of nested cross-validation; there is another portion of data ('val') which never enters this function.\n",
    "trn_size = n_trials - holdout_size\n",
    "assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "order = np.arange(len(voxel_data), dtype=int)\n",
    "if shuffle:\n",
    "    if shuff_rnd_seed==0:\n",
    "        print('Computing a new random seed')\n",
    "        shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "    print('Seeding random number generator: seed is %d'%shuff_rnd_seed)\n",
    "    np.random.seed(shuff_rnd_seed)\n",
    "    np.random.shuffle(order)\n",
    "images = images[order]\n",
    "voxel_data = voxel_data[order]  \n",
    "trn_data = voxel_data[:trn_size]\n",
    "out_data = voxel_data[trn_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e60f7c8-a41a-4b03-8dc8-03a0b58fe2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e96203e-f623-483c-98e7-64a75fcaa81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.54634801,  2.22595881,  0.19889429, -0.79778817,  1.53375134,\n",
       "       -0.0949584 ,  0.06196644,  0.09437636, -1.414537  , -1.56983386,\n",
       "        0.0660035 ,  0.35398885,  2.34682547,  0.2089229 ,  0.4671567 ,\n",
       "        0.53173037,  1.55089489,  0.30510638,  1.84373332, -0.51093351,\n",
       "       -0.08730406, -0.45746689,  0.7193505 ,  0.44867053,  0.71251256,\n",
       "       -1.10815184,  0.4767032 , -0.13708607, -0.88613917,  0.89895124,\n",
       "        1.73636182, -1.3365064 ,  1.16923248,  0.43083788,  0.74175572,\n",
       "       -0.11780459, -1.91741005,  1.78147399,  0.64809841, -0.91499099,\n",
       "        1.59393034,  0.12575663, -1.18292914,  0.31120017, -3.43065348,\n",
       "        0.1224519 ,  0.48308776, -0.8014592 , -2.84558417,  0.54096982,\n",
       "        1.29339576,  0.32470974,  0.33711501,  0.69027089, -1.63324072,\n",
       "       -0.30328126,  2.50247367, -0.15472073, -1.07030358,  0.14638405,\n",
       "        0.1804376 , -0.35323568, -0.87883493, -1.52475246,  0.02008066,\n",
       "        0.56855626,  0.86329133, -1.25374837,  0.51984632, -0.6278347 ,\n",
       "       -1.17036662,  0.52632311,  0.80060666, -1.08896229, -2.1765615 ,\n",
       "        1.33859763,  0.29790421, -0.88529304, -0.3274347 , -1.58296734])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all_origorder[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b1b36cf-d17e-40d4-a498-93becda0ae84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.54634801,  2.22595881,  0.19889429, -0.79778817,  1.53375134,\n",
       "       -0.0949584 ,  0.06196644,  0.09437636, -1.414537  , -1.56983386,\n",
       "        0.0660035 ,  0.35398885,  2.34682547,  0.2089229 ,  0.4671567 ,\n",
       "        0.53173037,  1.55089489,  0.30510638,  1.84373332, -0.51093351,\n",
       "       -0.08730406, -0.45746689,  0.7193505 ,  0.44867053,  0.71251256,\n",
       "       -1.10815184,  0.4767032 , -0.13708607, -0.88613917,  0.89895124,\n",
       "        1.73636182, -1.3365064 ,  1.16923248,  0.43083788,  0.74175572,\n",
       "       -0.11780459, -1.91741005,  1.78147399,  0.64809841, -0.91499099,\n",
       "        1.59393034,  0.12575663, -1.18292914,  0.31120017, -3.43065348,\n",
       "        0.1224519 ,  0.48308776, -0.8014592 , -2.84558417,  0.54096982,\n",
       "        1.29339576,  0.32470974,  0.33711501,  0.69027089, -1.63324072,\n",
       "       -0.30328126,  2.50247367, -0.15472073, -1.07030358,  0.14638405,\n",
       "        0.1804376 , -0.35323568, -0.87883493, -1.52475246,  0.02008066,\n",
       "        0.56855626,  0.86329133, -1.25374837,  0.51984632, -0.6278347 ,\n",
       "       -1.17036662,  0.52632311,  0.80060666, -1.08896229, -2.1765615 ,\n",
       "        1.33859763,  0.29790421, -0.88529304, -0.3274347 , -1.58296734])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_data_orig[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "758ede01-89f2-4b40-8930-736999b434ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all_shuffled = np.concatenate((pred_train, pred_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bc21552-c7cf-4d74-ab73-258aebbd2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all_origorder = unshuffle(preds_all_shuffled, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58f1355e-d4bf-4b6a-8d34-690d27192b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 9, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all_origorder.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
