{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a724b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4e35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "fpX = np.float32\n",
    "\n",
    "import torch \n",
    "sys.path.append('/user_data/mmhender/imStat/fwrf_code_from_osf/')\n",
    "import src.numpy_utility as pnu\n",
    "from src.file_utility import save_stuff, flatten_dict, embed_dict\n",
    "from src.gabor_feature_extractor import Gaborizer\n",
    "from src.torch_fwrf import get_value, set_value\n",
    "from src.rf_grid import linspace, logspace\n",
    "import src.numpy_utility as pnu\n",
    "from src.file_utility import save_stuff, flatten_dict, embed_dict\n",
    "from src.load_nsd import image_uncolorize_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da14878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b4d04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#device: 1\n",
      "device#: 0\n",
      "device name: GeForce RTX 2080 Ti\n",
      "\n",
      "torch: 1.8.1+cu111\n",
      "cuda:  11.1\n",
      "cudnn: 8005\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print ('#device:', torch.cuda.device_count())\n",
    "print ('device#:', torch.cuda.current_device())\n",
    "print ('device name:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "torch.manual_seed(time.time())\n",
    "device = torch.device(\"cuda:0\") #cuda\n",
    "torch.backends.cudnn.enabled=True\n",
    "\n",
    "print ('\\ntorch:', torch.__version__)\n",
    "print ('cuda: ', torch.version.cuda)\n",
    "print ('cudnn:', torch.backends.cudnn.version())\n",
    "print ('dtype:', torch.get_default_dtype())\n",
    "#torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b86e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_root = \"/lab_data/tarrlab/common/datasets/NSD/\"\n",
    "stim_root = '/user_data/mmhender/nsd_stimuli/stimuli/nsd/'\n",
    "mask_root = nsd_root + \"nsddata/ppdata/\"\n",
    "\n",
    "subject = 1\n",
    "saveext = \".png\"\n",
    "savearg = {'format':'png', 'dpi': 120, 'facecolor': None}\n",
    "# timestamp = 'May-03-2021_0134'\n",
    "# timestamp = 'May-04-2021_0340'\n",
    "# timestamp = 'May-09-2021_2309'\n",
    "# timestamp = 'May-10-2021_1849'\n",
    "timestamp = 'May-16-2021_1422'\n",
    "# timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime())\n",
    "model_name = 'gabor_fwrf'\n",
    "\n",
    "root_dir   = os.path.dirname(os.getcwd())\n",
    "net_dir    = root_dir + \"net/\" \n",
    "\n",
    "# input_dir  = '/home/styvesg/repo.data/results/nsd/torch_fwrf_full_brain/S%02d/dnn_fwrf_May-10-2020_1814/'\n",
    "output_dir = os.path.join(root_dir, 'gabor_model_fits','S%02d'%subject,'%s_%s/'% (model_name,timestamp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcce9442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_params_allROIs']\n",
      "dict_keys(['feature_table', 'sf_tuning_masks', 'ori_tuning_masks', 'cyc_per_stim', 'orients_deg', 'orient_filters', 'aperture', 'models', 'voxel_mask', 'brain_nii_shape', 'image_order', 'voxel_index', 'voxel_roi', 'voxel_ncsnr', 'best_params', 'lambdas', 'best_lambdas', 'best_losses', 'val_cc', 'val_r2', 'features_each_model_val', 'covar_each_model_training', 'voxel_feature_correlations_val', 'zscore_features', 'nonlin_fn', 'debug'])\n"
     ]
    }
   ],
   "source": [
    "# Loading the results of model fitting performed with fit_model.py\n",
    "\n",
    "fns = os.listdir(output_dir)\n",
    "fns = [fn for fn in fns if 'model_params' in fn]\n",
    "print(fns)\n",
    "out = torch.load(os.path.join(output_dir, fns[0]))\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50dbcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11694, 3)\n",
      "(11694, 432)\n"
     ]
    }
   ],
   "source": [
    "# Pulling out useful elements from the saved data\n",
    "\n",
    "feature_table = out['feature_table']\n",
    "orient_list = np.round(np.array(feature_table['orientation'])/np.pi*180,1)\n",
    "a,orient_ind_list = np.unique(orient_list,return_inverse=True)\n",
    "sf_list = np.array(feature_table['cycles per stimulus'])\n",
    "a,sf_ind_list = np.unique(sf_list,return_inverse=True)\n",
    "\n",
    "aperture = out['aperture']\n",
    "cyc_per_stim  = out['cyc_per_stim']\n",
    "orients_deg = out['orients_deg']\n",
    "\n",
    "sf_tuning_masks = out['sf_tuning_masks']\n",
    "ori_tuning_masks = out['ori_tuning_masks']\n",
    "orient_filters = out['orient_filters']\n",
    "\n",
    "voxel_mask = out['voxel_mask']\n",
    "brain_nii_shape = out['brain_nii_shape']\n",
    "image_order = out['image_order']\n",
    "voxel_idx = out['voxel_index']\n",
    "voxel_roi = out['voxel_roi']\n",
    "\n",
    "val_cc = out['val_cc']\n",
    "best_params = out['best_params']\n",
    "best_lambdas = out['best_lambdas']\n",
    "best_losses = out['best_losses']\n",
    "lambdas = out['lambdas']\n",
    "\n",
    "features_each_model_val = out['features_each_model_val']\n",
    "voxel_feature_correlations_val = out['voxel_feature_correlations_val']\n",
    "covar_each_model_training = out['covar_each_model_training']\n",
    "                                    \n",
    "zscore_features = out['zscore_features']\n",
    "# nonlin_fn = out['normalize_fn']\n",
    "nonlin_fn = out['nonlin_fn']\n",
    "\n",
    "# Best params[0] = x,y,sigma for pRF estimates [n_voxels x 3]\n",
    "print(np.shape(best_params[0]))\n",
    "# Best params[1] = best weights [n_voxels x nFeatures]\n",
    "print(np.shape(best_params[1]))\n",
    "\n",
    "best_models = best_params[0]\n",
    "best_ecc  = np.sqrt(np.square(best_models[:,0]) + np.square(best_models[:,1]))\n",
    "best_ang  = np.arctan2(best_models[:,1], best_models[:,0])\n",
    "best_size = best_models[:,2]\n",
    "\n",
    "feature_weights = best_params[1]\n",
    "\n",
    "n_sf = len(cyc_per_stim)\n",
    "n_ori = len(orients_deg)\n",
    "n_voxels = np.shape(feature_weights)[0]\n",
    "n_features_total = np.shape(feature_weights)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60965b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for sessions 1:3...\n",
      "/lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session01.nii.gz\n",
      "int16 -32768 32767 (750, 81, 104, 83)\n",
      "<beta> = 1.271, <sigma> = 1.348\n",
      "/lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session02.nii.gz\n",
      "int16 -32768 32767 (750, 81, 104, 83)\n",
      "<beta> = 1.136, <sigma> = 1.238\n",
      "/lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session03.nii.gz\n",
      "int16 -32768 32767 (750, 81, 104, 83)\n",
      "<beta> = 1.332, <sigma> = 1.340\n",
      "\n",
      "Size of full data set [nTrials x nVoxels] is:\n",
      "(2250, 11694)\n",
      "Total number of voxels = 11694\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "# Getting actual data to test with (slow)\n",
    "\n",
    "subject = 1\n",
    "root_dir   = os.path.dirname(os.getcwd())\n",
    "net_dir    = root_dir + \"net/\" \n",
    "\n",
    "from src.load_nsd import image_uncolorize_fn, data_split, load_betas\n",
    "\n",
    "nsd_root = \"/lab_data/tarrlab/common/datasets/NSD/\"\n",
    "stim_root = '/user_data/mmhender/nsd_stimuli/stimuli/nsd/'    \n",
    "beta_root = nsd_root + \"nsddata_betas/ppdata/\"\n",
    "up_to_sess = 3\n",
    "\n",
    "exp_design_file = nsd_root + \"nsddata/experiments/nsd/nsd_expdesign.mat\"\n",
    "exp_design = loadmat(exp_design_file)\n",
    "ordering = exp_design['masterordering'].flatten() - 1 # zero-indexed ordering of indices (matlab-like to python-like)\n",
    "    \n",
    "### LOADING DATA ####\n",
    "print('Loading data for sessions 1:%d...'%up_to_sess)\n",
    "beta_subj = beta_root + \"subj%02d/func1pt8mm/betas_fithrf_GLMdenoise_RR/\" % (subject,)\n",
    "\n",
    "voxel_data, filenames = load_betas(folder_name=beta_subj, zscore=True, voxel_mask=voxel_mask, up_to=up_to_sess, load_ext=\".nii\")\n",
    "print('\\nSize of full data set [nTrials x nVoxels] is:')\n",
    "print(voxel_data.shape)\n",
    "\n",
    "image_data = {}\n",
    "image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "image_data = np.copy(image_data_set['stimuli'])\n",
    "image_data_set.close()\n",
    "\n",
    "data_size, n_voxels = voxel_data.shape \n",
    "trn_stim_data, trn_voxel_data,\\\n",
    "val_stim_single_trial_data, val_voxel_single_trial_data,\\\n",
    "val_stim_multi_trial_data, val_voxel_multi_trial_data = \\\n",
    "    data_split(image_uncolorize_fn(image_data), voxel_data, ordering, imagewise=False)\n",
    "n_trials_val = val_stim_single_trial_data.shape[0]\n",
    "print(n_trials_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683866a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Gabor filter bank with 8 orientations and 3 spatial frequencies...\n"
     ]
    }
   ],
   "source": [
    "### DEFINE THE FILTERS FOR THE MODEL ###\n",
    "from src.rf_grid    import linspace, logspace, model_space, model_space_pyramid\n",
    "n_ori=8\n",
    "n_sf=3\n",
    "\n",
    "print('\\nBuilding Gabor filter bank with %d orientations and %d spatial frequencies...'%(n_ori, n_sf))\n",
    "cyc_per_stim = logspace(n_sf)(3., 72.) # Which SF values are we sampling here?\n",
    "_gaborizer = Gaborizer(num_orientations=n_ori, cycles_per_stim=cyc_per_stim,\n",
    "          pix_per_cycle=4.13, cycles_per_radius=.7, \n",
    "          radii_per_filter=4, complex_cell=True, pad_type='half', \n",
    "          crop=False).to(device)\n",
    "\n",
    "_fmaps_fn = _gaborizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70825eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMS FOR THE RF CENTERS, SIZES ####\n",
    "aperture = np.float32(1)\n",
    "smin, smax = np.float32(0.04), np.float32(0.4)\n",
    "n_sizes = 8\n",
    "\n",
    "# models is three columns, x, y, sigma\n",
    "models = model_space_pyramid(logspace(n_sizes)(smin, smax), min_spacing=1.4, aperture=1.1*aperture)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f320b89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_size = 108 (90.0%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "---------------------------------------\n",
      "\n",
      "computing mean and std\n",
      "(120, 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmhender/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:54: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x=-0.6, y=-0.6, sigma=0.0: retaining 33 components to expl 99 pct var\n",
      "\n",
      "fitting model    0 of 875 , voxels [    96:99    ] of 100computing mean and std\n",
      "(120, 600)\n",
      "\n",
      "x=-0.5, y=-0.6, sigma=0.0: retaining 31 components to expl 99 pct var\n",
      "\n",
      "fitting model    1 of 875 , voxels [    96:99    ] of 100\n",
      "---------------------------------------\n",
      "total time = 0.563350s\n",
      "total throughput = 0.005633s/voxel\n",
      "voxel throughput = 0.000231s/voxel\n",
      "setup throughput = 0.000617s/model\n",
      "\n",
      "Done with training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmhender/myenv/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    }
   ],
   "source": [
    "min_pct_var=99\n",
    "sample_batch_size = 10\n",
    "voxel_batch_size=12\n",
    "holdout_pct = 0.10\n",
    "# holdout_size = int(np.ceil(np.shape(trn_voxel_data)[0]*holdout_pct))\n",
    "debug=True\n",
    "zscore_features=True\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "nvox2use = 100\n",
    "trials2use = 120\n",
    "holdout_size = int(np.ceil(trials2use*holdout_pct))\n",
    "best_losses, pc, best_params, second_order_zstats = learn_params_second_order_pca(\n",
    "    trn_stim_data[0:trials2use,:], trn_voxel_data[0:trials2use,0:nvox2use], _fmaps_fn, models, min_pct_var=min_pct_var, \\\n",
    "    aperture=aperture, zscore=zscore_features, sample_batch_size=sample_batch_size, \\\n",
    "    voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, shuffle=False, add_bias=True, debug=debug)\n",
    "pca_wts = pc[0]\n",
    "pct_var_expl = pc[1]\n",
    "n_comp_needed = pc[3]\n",
    "pca_pre_mean = pc[4]\n",
    "best_model_inds = best_params[5]\n",
    "print('\\nDone with training\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "598d2cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model for validation...\n",
      "\n",
      "Making fwrf module...\n",
      "\n",
      "Getting model predictions on validation set...\n",
      "\n",
      "samples [  200:200  ] of 201, voxels [    96:99    ] of 100\n",
      "---------------------------------------\n",
      "total time = 3.864499s\n",
      "sample throughput = 0.019226s/sample\n",
      "voxel throughput = 0.038645s/voxel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4735.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating correlation coefficient on validation set...\n",
      "\n",
      "\n",
      "Computing activation in each feature channel on validation set trials...\n",
      "\n",
      "model 0 of 875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using input mean and std:\n",
      "[1.3823387e-04 1.2412257e-04 2.1719817e-08 3.6618051e-08]\n",
      "model 1 of 875using input mean and std:\n",
      "[7.3307886e-04 6.8315020e-04 6.0962191e-07 1.0814554e-06]\n",
      "\n",
      "Computing voxel/feature correlations for validation set trials...\n",
      "\n",
      "voxel 1 of 100"
     ]
    }
   ],
   "source": [
    "\n",
    "n_voxels = nvox2use\n",
    "\n",
    "#### EVALUATE PERFORMANCE ON VALIDATION SET #####\n",
    "print('\\nInitializing model for validation...\\n')\n",
    "param_batch = [p[:voxel_batch_size] if p is not None else None for p in best_params]\n",
    "# To initialize this module for prediction, need to take just first batch of voxels.\n",
    "# Will eventually pass all voxels through in batches.\n",
    "_fwrf_fn = Torch_fwRF_voxel_block(_fmaps_fn, param_batch, input_shape=val_stim_single_trial_data.shape, aperture=1.0, pc=pc, second_order_zstats=second_order_zstats)\n",
    "\n",
    "print('\\nGetting model predictions on validation set...\\n')\n",
    "val_voxel_pred = get_predictions(val_stim_single_trial_data, _fmaps_fn, _fwrf_fn, best_params, sample_batch_size=sample_batch_size)\n",
    "\n",
    "# val_cc is the correlation coefficient bw real and predicted responses across trials, for each voxel.\n",
    "val_cc  = np.zeros(shape=(n_voxels), dtype=fpX)\n",
    "val_r2 = np.zeros(shape=(n_voxels), dtype=fpX)\n",
    "\n",
    "print('\\nEvaluating correlation coefficient on validation set...\\n')\n",
    "for v in tqdm(range(n_voxels)):    \n",
    "    val_cc[v] = np.corrcoef(val_voxel_single_trial_data[:,v], val_voxel_pred[:,v])[0,1]  \n",
    "    val_r2[v] = get_r2(val_voxel_single_trial_data[:,v], val_voxel_pred[:,v])\n",
    "\n",
    "val_cc = np.nan_to_num(val_cc)\n",
    "val_r2 = np.nan_to_num(val_r2)\n",
    "\n",
    "### GET ACTUAL FEATURE VALUES FOR EACH TRIAL IN TESTING SET ########\n",
    "# will use to compute tuning etc based on voxel responses in validation set.\n",
    "# looping over every model here; there are fewer models than voxels so this is faster than doing each voxel separately.\n",
    "\n",
    "print('\\nComputing activation in each feature channel on validation set trials...\\n')\n",
    "n_features = best_params[1].shape[1]\n",
    "n_prfs = models.shape[0]\n",
    "features_each_model_val = np.zeros(shape=(n_trials_val, n_features, n_prfs),dtype=fpX)\n",
    "features_pca_each_model_val = np.zeros(shape=(n_trials_val, n_features, n_prfs),dtype=fpX)\n",
    "\n",
    "for mm in range(n_prfs):\n",
    "    if debug and mm>1:\n",
    "        break \n",
    "    sys.stdout.write('\\rmodel %d of %d'%(mm,n_prfs))\n",
    "\n",
    "    features, zstats = get_features_in_prf_second_order(models[mm,:], _fmaps_fn, val_stim_single_trial_data, sample_batch_size, aperture, device, zstats=second_order_zstats[mm,:]) \n",
    "    features_each_model_val[:,:,mm] = features\n",
    "\n",
    "    # project into pca space\n",
    "    features_submean = features - np.tile(np.expand_dims(pca_pre_mean[:,mm], axis=0), [np.shape(features)[0], 1])\n",
    "    features_reduced = features_submean @ np.transpose(pca_wts[0:n_comp_needed[mm],:,mm]) # subtract mean in same way as for original training set features                                                       \n",
    "    features_pca_each_model_val[:,0:n_comp_needed[mm],mm] = features_reduced[:,0:n_comp_needed[mm]] # multiply by weight matrix\n",
    "\n",
    "\n",
    "### COMPUTE CORRELATION OF VALIDATION SET VOXEL RESP WITH FEATURE ACTIVATIONS ###########\n",
    "# this will serve as another measure of \"tuning\"\n",
    "print('\\nComputing voxel/feature correlations for validation set trials...\\n')\n",
    "voxel_feature_correlations_val = np.zeros((n_voxels, n_features),dtype=fpX)\n",
    "voxel_pca_feature_correlations_val = np.zeros((n_voxels, n_features),dtype=fpX)\n",
    "best_models = best_params[0]\n",
    "\n",
    "for vv in range(n_voxels):\n",
    "    if debug and vv>1:\n",
    "        break \n",
    "    sys.stdout.write('\\rvoxel %d of %d'%(vv,n_voxels))\n",
    "\n",
    "    # figure out for this voxel, which pRF estimate was best.\n",
    "    best_model_ind = best_model_inds[vv]\n",
    "\n",
    "    # taking features for the validation set images, within this voxel's fitted RF\n",
    "    features2use = features_each_model_val[:,:,best_model_ind]\n",
    "    features2use_pca = features_pca_each_model_val[:,:,best_model_ind]\n",
    "\n",
    "    for ff in range(n_features):        \n",
    "        voxel_feature_correlations_val[vv,ff] = np.corrcoef(features2use[:,ff], val_voxel_single_trial_data[:,vv])[0,1]\n",
    "        if ff<n_comp_needed[best_model_ind]:                                               \n",
    "            voxel_pca_feature_correlations_val[vv,ff] = np.corrcoef(features2use_pca[:,ff], val_voxel_single_trial_data[:,vv])[0,1]\n",
    "        else:\n",
    "            voxel_pca_feature_correlations_val[vv,ff] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64d8173e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43dbdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "_features = np.random.normal(0,1, [10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcbea338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41062532374755545\n",
      "0.41062532374755545\n"
     ]
    }
   ],
   "source": [
    "f = np.tile(_features, [1,11,1]) * np.repeat(_features, 11, axis=1)\n",
    "np.shape(f)\n",
    "ind=4\n",
    "i0=0\n",
    "i2=0\n",
    "print(f[i0,ind,i2])\n",
    "print(_features[i0,np.mod(ind,11),i2] * _features[i0,int(np.ceil(ind/11))-1,i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da1822be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 121, 12)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e3e520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Torch_fwRF_voxel_block(nn.Module):\n",
    "    '''\n",
    "    This is the module that maps from feature maps to voxel predictions according to weights.\n",
    "    This works for a batch of voxels at a time. \n",
    "    Initialize with one set of voxels, but can use load_voxel_block to run w different batches\n",
    "    '''\n",
    "\n",
    "    def __init__(self, _fmaps_fn, params, input_shape=(1,3,227,227), aperture=1.0, pc=None, second_order_zstats=None):\n",
    "        super(Torch_fwRF_voxel_block, self).__init__()\n",
    "        print('Making fwrf module...')\n",
    "        self.aperture = aperture\n",
    "        models, weights, bias, features_mt, features_st, best_model_inds = params\n",
    "        device = next(_fmaps_fn.parameters()).device\n",
    "        _x =torch.empty((1,)+input_shape[1:], device=device).uniform_(0, 1)\n",
    "        _fmaps = _fmaps_fn(_x)\n",
    "        self.fmaps_rez = []\n",
    "        for k,_fm in enumerate(_fmaps):\n",
    "            assert _fm.size()[2]==_fm.size()[3], 'All feature maps need to be square'\n",
    "            self.fmaps_rez += [_fm.size()[2],]\n",
    "        \n",
    "        self.prfs = []\n",
    "        for k,n_pix in enumerate(self.fmaps_rez):\n",
    "            prf = pnu.make_gaussian_mass_stack(models[:,0], models[:,1], models[:,2], n_pix, size=aperture, dtype=np.float32)[2]\n",
    "            self.prfs += [nn.Parameter(torch.from_numpy(prf).to(device), requires_grad=False),]\n",
    "            self.register_parameter('prfs%d'%k, self.prfs[-1])\n",
    "            \n",
    "        self.weights = nn.Parameter(torch.from_numpy(weights).to(device), requires_grad=False)\n",
    "        self.bias = None\n",
    "        if bias is not None:\n",
    "            self.bias = nn.Parameter(torch.from_numpy(bias).to(device), requires_grad=False)\n",
    "            \n",
    "        self.features_m = None\n",
    "        self.features_s = None\n",
    "        if features_mt is not None:\n",
    "            self.features_m = nn.Parameter(torch.from_numpy(features_mt.T).to(device), requires_grad=False)\n",
    "        if features_st is not None:\n",
    "            self.features_s = nn.Parameter(torch.from_numpy(features_st.T).to(device), requires_grad=False)\n",
    "       \n",
    "        # add in params related to pca on training features, if this was done. otherwise ignore.\n",
    "        self.pca_wts = None\n",
    "        self.n_comp_needed = None\n",
    "        self.pca_pre_mean = None\n",
    "        if pc is not None:\n",
    "            self.pca_wts = pc[0]\n",
    "            self.n_comp_needed = pc[3]\n",
    "            self.pca_pre_mean = pc[4]\n",
    "            self.n_comp_this_batch = nn.Parameter(torch.from_numpy(self.n_comp_needed[best_model_inds]).to(device), requires_grad=False)\n",
    "            self.pca_wts_this_batch = nn.Parameter(torch.from_numpy(self.pca_wts[:,:,best_model_inds]).to(device), requires_grad=False)\n",
    "            self.pca_premean_this_batch = nn.Parameter(torch.from_numpy(self.pca_pre_mean[:,best_model_inds]).to(device), requires_grad=False)\n",
    "        \n",
    "        self.second_order_zstats = None\n",
    "        if second_order_zstats is not None:\n",
    "            self.second_order_zstats = second_order_zstats\n",
    "            self.second_order_zstats_this_batch = nn.Parameter(torch.from_numpy(self.second_order_zstats[best_model_inds,:]).to(device), requires_grad=False)\n",
    "            \n",
    "    def load_voxel_block(self, *params):\n",
    "        # This takes a given set of parameters for the voxel batch of interest, and puts them \n",
    "        # into the right fields of the module so we can use them in a forward pass.\n",
    "        models = params[0]\n",
    "                \n",
    "        for _prfs,n_pix in zip(self.prfs, self.fmaps_rez):\n",
    "            prfs = pnu.make_gaussian_mass_stack(models[:,0], models[:,1], models[:,2], n_pix, size=self.aperture, dtype=np.float32)[2]\n",
    "            if len(prfs)<_prfs.size()[0]:\n",
    "                pp = np.zeros(shape=_prfs.size(), dtype=prfs.dtype)\n",
    "                pp[:len(prfs)] = prfs\n",
    "                set_value(_prfs, pp)\n",
    "            else:\n",
    "                set_value(_prfs, prfs)\n",
    "                \n",
    "        if self.second_order_zstats is not None:\n",
    "            best_model_inds = params[5]\n",
    "            set_value(self.second_order_zstats_this_batch, self.second_order_zstats[best_model_inds,:])\n",
    "            \n",
    "        if self.pca_wts is not None:\n",
    "            \n",
    "            # figure out which pca parameters go with which voxels in this voxel batch\n",
    "            best_model_inds = params[5]\n",
    "#             print([self.pca_wts_this_batch.shape[0],len(best_model_inds)])\n",
    "            if len(best_model_inds)<self.pca_wts_this_batch.shape[2]:\n",
    "                \n",
    "                # if this is a small batch of trials, pad it with zeros                \n",
    "                pp1 = np.zeros(shape=self.pca_wts_this_batch.shape, dtype=self.pca_wts.dtype)\n",
    "                pp1[:,:,0:len(best_model_inds)] = self.pca_wts[:,:,best_model_inds]\n",
    "                \n",
    "                pp2 = np.zeros(shape=self.n_comp_this_batch.shape, dtype=self.n_comp_needed.dtype)\n",
    "                pp2[0:len(best_model_inds)] = self.n_comp_needed[best_model_inds]   \n",
    "                \n",
    "                pp3 = np.zeros(shape=self.pca_premean_this_batch.shape, dtype=self.pca_pre_mean.dtype)\n",
    "                pp3[:,0:len(best_model_inds)] = self.pca_pre_mean[:,best_model_inds]\n",
    "                \n",
    "                \n",
    "                set_value(self.pca_wts_this_batch,   pp1)\n",
    "                set_value(self.n_comp_this_batch,   pp2)\n",
    "                set_value(self.pca_premean_this_batch,   pp3)\n",
    "            else:\n",
    "                set_value(self.pca_wts_this_batch,   self.pca_wts[:,:,best_model_inds])\n",
    "                set_value(self.n_comp_this_batch,   self.n_comp_needed[best_model_inds])\n",
    "                set_value(self.pca_premean_this_batch, self.pca_pre_mean[:,best_model_inds])\n",
    "                \n",
    "        for _p,p in zip([self.weights, self.bias], params[1:3]):\n",
    "            if _p is not None:\n",
    "                if len(p)<_p.size()[0]:\n",
    "                    pp = np.zeros(shape=_p.size(), dtype=p.dtype)\n",
    "                    pp[:len(p)] = p\n",
    "                    set_value(_p, pp)\n",
    "                else:\n",
    "                    set_value(_p, p)\n",
    "                    \n",
    "        for _p,p in zip([self.features_m, self.features_s], params[3:]):\n",
    "            if _p is not None:\n",
    "                if len(p)<_p.size()[1]:\n",
    "                    pp = np.zeros(shape=(_p.size()[1], _p.size()[0]), dtype=p.dtype)\n",
    "                    pp[:len(p)] = p\n",
    "                    set_value(_p, pp.T)\n",
    "                else:\n",
    "                    set_value(_p, p.T)\n",
    " \n",
    "    def forward(self, _fmaps):\n",
    "\n",
    "        _features = torch.cat([torch.tensordot(_fm, _prf, dims=[[2,3], [1,2]]) for _fm,_prf in zip(_fmaps, self.prfs)], dim=1) # [#samples, #features, #voxels]\n",
    "        \n",
    "        if self.second_order_zstats is not None:    \n",
    "            # convert these first order features into a larger matrix that includes second-order combinations of features            \n",
    "            f = _to_torch(np.zeros(shape=(_features.shape[0], _features.shape[1]*_features.shape[1]+_features.shape[1], _features.shape[2]),dtype=self.second_order_zstats.dtype), device=_features.device)\n",
    "            for vv in range(_features.shape[2]):\n",
    "                f_first = (_features[:,:,vv] - self.second_order_zstats[vv,0])/self.second_order_zstats[vv,1]\n",
    "                f_second = torch.tile(_features[:,:,vv], [1,_features.shape[1]]) * torch.repeat_interleave(_features[:,:,vv], _features.shape[1], axis=1)\n",
    "                f_second = (f_second - self.second_order_zstats[vv,2])/self.second_order_zstats[vv,3]\n",
    "                f[:,:,vv] = torch.cat([f_first, f_second], axis=1)\n",
    "                \n",
    "            _features = f\n",
    "#         print(_features.shape)\n",
    "        \n",
    "        if self.pca_wts is not None:            \n",
    "        \n",
    "            # apply the pca matrix to each voxel - to keep all features same length, put zeros for components past the desired number.\n",
    "            features_pca = _to_torch(np.zeros(shape=_features.shape, dtype=self.pca_wts.dtype), device=_features.device)\n",
    "            \n",
    "            # features is [#samples, #features, #voxels]\n",
    "            for vv in range(_features.shape[2]):\n",
    "#                 print([vv, self.n_comp_this_batch.shape, self.pca_wts_this_batch.shape, self.pca_premean_this_batch.shape])\n",
    "                features_submean = _features[:,:,vv] - torch.tile(torch.unsqueeze(self.pca_premean_this_batch[:,vv], dim=0), [_features.shape[0],1])\n",
    "                \n",
    "                features_pca[:, 0:self.n_comp_this_batch[vv], vv] = torch.tensordot(features_submean, self.pca_wts_this_batch[0:self.n_comp_this_batch[vv],:,vv], dims=[[1],[1]]) \n",
    "\n",
    "            _features = features_pca\n",
    "\n",
    "        if self.features_m is not None:    \n",
    "            # features_m is [nfeatures x nvoxels]\n",
    "            _features = _features - torch.tile(torch.unsqueeze(self.features_m, dim=0), [_features.shape[0], 1, 1])\n",
    "\n",
    "        if self.features_s is not None:\n",
    "            _features = _features/torch.tile(torch.unsqueeze(self.features_s, dim=0), [_features.shape[0], 1, 1])\n",
    "            _features[torch.isnan(_features)] = 0.0 # this applies in the pca case when last few columns of features are missing\n",
    "\n",
    "        # features is [#samples, #features, #voxels] - swap dims to [#voxels, #samples, features]\n",
    "        _features = torch.transpose(torch.transpose(_features, 0, 2), 1, 2)\n",
    "        # weights is [#voxels, #features]\n",
    "        # _r will be [#voxels, #samples, 1] - then [#samples, #voxels]\n",
    "        _r = torch.squeeze(torch.bmm(_features, torch.unsqueeze(self.weights, 2)), dim=2).t() \n",
    "  \n",
    "        if self.bias is not None:\n",
    "            _r = _r + torch.tile(torch.unsqueeze(self.bias, 0), [_r.shape[0],1])\n",
    "            \n",
    "        return _r\n",
    "\n",
    "\n",
    "    \n",
    "def get_predictions(images, _fmaps_fn, _fwrf_fn, params, sample_batch_size=100):\n",
    "    \"\"\"\n",
    "    The predictive fwRF model for arbitrary input image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : ndarray, shape (#samples, #channels, x, y)\n",
    "        Input image block.\n",
    "    _fmaps_fn: Torch module\n",
    "        Torch module that returns a list of torch tensors.\n",
    "        This is defined previously, maps from images to feature maps.\n",
    "    _fwrf_fn: Torch module\n",
    "        Torch module that compute the fwrf model for one batch of voxels\n",
    "        Defined in Torch_fwrf_voxel_block\n",
    "    params: list including all of the following:\n",
    "    [\n",
    "        models : ndarray, shape (#voxels, 3)\n",
    "            The RF model (x, y, sigma) associated with each voxel.\n",
    "        weights : ndarray, shape (#voxels, #features)\n",
    "            Tuning weights\n",
    "        bias: Can contain a bias parameter of shape (#voxels) if add_bias is True.\n",
    "           Tuning biases: None if there are no bias\n",
    "        features_mean (optional): ndarray, shape (#voxels, #feature)\n",
    "            None if zscore is False. Otherwise returns zscoring average per feature.\n",
    "        features_std (optional): ndarray, shape (#voxels, #feature)\n",
    "            None if zscore is False. Otherwise returns zscoring std.dev. per feature.\n",
    "    ]\n",
    "    sample_batch_size (default: 100)\n",
    "        The sample batch size (used where appropriate)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pred : ndarray, shape (#samples, #voxels)\n",
    "        The prediction of voxel activities for each voxels associated with the input images.\n",
    "    \"\"\"\n",
    "    \n",
    "    dtype = images.dtype.type\n",
    "    device = next(_fmaps_fn.parameters()).device\n",
    "    _params = [_p for _p in _fwrf_fn.parameters()]\n",
    "    voxel_batch_size = _params[0].size()[0]    \n",
    "    n_trials, n_voxels = len(images), len(params[0])\n",
    "\n",
    "    pred = np.full(fill_value=0, shape=(n_trials, n_voxels), dtype=dtype)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        ## Looping over voxels here in batches, will eventually go through all.\n",
    "        for rv, lv in iterate_range(0, n_voxels, voxel_batch_size):\n",
    "            \n",
    "            # for this voxel batch, put the right parameters into the _fwrf_fn module\n",
    "            # so that we can do forward pass...\n",
    "            _fwrf_fn.load_voxel_block(*[p[rv] if p is not None else None for p in params])\n",
    "            pred_block = np.full(fill_value=0, shape=(n_trials, voxel_batch_size), dtype=dtype)\n",
    "            \n",
    "            # Now looping over validation set trials in batches\n",
    "            for rt, lt in iterate_range(0, n_trials, sample_batch_size):\n",
    "                sys.stdout.write('\\rsamples [%5d:%-5d] of %d, voxels [%6d:%-6d] of %d' % (rt[0], rt[-1], n_trials, rv[0], rv[-1], n_voxels))\n",
    "                # Get predictions for this set of trials.\n",
    "                pred_block[rt] = get_value(_fwrf_fn(_fmaps_fn(_to_torch(images[rt], device)))) \n",
    "                \n",
    "            pred[:,rv] = pred_block[:,:lv]\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('sample throughput = %fs/sample' % (total_time / n_trials))\n",
    "    print ('voxel throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    sys.stdout.flush()\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "class add_nonlinearity(nn.Module):\n",
    "    def __init__(self, _fmaps_fn, _nonlinearity):\n",
    "        super(add_nonlinearity, self).__init__()\n",
    "        self.fmaps_fn = _fmaps_fn\n",
    "        self.nl_fn = _nonlinearity\n",
    "    def forward(self, _x):\n",
    "        return [self.nl_fn(_fm) for _fm in self.fmaps_fn(_x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f913cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_params_second_order_pca(images, voxel_data, _fmaps_fn, models, min_pct_var = 99, aperture=1.0, zscore=False, sample_batch_size=100, voxel_batch_size=100, holdout_size=100, shuffle=True, add_bias=False, debug=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Learn the parameters of the model, using PCA first to decorrelate features.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pca = decomposition.PCA()\n",
    "\n",
    "    dtype = images.dtype.type\n",
    "    device = next(_fmaps_fn.parameters()).device\n",
    "    trn_size = len(voxel_data) - holdout_size\n",
    "    assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "    \n",
    "    print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "    print ('dtype = %s' % dtype)\n",
    "    print ('device = %s' % device)\n",
    "    print ('---------------------------------------')\n",
    "       \n",
    "    n_trials = len(images)\n",
    "    n_prfs = len(models)\n",
    "    n_voxels = voxel_data.shape[1]   \n",
    "    order = np.arange(len(voxel_data), dtype=int)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(order)\n",
    "    images = images[order]\n",
    "    voxel_data = voxel_data[order]  \n",
    "    trn_data = voxel_data[:trn_size]\n",
    "    out_data = voxel_data[trn_size:]\n",
    "    \n",
    "    # Looping over the feature maps once with a batch of images, to get their sizes\n",
    "    n_features, fmaps_rez = get_fmaps_sizes(_fmaps_fn, images[0:sample_batch_size], device)\n",
    "    n_features_full = n_features*n_features+n_features # this is total dim of feature matrix once we add in second order combinations.\n",
    "    \n",
    "    # Create full model value buffers    \n",
    "    best_models = np.full(shape=(n_voxels,), fill_value=-1, dtype=int)   \n",
    "    best_losses = np.full(fill_value=np.inf, shape=(n_voxels), dtype=dtype)\n",
    "    best_w_params = np.zeros(shape=(n_voxels, n_features_full ), dtype=dtype)\n",
    "\n",
    "    if add_bias:\n",
    "        best_w_params = np.concatenate([best_w_params, np.ones(shape=(len(best_w_params),1), dtype=dtype)], axis=1)\n",
    "    features_mean = None\n",
    "    features_std = None\n",
    "    if zscore:\n",
    "        features_mean = np.zeros(shape=(n_voxels, n_features_full), dtype=dtype)\n",
    "        features_std  = np.zeros(shape=(n_voxels, n_features_full), dtype=dtype)\n",
    "       \n",
    "    second_order_zstats = np.zeros(shape=(n_prfs,4), dtype=dtype)\n",
    "    \n",
    "    # will save pca stuff as well\n",
    "    pca_wts = np.zeros(shape=(n_features_full, n_features_full, n_prfs), dtype=dtype) # will be [ncomponents x nfeatures x nmodels]\n",
    "    pca_pre_mean = np.zeros(shape=(n_features_full, n_prfs), dtype=dtype)\n",
    "    pct_var_expl = np.zeros(shape=(n_features_full, n_prfs), dtype=dtype)\n",
    "    n_comp_needed = np.zeros(shape=(n_prfs), dtype=np.int)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    vox_loop_time = 0\n",
    "    print ('')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Looping over models (here models are different spatial RF definitions)\n",
    "        for m,(x,y,sigma) in enumerate(models):\n",
    "            if debug and m>1:\n",
    "                break\n",
    "\n",
    "            t = time.time()            \n",
    "            # Get features for the desired pRF, across all trn set images            \n",
    "            features, zs = get_features_in_prf_second_order((x,y,sigma), _fmaps_fn, images, sample_batch_size, aperture, device)     \n",
    "            second_order_zstats[m,:] = zs\n",
    "            elapsed = time.time() - t\n",
    "#             print(features.shape)\n",
    "            # separate design matrix into training/held out data (for lambda selection)\n",
    "            trn_features = features[:trn_size]\n",
    "            out_features = features[trn_size:]   \n",
    "\n",
    "            # Perform PCA to decorrelate feats and reduce dimensionality\n",
    "            pca.fit(trn_features)\n",
    "            trn_scores = pca.transform(trn_features)\n",
    "            out_scores = pca.transform(out_features)\n",
    "            wts = pca.components_\n",
    "            ev = pca.explained_variance_\n",
    "            ev = ev/np.sum(ev)*100\n",
    "            pca_wts[0:len(ev),:,m] = wts # save a record of the transformation to interpret encoding model weights later [ncomponents x nfeatures]\n",
    "            pca_pre_mean[:,m] = pca.mean_ # mean of each feature, nfeatures long - needed to reproduce transformation\n",
    "            pct_var_expl[0:len(ev),m] = ev   # max len of ev is the number of components (note for a small # samples, this could be smaller than total feature #)\n",
    "            ncompneeded = int(np.where(np.cumsum(ev)>min_pct_var)[0][0] if np.any(np.cumsum(ev)>min_pct_var) else len(ev))\n",
    "            n_comp_needed[m] = ncompneeded\n",
    "            print('\\nx=%.1f, y=%.1f, sigma=%.1f: retaining %d components to expl %d pct var\\n'%(x,y,sigma, ncompneeded, min_pct_var))\n",
    "            trn_features = trn_scores[:,0:ncompneeded]\n",
    "            out_features = out_scores[:,0:ncompneeded]\n",
    " \n",
    "            if zscore:  \n",
    "                features_m = np.mean(trn_features, axis=0, keepdims=True) #[:trn_size]\n",
    "                features_s = np.std(trn_features, axis=0, keepdims=True) + 1e-6          \n",
    "                trn_features -= features_m\n",
    "                trn_features /= features_s    \n",
    "\n",
    "            if add_bias:\n",
    "                trn_features = np.concatenate([trn_features, np.ones(shape=(len(trn_features), 1), dtype=dtype)], axis=1)\n",
    "                out_features = np.concatenate([out_features, np.ones(shape=(len(out_features), 1), dtype=dtype)], axis=1)\n",
    "\n",
    "            # Send matrices to gpu\n",
    "            _xtrn = _to_torch(trn_features, device=device)\n",
    "            _xout = _to_torch(out_features, device=device)   \n",
    "\n",
    "            # Do part of the matrix math involved in ridge regression optimization out of the loop, \n",
    "            # because this part will be same for all the voxels.\n",
    "            _cof = _cofactor_fn_cpu(_xtrn, lambdas = [0.0]) # no ridge param here because already regularizing by doing pca first\n",
    "\n",
    "            # Now looping over batches of voxels (only reason is because can't store all in memory at same time)\n",
    "            vox_start = time.time()\n",
    "            for rv,lv in iterate_range(0, n_voxels, voxel_batch_size):\n",
    "                sys.stdout.write('\\rfitting model %4d of %-4d, voxels [%6d:%-6d] of %d' % (m, n_prfs, rv[0], rv[-1], n_voxels))\n",
    "\n",
    "                # Send matrices to gpu\n",
    "                _vtrn = _to_torch(trn_data[:,rv], device=device)\n",
    "                _vout = _to_torch(out_data[:,rv], device=device)\n",
    "\n",
    "                # Here is where optimization happens - relatively simple matrix math inside loss fn.\n",
    "                _betas, _loss = _loss_fn(_cof, _vtrn, _xout, _vout) #   [#lambda, #feature, #voxel, ], [#lambda, #voxel]\n",
    "                # Now have a set of weights (in betas) and a loss value for every voxel and every lambda. \n",
    "                # goal is then to choose for each voxel, what is the best lambda and what weights went with that lambda.\n",
    "\n",
    "                # choose best lambda value and the loss that went with it.\n",
    "                _values, _select = torch.min(_loss, dim=0)\n",
    "                betas = get_value(_betas)\n",
    "                values, select = get_value(_values), get_value(_select)\n",
    "\n",
    "                # comparing this loss to the other models for each voxel (e.g. the other RF position/sizes)\n",
    "                imp = values<best_losses[rv]\n",
    "\n",
    "                if np.sum(imp)>0:\n",
    "                    # for whichever voxels had improvement relative to previous models, save parameters now\n",
    "                    # this means we won't have to save all params for all models, just best.\n",
    "                    arv = np.array(rv)[imp]\n",
    "                    li = select[imp]\n",
    "\n",
    "                    best_losses[arv] = values[imp]\n",
    "                    best_models[arv] = m\n",
    "                    if zscore:\n",
    "                        features_mean[arv,0:ncompneeded] = features_m # broadcast over updated voxels\n",
    "                        features_std[arv,0:ncompneeded]  = features_s\n",
    "                        features_mean[arv,ncompneeded:] = 0.0 # make sure to fill zeros here\n",
    "                        features_std[arv,ncompneeded:] = 0.0 # make sure to fill zeros here\n",
    "                    # taking the weights associated with the best lambda value\n",
    "                    # remember that they won't fill entire matrix, rest of values stay at zero\n",
    "                    best_w_params[arv,0:ncompneeded] = pnu.select_along_axis(betas[:,0:ncompneeded,imp], li, run_axis=2, choice_axis=0).T\n",
    "                    best_w_params[arv,ncompneeded:] = 0.0 # make sure to fill zeros here\n",
    "                    # bias is always last value, even if zeros for the later features\n",
    "                    if add_bias:\n",
    "                        best_w_params[arv,-1] = pnu.select_along_axis(betas[:,-1,imp], li, run_axis=1, choice_axis=0).T\n",
    "\n",
    "            vox_loop_time += (time.time() - vox_start)\n",
    "            elapsed = (time.time() - vox_start)\n",
    "\n",
    "    # Print information about how fitting went...\n",
    "    total_time = time.time() - start_time\n",
    "    inv_time = total_time - vox_loop_time\n",
    "    return_params = [best_w_params[:,:n_features_full],]\n",
    "    if add_bias:\n",
    "        return_params += [best_w_params[:,-1],]\n",
    "    else: \n",
    "        return_params += [None,]\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('total throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    print ('voxel throughput = %fs/voxel' % (vox_loop_time / n_voxels))\n",
    "    print ('setup throughput = %fs/model' % (inv_time / n_prfs))\n",
    "    sys.stdout.flush()\n",
    "    return best_losses, [pca_wts, pct_var_expl, min_pct_var, n_comp_needed, pca_pre_mean], [models[best_models],]+return_params+[features_mean, features_std]+[best_models], second_order_zstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad97e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_in_prf_second_order(prf_params, _fmaps_fn, images, sample_batch_size, aperture, device, zstats=None):\n",
    "    \"\"\"\n",
    "    For a given set of images and a specified pRF position and size, compute the\n",
    "    activation in each feature map channel. Returns [nImages x nFeatures]\n",
    "    # Use second order model here, so nFeatures output is nFeatures*nFeatures + nFeatures\n",
    "    \"\"\"\n",
    "    \n",
    "    dtype = images.dtype.type\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        x,y,sigma = prf_params\n",
    "        n_trials = images.shape[0]\n",
    "\n",
    "        # pass first batch of images through feature map, just to get sizes.\n",
    "        n_features, fmaps_rez = get_fmaps_sizes(_fmaps_fn, images[0:sample_batch_size], device)\n",
    "\n",
    "        features = np.zeros(shape=(n_trials, n_features*n_features+n_features), dtype=dtype)\n",
    "\n",
    "        # Define the RF for this \"model\" version - at several resolutions.\n",
    "        _prfs = [_to_torch(pnu.make_gaussian_mass(x, y, sigma, n_pix, size=aperture, \\\n",
    "                                  dtype=dtype)[2], device=device) for n_pix in fmaps_rez]\n",
    "\n",
    "        # To make full design matrix for all trials, first looping over trials in batches to get the features\n",
    "        # Only reason to loop is memory constraints, because all trials is big matrices.\n",
    "        t = time.time()\n",
    "        n_batches = np.ceil(n_trials/sample_batch_size)\n",
    "        bb=-1\n",
    "        for rt,rl in pnu.iterate_range(0, n_trials, sample_batch_size):\n",
    "\n",
    "            bb=bb+1\n",
    "            # multiplying feature maps by RFs here. \n",
    "            # features is [nTrialsTotal x nFeatures*nResolutions]\n",
    "            # note this is concatenating SFs together from low to high - \n",
    "            # cycles through all orient channels in order for first SF, then again for next SF.\n",
    "            _features = torch.cat([torch.tensordot(_fm, _prf, dims=[[2,3], [0,1]]) \\\n",
    "                                   for _fm,_prf in zip(_fmaps_fn(_to_torch(images[rt], \\\n",
    "                                           device=device)), _prfs)], dim=1) # [#samples, #features]\n",
    "\n",
    "            # Add features for this batch to full design matrix over all trials\n",
    "            f = get_value(_features)\n",
    "            # create all the possible combinations\n",
    "            f_combs = np.tile(f, [1,n_features]) * np.repeat(f, n_features, axis=1)\n",
    "            # final array will have all these concatenated\n",
    "            features[rt,0:n_features] = f\n",
    "            features[rt,n_features:] = f_combs\n",
    "            \n",
    "        elapsed = time.time() - t\n",
    "#         print('\\nComputing features took %d sec'%elapsed)\n",
    "        \n",
    "        # to make first and second order features comparable, scale each separately by overall mean and variance \n",
    "        # doing this across all images so that it doesn't disrupt covariance structure within each set of features.\n",
    "        if zstats is None:\n",
    "#             print('computing mean and std')\n",
    "            mean_first = np.mean(features[:,0:n_features], axis=None)\n",
    "            std_first = np.std(features[:,0:n_features], axis=None)        \n",
    "            mean_second = np.mean(features[:,n_features:], axis=None)\n",
    "            std_second = np.std(features[:,n_features:], axis=None)\n",
    "        else:\n",
    "#             print('using input mean and std:')\n",
    "#             print(zstats)\n",
    "            # if this is validation pass, these stats have already been computed on trn set so use them here.\n",
    "            mean_first = zstats[0]\n",
    "            std_first = zstats[1]\n",
    "            mean_second = zstats[2]\n",
    "            std_second = zstats[3]\n",
    "                        \n",
    "        features[:,0:n_features] = (features[:,0:n_features] - mean_first)/std_first        \n",
    "        features[:,n_features:] = (features[:,n_features:] - mean_second)/std_second\n",
    "        \n",
    "        \n",
    "    return features, np.array([mean_first, std_first, mean_second, std_second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c443f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "import src.numpy_utility as pnu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as I\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from src.numpy_utility import iterate_range\n",
    "\n",
    "\n",
    "def get_value(_x):\n",
    "    return np.copy(_x.data.cpu().numpy())\n",
    "\n",
    "def set_value(_x, x):\n",
    "    if list(x.shape)!=list(_x.size()):\n",
    "        _x.resize_(x.shape)\n",
    "    _x.data.copy_(torch.from_numpy(x))\n",
    "    \n",
    "def _to_torch(x, device=None):\n",
    "    return torch.from_numpy(x).float().to(device)    \n",
    "\n",
    "def _cofactor_fn(_x, lambdas, device):\n",
    "    '''\n",
    "    Generating a matrix needed to solve ridge regression model for each lambda value.\n",
    "    Ridge regression (Tikhonov) solution is :\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    This func will return (X^T*X + I*lambda)^-1 * X^T. \n",
    "    So once we have that, can just multiply by training data (Y) to get weights.\n",
    "    returned size is [nLambdas x nFeatures x nTrials]\n",
    "    '''\n",
    "    _f = torch.stack([(torch.mm(torch.t(_x), _x) + torch.eye(_x.size()[1], device=device) * l).inverse() for l in lambdas], axis=0) \n",
    "    \n",
    "    # [#lambdas, #feature, #feature]       \n",
    "    return torch.tensordot(_f, _x, dims=[[2],[1]]) # [#lambdas, #feature, #sample]\n",
    "\n",
    "\n",
    "\n",
    "def _cofactor_fn_cpu(_x, lambdas):\n",
    "    '''\n",
    "    Generating a matrix needed to solve ridge regression model for each lambda value.\n",
    "    Ridge regression (Tikhonov) solution is :\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    This func will return (X^T*X + I*lambda)^-1 * X^T. \n",
    "    So once we have that, can just multiply by training data (Y) to get weights.\n",
    "    returned size is [nLambdas x nFeatures x nTrials]\n",
    "    This version makes sure that the torch inverse operation is done on the cpu, and in floating point-64 precision.\n",
    "    Otherwise get bad results for small lambda values. This seems to be a torch-specific bug.\n",
    "    \n",
    "    '''\n",
    "    device_orig = _x.device\n",
    "    type_orig = _x.dtype\n",
    "    # switch to this specific format which works with inverse\n",
    "    _x = _x.to('cpu').to(torch.float64)\n",
    "    _f = torch.stack([(torch.mm(torch.t(_x), _x) + torch.eye(_x.size()[1], device='cpu', dtype=torch.float64) * l).inverse() for l in lambdas], axis=0) \n",
    "    \n",
    "    # [#lambdas, #feature, #feature] \n",
    "    cof = torch.tensordot(_f, _x, dims=[[2],[1]]) # [#lambdas, #feature, #sample]\n",
    "    \n",
    "    # put back to whatever way it was before, so that we can continue with other operations as usual\n",
    "    return cof.to(device_orig).to(type_orig)\n",
    "\n",
    "\n",
    "\n",
    "def _loss_fn(_cofactor, _vtrn, _xout, _vout):\n",
    "    '''\n",
    "    Calculate loss given \"cofactor\" from cofactor_fn, training data, held-out design matrix, held out data.\n",
    "    returns weights (betas) based on equation\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    also returns loss for these weights w the held out data. SSE is loss func here.\n",
    "    '''\n",
    "\n",
    "    _beta = torch.tensordot(_cofactor, _vtrn, dims=[[2], [0]]) # [#lambdas, #feature, #voxel]\n",
    "    _pred = torch.tensordot(_xout, _beta, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "    _loss = torch.sum(torch.pow(_vout[:,None,:] - _pred, 2), dim=0) # [#lambdas, #voxels]\n",
    "    return _beta, _loss\n",
    "\n",
    "    \n",
    "def get_r2(actual,predicted):\n",
    "  \n",
    "    # calculate r2 for this fit.\n",
    "    ssres = np.sum(np.power((predicted - actual),2));\n",
    "#     print(ssres)\n",
    "    sstot = np.sum(np.power((actual - np.mean(actual)),2));\n",
    "#     print(sstot)\n",
    "    r2 = 1-(ssres/sstot)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "def get_fmaps_sizes(_fmaps_fn, image_batch, device):\n",
    "    \"\"\" \n",
    "    Passing a batch of images through feature maps, in order to compute sizes.\n",
    "    Returns number of total features across all groups of maps, and the resolution of each map group.\n",
    "    \"\"\"\n",
    "    n_features = 0\n",
    "    _x = torch.tensor(image_batch).to(device) # the input variable.\n",
    "    _fmaps = _fmaps_fn(_x)\n",
    "    resolutions_each_sf = []\n",
    "    for k,_fm in enumerate(_fmaps):\n",
    "        n_features = n_features + _fm.size()[1]\n",
    "        resolutions_each_sf.append(_fm.size()[2])\n",
    "    \n",
    "    return n_features, resolutions_each_sf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
