{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1dfbfdbf-03ec-4123-8136-870c245b47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Functions to estimate cost for each lambda, by voxel:\n",
    "\n",
    "\n",
    "from numpy.linalg import inv, svd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "import time\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from cvxopt import matrix, solvers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78ef9133-5279-4329-8eb6-710f616cbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "\n",
    "for ff in range(2):\n",
    "    \n",
    "    feature_list.append(np.random.normal(0,1,(100,50)))\n",
    "    \n",
    "dt_1 = np.random.normal(0,1,(100,5))\n",
    "\n",
    "method=\"cross_val_ridge\";\n",
    "n_folds=5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dfa7b0d-3be0-4055-a722-1370e953fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n",
      "(1, 20)\n",
      "(1, 20)\n",
      "(2, 20)\n",
      "(1, 20)\n",
      "(1, 20)\n",
      "(2, 20)\n",
      "(1, 20)\n",
      "(1, 20)\n",
      "(2, 20)\n",
      "(1, 20)\n",
      "(1, 20)\n",
      "(2, 20)\n",
      "(1, 20)\n",
      "(1, 20)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "r2s,\n",
    "stacked_r2s,\n",
    "stacked_r2s_lo,\n",
    "r2s_weighted,\n",
    "r2s_train,\n",
    "stacked_train,\n",
    "S_average,\n",
    "S_average_lo,\n",
    ") = stacking_CV_fmri(dt_1, feature_list, method=\"cross_val_ridge\", n_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f18ac5be-b704-47fe-a80b-a02e9b5a7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt_1\n",
    "features = feature_list\n",
    "\n",
    "n_time = data.shape[0]\n",
    "n_voxels = data.shape[1]\n",
    "n_features = len(features)\n",
    "\n",
    "ind = CV_ind(n_time, n_folds=n_folds)\n",
    "\n",
    "# easier to store r2s in an array and access them programatically than to maintain a different\n",
    "# variable for each\n",
    "r2s = np.zeros((n_features, n_voxels))\n",
    "# r2s_folds = np.zeros((n_folds, n_features, n_voxels))\n",
    "r2s_train_folds = np.zeros((n_folds, n_features, n_voxels))\n",
    "r2s_weighted = np.zeros((n_features, n_voxels))\n",
    "# r2s_weighted_fold = np.zeros((n_folds, n_features, n_voxels))\n",
    "# stacked_r2s_fold = np.zeros((n_folds, n_voxels))\n",
    "stacked_train_r2s_fold = np.zeros((n_folds, n_voxels))\n",
    "\n",
    "# store predictions in array\n",
    "stacked_pred = np.zeros((n_time, n_voxels))\n",
    "preds_test = np.zeros((n_features, n_time, n_voxels))\n",
    "weighted_pred = np.zeros((n_features, n_time, n_voxels))\n",
    "\n",
    "#\n",
    "S_average = np.zeros((n_voxels, n_features))\n",
    "\n",
    "stacked_pred_lo = dict()\n",
    "stacked_train_r2s_fold_lo = dict()\n",
    "S_average_lo = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bd21b6a-34a3-4b98-ae7c-9b7adb01759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(n_features):\n",
    "    stacked_pred_lo[t] = np.zeros((n_time, n_voxels))\n",
    "    stacked_train_r2s_fold_lo[t] = np.zeros((n_folds, n_voxels))\n",
    "    S_average_lo[t] = np.zeros((n_voxels, n_features - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00855d37-71e6-4806-9061-da143373e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_num=0\n",
    "train_ind = ind != ind_num\n",
    "test_ind = ind == ind_num\n",
    "\n",
    "# split data\n",
    "train_data = data[train_ind]\n",
    "train_features = [F[train_ind] for F in features]\n",
    "\n",
    "test_data = data[test_ind]\n",
    "test_features = [F[test_ind] for F in features]\n",
    "\n",
    "# normalize data  <= WE SHOULD ZSCORE BY TRAIN/TEST\n",
    "train_data = np.nan_to_num(zscore(train_data))\n",
    "test_data = np.nan_to_num(zscore(test_data))\n",
    "\n",
    "train_features = [np.nan_to_num(zscore(F)) for F in train_features]\n",
    "test_features = [np.nan_to_num(zscore(F)) for F in test_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9b94d08-8595-4215-80cc-936475d3c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = dict()\n",
    "preds_train = dict()\n",
    "\n",
    "for FEATURE in range(n_features):\n",
    "        if method == \"simple_ridge\":\n",
    "            weights = ridge(train_features[FEATURE], train_data, 100)\n",
    "        elif method == \"cross_val_ridge\":\n",
    "            weights, __ = cross_val_ridge(\n",
    "                train_features[FEATURE],\n",
    "                train_data,\n",
    "                n_splits=4,\n",
    "                lambdas=np.array([10 ** i for i in range(-6, 10)]),\n",
    "                do_plot=False,\n",
    "            )\n",
    "        preds_train[FEATURE] = np.dot(train_features[FEATURE], weights)\n",
    "        err[FEATURE] = train_data - preds_train[FEATURE]\n",
    "        # predict the test data also before overwriting the weights:\n",
    "        preds_test[FEATURE, test_ind] = np.dot(test_features[FEATURE], weights)\n",
    "        # preds_test[FEATURE,test_ind] = zscore(preds_test[FEATURE][test_ind])\n",
    "        # single feature space predictions, computed over a fold\n",
    "        # r2s_folds[ind_num,FEATURE,:] = score_f(preds_test[FEATURE,test_ind],test_data)\n",
    "        r2s_train_folds[ind_num, FEATURE, :] = score_f(\n",
    "            preds_train[FEATURE], train_data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d17bb69-e907-4c58-959f-1cba37786185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "beb1b5a5-6638-4db6-9d2d-4ef18814e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n"
     ]
    }
   ],
   "source": [
    "stacked_pred, stacked_train_r2s_fold, S_average, S = stacked_core(\n",
    "        n_voxels,\n",
    "        range(n_features),\n",
    "        err,\n",
    "        train_data,\n",
    "        preds_test,\n",
    "        preds_train,\n",
    "        test_ind,\n",
    "        ind_num,\n",
    "        stacked_pred,\n",
    "        stacked_train_r2s_fold,\n",
    "        S_average,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d84549a7-4361-4bfc-ad98-a961cb79ad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10518112, 0.1006589 , 0.10645679, 0.01234493, 0.09411569],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_train_r2s_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99186fcd-d01c-48d8-9b36-76a6ed438494",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_use = range(n_features)\n",
    "n_features = len(feat_use)\n",
    "# calculate error matrix for stacking\n",
    "P = np.zeros((n_voxels, n_features, n_features))\n",
    "idI = 0\n",
    "for i in feat_use:\n",
    "    idJ = 0\n",
    "    for j in feat_use:\n",
    "        P[:, idI, idJ] = np.mean(err[i] * err[j], 0)\n",
    "        idJ += 1\n",
    "    idI += 1\n",
    "\n",
    "idI = 0\n",
    "idJ = 0\n",
    "\n",
    "# PROGRAMATICALLY SET THIS FROM THE NUMBER OF FEATURES\n",
    "q = matrix(np.zeros((n_features)))\n",
    "G = matrix(-np.eye(n_features, n_features))\n",
    "h = matrix(np.zeros(n_features))\n",
    "A = matrix(np.ones((1, n_features)))\n",
    "b = matrix(np.ones(1))\n",
    "\n",
    "S = np.zeros((n_voxels, n_features))\n",
    "\n",
    "stacked_pred_train = np.zeros_like(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5985a549-0fac-4f5d-95f6-8fb64e840ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "PP = matrix(P[i])\n",
    "# solve for stacking weights for every voxel\n",
    "S[i, :] = np.array(solvers.qp(PP, q, G, h, A, b)[\"x\"]).reshape(\n",
    "n_features,\n",
    ")\n",
    "# combine the prednp.unique(np.nonzero(dt)[1]).shapeictions from the individual feature spaces for voxel i\n",
    "z = np.array([preds_test[feature_j, test_ind, i] for feature_j in feat_use])\n",
    "if i == 0:\n",
    "    print(z.shape)  # to make sure\n",
    "# multiply the predictions by S[i,:]\n",
    "stacked_pred[test_ind, i] = np.dot(S[i, :], z)\n",
    "# combine the training predictions from the individual feature spaces for voxel i\n",
    "z = np.array([preds_train[feature_j][:, i] for feature_j in feat_use])\n",
    "stacked_pred_train[:, i] = np.dot(S[i, :], z)\n",
    "#             if score_f(stacked_pred_train[:,i],train_data[:,i])>0.1:\n",
    "#                 a = blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54704cb5-0c0a-437a-9bd9-05d6a2141530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 80)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1527e7e1-af68-4b9e-bf36-6db26853543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "702a8c4a-fabb-446e-8708-feb1ed33c54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -0.],\n",
       "       [-0., -1.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.eye(n_features, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79bf6c78-aa91-4ec6-a75c-c2274d9cba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(solvers.qp(PP, q, G, h, A, b)['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f92aafe-64e0-411c-993c-3c5b2f66aa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]+x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1f10d6e-79cc-42dc-a670-d2742dddc278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1e6885e-358a-4189-92aa-0ba319e6bbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8993411]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T @ PP @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "30cb56d8-da18-4c4a-88fe-a82cc0d08a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89934105, 0.94085163],\n",
       "       [0.94085163, 0.9882557 ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6adf179-d3cf-4219-a009-985cd9fe8c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9cbc043b-9293-4a24-8300-de0bf5842230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "637c5961-caae-4e7c-9ff5-082faff5bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b862342b-1eae-49f0-8c0a-7c3f77be4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darwin'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8fd935-c7fb-4170-8a62-7fcdf94bff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_CV_fmri(data, features, method=\"simple_ridge\", n_folds=4):\n",
    "\n",
    "    # INPUTS: data (ntime*nvoxels), features (list of ntime*ndim), method = what to use to train,\n",
    "    #         n_folds = number of cross-val folds\n",
    "\n",
    "    n_time = data.shape[0]\n",
    "    n_voxels = data.shape[1]\n",
    "    n_features = len(features)\n",
    "\n",
    "    ind = CV_ind(n_time, n_folds=n_folds)\n",
    "\n",
    "    # easier to store r2s in an array and access them programatically than to maintain a different\n",
    "    # variable for each\n",
    "    r2s = np.zeros((n_features, n_voxels))\n",
    "    # r2s_folds = np.zeros((n_folds, n_features, n_voxels))\n",
    "    r2s_train_folds = np.zeros((n_folds, n_features, n_voxels))\n",
    "    r2s_weighted = np.zeros((n_features, n_voxels))\n",
    "    # r2s_weighted_fold = np.zeros((n_folds, n_features, n_voxels))\n",
    "    # stacked_r2s_fold = np.zeros((n_folds, n_voxels))\n",
    "    stacked_train_r2s_fold = np.zeros((n_folds, n_voxels))\n",
    "\n",
    "    # store predictions in array\n",
    "    stacked_pred = np.zeros((n_time, n_voxels))\n",
    "    preds_test = np.zeros((n_features, n_time, n_voxels))\n",
    "    weighted_pred = np.zeros((n_features, n_time, n_voxels))\n",
    "\n",
    "    #\n",
    "    S_average = np.zeros((n_voxels, n_features))\n",
    "\n",
    "    stacked_pred_lo = dict()\n",
    "    stacked_train_r2s_fold_lo = dict()\n",
    "    S_average_lo = dict()\n",
    "\n",
    "    for t in range(n_features):\n",
    "        stacked_pred_lo[t] = np.zeros((n_time, n_voxels))\n",
    "        stacked_train_r2s_fold_lo[t] = np.zeros((n_folds, n_voxels))\n",
    "        S_average_lo[t] = np.zeros((n_voxels, n_features - 1))\n",
    "\n",
    "    # DO BY FOLD\n",
    "    for ind_num in range(n_folds):\n",
    "        train_ind = ind != ind_num\n",
    "        test_ind = ind == ind_num\n",
    "\n",
    "        # split data\n",
    "        train_data = data[train_ind]\n",
    "        train_features = [F[train_ind] for F in features]\n",
    "\n",
    "        test_data = data[test_ind]\n",
    "        test_features = [F[test_ind] for F in features]\n",
    "\n",
    "        # normalize data  <= WE SHOULD ZSCORE BY TRAIN/TEST\n",
    "        train_data = np.nan_to_num(zscore(train_data))\n",
    "        test_data = np.nan_to_num(zscore(test_data))\n",
    "\n",
    "        train_features = [np.nan_to_num(zscore(F)) for F in train_features]\n",
    "        test_features = [np.nan_to_num(zscore(F)) for F in test_features]\n",
    "\n",
    "        err = dict()\n",
    "        preds_train = dict()\n",
    "\n",
    "        #         for FEATURE in range(n_features):\n",
    "        #             preds_train[FEATURE], error, preds_test[FEATURE,test_ind], r2s_train_folds[ind_num,FEATURE,:], _ = feat_ridge_CV(train_features[FEATURE],\n",
    "        #                                                                train_data,\n",
    "        #                                                                test_features[FEATURE],method=method)\n",
    "        #             err[FEATURE] = error\n",
    "\n",
    "        for FEATURE in range(n_features):\n",
    "            if method == \"simple_ridge\":\n",
    "                weights = ridge(train_features[FEATURE], train_data, 100)\n",
    "            elif method == \"cross_val_ridge\":\n",
    "                weights, __ = cross_val_ridge(\n",
    "                    train_features[FEATURE],\n",
    "                    train_data,\n",
    "                    n_splits=4,\n",
    "                    lambdas=np.array([10 ** i for i in range(-6, 10)]),\n",
    "                    do_plot=False,\n",
    "                )\n",
    "            preds_train[FEATURE] = np.dot(train_features[FEATURE], weights)\n",
    "            err[FEATURE] = train_data - preds_train[FEATURE]\n",
    "            # predict the test data also before overwriting the weights:\n",
    "            preds_test[FEATURE, test_ind] = np.dot(test_features[FEATURE], weights)\n",
    "            # preds_test[FEATURE,test_ind] = zscore(preds_test[FEATURE][test_ind])\n",
    "            # single feature space predictions, computed over a fold\n",
    "            # r2s_folds[ind_num,FEATURE,:] = score_f(preds_test[FEATURE,test_ind],test_data)\n",
    "            r2s_train_folds[ind_num, FEATURE, :] = score_f(\n",
    "                preds_train[FEATURE], train_data\n",
    "            )\n",
    "\n",
    "        stacked_pred, stacked_train_r2s_fold, S_average, S = stacked_core(\n",
    "            n_voxels,\n",
    "            range(n_features),\n",
    "            err,\n",
    "            train_data,\n",
    "            preds_test,\n",
    "            preds_train,\n",
    "            test_ind,\n",
    "            ind_num,\n",
    "            stacked_pred,\n",
    "            stacked_train_r2s_fold,\n",
    "            S_average,\n",
    "        )\n",
    "\n",
    "        for leave_one in range(n_features):\n",
    "            feat_use = list(range(n_features))\n",
    "            feat_use.remove(leave_one)\n",
    "            (\n",
    "                stacked_pred_lo[leave_one],\n",
    "                stacked_train_r2s_fold_lo[leave_one],\n",
    "                S_average_lo[leave_one],\n",
    "                _,\n",
    "            ) = stacked_core(\n",
    "                n_voxels,\n",
    "                feat_use,\n",
    "                err,\n",
    "                train_data,\n",
    "                preds_test,\n",
    "                preds_train,\n",
    "                test_ind,\n",
    "                ind_num,\n",
    "                stacked_pred_lo[leave_one],\n",
    "                stacked_train_r2s_fold_lo[leave_one],\n",
    "                S_average_lo[leave_one],\n",
    "            )\n",
    "\n",
    "        for FEATURE in range(n_features):\n",
    "            # weight the predictions according to S:\n",
    "            # weighted single feature space predictions, computed over a fold\n",
    "            weighted_pred[FEATURE, test_ind] = (\n",
    "                preds_test[FEATURE, test_ind] * S[:, FEATURE]\n",
    "            )\n",
    "            # r2s_weighted_fold[ind_num,FEATURE,:] = score_f(weighted_pred[FEATURE,test_ind],test_data)\n",
    "\n",
    "    # compute overall\n",
    "    for FEATURE in range(n_features):\n",
    "        r2s[FEATURE, :] = score_f(preds_test[FEATURE], data)\n",
    "        r2s_weighted[FEATURE, :] = score_f(weighted_pred[FEATURE], data)\n",
    "\n",
    "    stacked_r2s = score_f(stacked_pred, data)\n",
    "\n",
    "    stacked_r2s_lo = np.zeros((n_features, n_voxels))\n",
    "    for FEATURE in range(n_features):\n",
    "        stacked_r2s_lo[FEATURE, :] = score_f(stacked_pred_lo[FEATURE], data)\n",
    "        S_average_lo[FEATURE] = S_average_lo[FEATURE] / n_folds\n",
    "\n",
    "    r2s_train = r2s_train_folds.mean(0)\n",
    "    stacked_train = stacked_train_r2s_fold.mean(0)\n",
    "\n",
    "    S_average = S_average / n_folds\n",
    "\n",
    "    return (\n",
    "        r2s,\n",
    "        stacked_r2s,\n",
    "        stacked_r2s_lo,\n",
    "        r2s_weighted,\n",
    "        r2s_train,\n",
    "        stacked_train,\n",
    "        S_average,\n",
    "        S_average_lo,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de554c5-eca7-4e99-bcd0-156f57fb32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def corr(X, Y, axis=0):\n",
    "    # correlation coefficient\n",
    "    return np.mean(zscore(X) * zscore(Y), axis)\n",
    "\n",
    "\n",
    "def R2(Pred, Real):\n",
    "    # coefficient of determination\n",
    "    # R^2 = 1 -  residual sum of squares/total sum of squares\n",
    "    SSres = np.mean((Real - Pred) ** 2, 0)\n",
    "    SStot = np.var(Real, 0)\n",
    "    return np.nan_to_num(1 - SSres / SStot)\n",
    "\n",
    "\n",
    "def fit_predict(data, features, n_folds=10):\n",
    "    n, v = data.shape\n",
    "    p = features.shape[1]\n",
    "    corrs = np.zeros((n_folds, v))\n",
    "    R2s = np.zeros((n_folds, v))\n",
    "    ind = CV_ind(n, n_folds)\n",
    "    preds_all = np.zeros_like(data)\n",
    "    for i in range(n_folds):\n",
    "        train_data = np.nan_to_num(zscore(data[ind != i]))\n",
    "        train_features = np.nan_to_num(zscore(features[ind != i]))\n",
    "        test_data = np.nan_to_num(zscore(data[ind == i]))\n",
    "        test_features = np.nan_to_num(zscore(features[ind == i]))\n",
    "        weights, __ = cross_val_ridge(train_features, train_data)\n",
    "        preds = np.dot(test_features, weights)\n",
    "        preds_all[ind == i] = preds\n",
    "    #         print(\"fold {}\".format(i))\n",
    "    corrs = corr(preds_all, data)\n",
    "    R2s = R2(preds_all, data)\n",
    "    return corrs, R2s\n",
    "\n",
    "\n",
    "def CV_ind(n, n_folds):\n",
    "    ind = np.zeros((n))\n",
    "    n_items = int(np.floor(n / n_folds))\n",
    "    for i in range(0, n_folds - 1):\n",
    "        ind[i * n_items : (i + 1) * n_items] = i\n",
    "    ind[(n_folds - 1) * n_items :] = n_folds - 1\n",
    "    return ind\n",
    "\n",
    "\n",
    "def R2r(Pred, Real):\n",
    "    # square root of R^2\n",
    "    R2rs = R2(Pred, Real)\n",
    "    ind_neg = R2rs < 0  # pick out negative ones\n",
    "    R2rs = np.abs(R2rs)  # use absolute value to calculate sqaure root\n",
    "    R2rs = np.sqrt(R2rs)\n",
    "    R2rs[ind_neg] *= -1  # recover negative data\n",
    "    return R2rs\n",
    "\n",
    "\n",
    "def ridge(X, Y, lmbda):\n",
    "    # weight of ridge regression\n",
    "    return np.dot(inv(X.T.dot(X) + lmbda * np.eye(X.shape[1])), X.T.dot(Y))\n",
    "\n",
    "\n",
    "def lasso(X, Y, lmbda):\n",
    "    return soft_ths(ols(X, Y), X.shape[0] * lmbda)\n",
    "\n",
    "\n",
    "def soft_ths(X, alpha):\n",
    "    Y = np.zeros_like(X)\n",
    "    Y[X > alpha] = (X - alpha)[X > alpha]\n",
    "    Y[X < alpha] = (X + alpha)[X < alpha]\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "# def soft_threshold(alpha, beta):\n",
    "#     if beta > alpha:\n",
    "#         return beta - alpha\n",
    "#     elif beta < -alpha:\n",
    "#         return beta + alpha\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "\n",
    "def ols(X, Y):\n",
    "    return np.dot(np.linalg.pinv(X.T.dot(X)), X.T.dot(Y))\n",
    "    # return np.linalg.inv(X.T @ X) @ (X.T @ Y)\n",
    "\n",
    "\n",
    "def ridge_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])):\n",
    "    # validation error of ridge regression under different lambdas\n",
    "    error = np.zeros((lambdas.shape[0], Y.shape[1]))\n",
    "    for idx, lmbda in enumerate(lambdas):\n",
    "        weights = ridge(X, Y, lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def lasso_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])):\n",
    "    # validation error of ridge regression under different lambdas\n",
    "    error = np.zeros((lambdas.shape[0], Y.shape[1]))\n",
    "    for idx, lmbda in enumerate(lambdas):\n",
    "        weights = lasso(X, Y, lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def ols_err(X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])):\n",
    "    error = np.zeros(Y.shape[1])\n",
    "    weights = ols(X, Y)\n",
    "    error = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def ridge_sk(X, Y, lmbda):\n",
    "    rd = Ridge(alpha=lmbda)\n",
    "    rd.fit(X, Y)\n",
    "    return rd.coef_.T\n",
    "\n",
    "\n",
    "def ridgeCV_sk(X, Y, lmbdas):\n",
    "    rd = RidgeCV(alphas=lmbdas, solver=\"svd\")\n",
    "    rd.fit(X, Y)\n",
    "    return rd.coef_.T\n",
    "\n",
    "\n",
    "def ridge_by_lambda_sk(X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])):\n",
    "    error = np.zeros((lambdas.shape[0], Y.shape[1]))\n",
    "    for idx, lmbda in enumerate(lambdas):\n",
    "        weights = ridge_sk(X, Y, lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def ridge_svd(X, Y, lmbda):\n",
    "    U, s, Vt = svd(X, full_matrices=False)\n",
    "    d = s / (s ** 2 + lmbda)\n",
    "    return np.dot(Vt, np.diag(d).dot(U.T.dot(Y)))\n",
    "\n",
    "\n",
    "def ridge_by_lambda_svd(X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])):\n",
    "    error = np.zeros((lambdas.shape[0], Y.shape[1]))\n",
    "    U, s, Vt = svd(X, full_matrices=False)\n",
    "    for idx, lmbda in enumerate(lambdas):\n",
    "        d = s / (s ** 2 + lmbda)\n",
    "        weights = np.dot(Vt, np.diag(d).dot(U.T.dot(Y)))\n",
    "        error[idx] = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def kernel_ridge(X, Y, lmbda):\n",
    "    return np.dot(X.T.dot(inv(X.dot(X.T) + lmbda * np.eye(X.shape[0]))), Y)\n",
    "\n",
    "\n",
    "def kernel_ridge_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])):\n",
    "    error = np.zeros((lambdas.shape[0], Y.shape[1]))\n",
    "    for idx, lmbda in enumerate(lambdas):\n",
    "        weights = kernel_ridge(X, Y, lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def kernel_ridge_svd(X, Y, lmbda):\n",
    "    U, s, Vt = svd(X.T, full_matrices=False)\n",
    "    d = s / (s ** 2 + lmbda)\n",
    "    return np.dot(np.dot(U, np.diag(d).dot(Vt)), Y)\n",
    "\n",
    "\n",
    "def kernel_ridge_by_lambda_svd(\n",
    "    X, Y, Xval, Yval, lambdas=np.array([0.1, 1, 10, 100, 1000])\n",
    "):\n",
    "    error = np.zeros((lambdas.shape[0], Y.shape[1]))\n",
    "    U, s, Vt = svd(X.T, full_matrices=False)\n",
    "    for idx, lmbda in enumerate(lambdas):\n",
    "        d = s / (s ** 2 + lmbda)\n",
    "        weights = np.dot(np.dot(U, np.diag(d).dot(Vt)), Y)\n",
    "        error[idx] = 1 - R2(np.dot(Xval, weights), Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def cross_val_ridge(\n",
    "    train_features,\n",
    "    train_data,\n",
    "    n_splits=10,\n",
    "    lambdas=np.array([10 ** i for i in range(-6, 10)]),\n",
    "    method=\"plain\",\n",
    "    do_plot=False,\n",
    "):\n",
    "    # cross validation for ridge regression\n",
    "\n",
    "    ridge_1 = dict(\n",
    "        plain=ridge_by_lambda,\n",
    "        svd=ridge_by_lambda_svd,\n",
    "        kernel_ridge=kernel_ridge_by_lambda,\n",
    "        kernel_ridge_svd=kernel_ridge_by_lambda_svd,\n",
    "        ridge_sk=ridge_by_lambda_sk,\n",
    "    )[\n",
    "        method\n",
    "    ]  # loss of the regressor\n",
    "    ridge_2 = dict(\n",
    "        plain=ridge,\n",
    "        svd=ridge_svd,\n",
    "        kernel_ridge=kernel_ridge,\n",
    "        kernel_ridge_svd=kernel_ridge_svd,\n",
    "        ridge_sk=ridge_sk,\n",
    "    )[\n",
    "        method\n",
    "    ]  # solver for the weights\n",
    "\n",
    "    n_voxels = train_data.shape[1]  # get number of voxels from data\n",
    "    nL = lambdas.shape[0]  # get number of hyperparameter (lambdas) from setting\n",
    "    r_cv = np.zeros((nL, train_data.shape[1]))  # loss matrix\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)  # set up dataset for cross validation\n",
    "    start_t = time.time()  # record start time\n",
    "    for icv, (trn, val) in enumerate(kf.split(train_data)):\n",
    "        # print('ntrain = {}'.format(train_features[trn].shape[0]))\n",
    "        cost = ridge_1(\n",
    "            train_features[trn],\n",
    "            train_data[trn],\n",
    "            train_features[val],\n",
    "            train_data[val],\n",
    "            lambdas=lambdas,\n",
    "        )  # loss of regressor 1\n",
    "        if do_plot:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(cost, aspect=\"auto\")\n",
    "        r_cv += cost\n",
    "    #         if icv%3 ==0:\n",
    "    #             print(icv)\n",
    "    #         print('average iteration length {}'.format((time.time()-start_t)/(icv+1))) # time used\n",
    "    if do_plot:  # show loss\n",
    "        plt.figure()\n",
    "        plt.imshow(r_cv, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "\n",
    "    argmin_lambda = np.argmin(r_cv, axis=0)  # pick the best lambda\n",
    "    weights = np.zeros(\n",
    "        (train_features.shape[1], train_data.shape[1])\n",
    "    )  # initialize the weight\n",
    "    for idx_lambda in range(\n",
    "        lambdas.shape[0]\n",
    "    ):  # this is much faster than iterating over voxels!\n",
    "        idx_vox = argmin_lambda == idx_lambda\n",
    "        weights[:, idx_vox] = ridge_2(\n",
    "            train_features, train_data[:, idx_vox], lambdas[idx_lambda]\n",
    "        )\n",
    "    if do_plot:  # show the weights\n",
    "        plt.figure()\n",
    "        plt.imshow(weights, aspect=\"auto\", cmap=\"RdBu_r\", vmin=-0.5, vmax=0.5)\n",
    "\n",
    "    return weights, np.array([lambdas[i] for i in argmin_lambda])\n",
    "\n",
    "\n",
    "def cross_val_lasso(\n",
    "    train_features,\n",
    "    train_data,\n",
    "    n_splits=10,\n",
    "    lambdas=np.array([10 ** i for i in range(-6, 10)]),\n",
    "    method=\"plain\",\n",
    "    do_plot=False,\n",
    "):\n",
    "    # cross validation for ridge regression\n",
    "\n",
    "    # ridge_1 = dict(plain = ridge_by_lambda,\n",
    "    #                svd = ridge_by_lambda_svd,\n",
    "    #                kernel_ridge = kernel_ridge_by_lambda,\n",
    "    #                kernel_ridge_svd = kernel_ridge_by_lambda_svd,\n",
    "    #                ridge_sk = ridge_by_lambda_sk)[method] #loss of the regressor\n",
    "    # ridge_2 = dict(plain = ridge,\n",
    "    #                svd = ridge_svd,\n",
    "    #                kernel_ridge = kernel_ridge,\n",
    "    #                kernel_ridge_svd = kernel_ridge_svd,\n",
    "    #                ridge_sk = ridge_sk)[method] # solver for the weights\n",
    "\n",
    "    n_voxels = train_data.shape[1]  # get number of voxels from data\n",
    "    nL = lambdas.shape[0]  # get number of hyperparameter (lambdas) from setting\n",
    "    r_cv = np.zeros((nL, train_data.shape[1]))  # loss matrix\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)  # set up dataset for cross validation\n",
    "    start_t = time.time()  # record start time\n",
    "    for icv, (trn, val) in enumerate(kf.split(train_data)):\n",
    "        print(\"ntrain = {}\".format(train_features[trn].shape[0]))\n",
    "        cost = lasso_by_lambda(\n",
    "            train_features[trn],\n",
    "            train_data[trn],\n",
    "            train_features[val],\n",
    "            train_data[val],\n",
    "            lambdas=lambdas,\n",
    "        )  # loss of regressor 1\n",
    "        if do_plot:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(cost, aspect=\"auto\")\n",
    "        r_cv += cost\n",
    "        if icv % 3 == 0:\n",
    "            print(icv)\n",
    "        print(\n",
    "            \"average iteration length {}\".format((time.time() - start_t) / (icv + 1))\n",
    "        )  # time used\n",
    "    if do_plot:  # show loss\n",
    "        plt.figure()\n",
    "        plt.imshow(r_cv, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "\n",
    "    argmin_lambda = np.argmin(r_cv, axis=0)  # pick the best lambda\n",
    "    weights = np.zeros(\n",
    "        (train_features.shape[1], train_data.shape[1])\n",
    "    )  # initialize the weight\n",
    "    for idx_lambda in range(\n",
    "        lambdas.shape[0]\n",
    "    ):  # this is much faster than iterating over voxels!\n",
    "        idx_vox = argmin_lambda == idx_lambda\n",
    "        weights[:, idx_vox] = lasso(\n",
    "            train_features, train_data[:, idx_vox], lambdas[idx_lambda]\n",
    "        )\n",
    "    if do_plot:  # show the weights\n",
    "        plt.figure()\n",
    "        plt.imshow(weights, aspect=\"auto\", cmap=\"RdBu_r\", vmin=-0.5, vmax=0.5)\n",
    "\n",
    "    return weights, np.array([lambdas[i] for i in argmin_lambda])\n",
    "\n",
    "\n",
    "def cross_val_ols(\n",
    "    train_features,\n",
    "    train_data,\n",
    "    n_splits=10,\n",
    "    lambdas=np.array([10 ** i for i in range(-6, 10)]),\n",
    "    method=\"plain\",\n",
    "    do_plot=False,\n",
    "):\n",
    "    # cross validation for ridge regression\n",
    "\n",
    "    # ridge_1 = dict(plain = ridge_by_lambda,\n",
    "    #                svd = ridge_by_lambda_svd,\n",
    "    #                kernel_ridge = kernel_ridge_by_lambda,\n",
    "    #                kernel_ridge_svd = kernel_ridge_by_lambda_svd,\n",
    "    #                ridge_sk = ridge_by_lambda_sk)[method] #loss of the regressor\n",
    "    # ridge_2 = dict(plain = ridge,\n",
    "    #                svd = ridge_svd,\n",
    "    #                kernel_ridge = kernel_ridge,\n",
    "    #                kernel_ridge_svd = kernel_ridge_svd,\n",
    "    #                ridge_sk = ridge_sk)[method] # solver for the weights\n",
    "\n",
    "    n_voxels = train_data.shape[1]  # get number of voxels from data\n",
    "    nL = lambdas.shape[0]  # get number of hyperparameter (lambdas) from setting\n",
    "    r_cv = np.zeros((nL, train_data.shape[1]))  # loss matrix\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)  # set up dataset for cross validation\n",
    "    start_t = time.time()  # record start time\n",
    "    for icv, (trn, val) in enumerate(kf.split(train_data)):\n",
    "        print(\"ntrain = {}\".format(train_features[trn].shape[0]))\n",
    "        cost = ols_err(\n",
    "            train_features[trn],\n",
    "            train_data[trn],\n",
    "            train_features[val],\n",
    "            train_data[val],\n",
    "            lambdas=lambdas,\n",
    "        )  # loss of regressor 1\n",
    "        if do_plot:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(cost, aspect=\"auto\")\n",
    "        r_cv += cost\n",
    "        if icv % 3 == 0:\n",
    "            print(icv)\n",
    "        print(\n",
    "            \"average iteration length {}\".format((time.time() - start_t) / (icv + 1))\n",
    "        )  # time used\n",
    "    if do_plot:  # show loss\n",
    "        plt.figure()\n",
    "        plt.imshow(r_cv, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "\n",
    "    argmin_lambda = np.argmin(r_cv, axis=0)  # pick the best lambda\n",
    "    weights = np.zeros(\n",
    "        (train_features.shape[1], train_data.shape[1])\n",
    "    )  # initialize the weight\n",
    "    for idx_lambda in range(\n",
    "        lambdas.shape[0]\n",
    "    ):  # this is much faster than iterating over voxels!\n",
    "        idx_vox = argmin_lambda == idx_lambda\n",
    "        weights[:, idx_vox] = ols(train_features, train_data[:, idx_vox])\n",
    "    if do_plot:  # show the weights\n",
    "        plt.figure()\n",
    "        plt.imshow(weights, aspect=\"auto\", cmap=\"RdBu_r\", vmin=-0.5, vmax=0.5)\n",
    "\n",
    "    return weights, np.array([lambdas[i] for i in argmin_lambda])\n",
    "\n",
    "\n",
    "def GCV_ridge(\n",
    "    train_features, train_data, lambdas=np.array([10 ** i for i in range(-6, 10)])\n",
    "):\n",
    "\n",
    "    n_lambdas = lambdas.shape[0]\n",
    "    n_voxels = train_data.shape[1]\n",
    "    n_time = train_data.shape[0]\n",
    "    n_p = train_features.shape[1]\n",
    "\n",
    "    CVerr = np.zeros((n_lambdas, n_voxels))\n",
    "\n",
    "    # % If we do an eigendecomp first we can quickly compute the inverse for many different values\n",
    "    # % of lambda. SVD uses X = UDV' form.\n",
    "    # % First compute K0 = (X'X + lambda*I) where lambda = 0.\n",
    "    # K0 = np.dot(train_features,train_features.T)\n",
    "    print(\n",
    "        \"Running svd\",\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    [U, D, Vt] = svd(train_features, full_matrices=False)\n",
    "    V = Vt.T\n",
    "    print(U.shape, D.shape, Vt.shape)\n",
    "    print(\"svd time: {}\".format(time.time() - start_time))\n",
    "\n",
    "    for i, regularizationParam in enumerate(lambdas):\n",
    "        regularizationParam = lambdas[i]\n",
    "        print(\"CVLoop: Testing regularization param: {}\".format(regularizationParam))\n",
    "\n",
    "        # Now we can obtain Kinv for any lambda doing Kinv = V * (D + lambda*I)^-1 U'\n",
    "        dlambda = D ** 2 + np.eye(n_p) * regularizationParam\n",
    "        dlambdaInv = np.diag(D / np.diag(dlambda))\n",
    "        KlambdaInv = V.dot(dlambdaInv).dot(U.T)\n",
    "\n",
    "        # Compute S matrix of Hastie Trick  H = X(XT X + lambdaI)-1XT\n",
    "        S = np.dot(U, np.diag(D * np.diag(dlambdaInv))).dot(U.T)\n",
    "        denum = 1 - np.trace(S) / n_time\n",
    "\n",
    "        # Solve for weight matrix so we can compute residual\n",
    "        weightMatrix = KlambdaInv.dot(train_data)\n",
    "\n",
    "        #         Snorm = np.tile(1 - np.diag(S) , (n_voxels, 1)).T\n",
    "        YdiffMat = train_data - (train_features.dot(weightMatrix))\n",
    "        YdiffMat = YdiffMat / denum\n",
    "        CVerr[i, :] = (1 / n_time) * np.sum(YdiffMat * YdiffMat, 0)\n",
    "\n",
    "    # try using min of avg err\n",
    "    minerrIndex = np.argmin(CVerr, axis=0)\n",
    "    r = np.zeros((n_voxels))\n",
    "\n",
    "    for nPar, regularizationParam in enumerate(lambdas):\n",
    "        ind = np.where(minerrIndex == nPar)[0]\n",
    "        if len(ind) > 0:\n",
    "            r[ind] = regularizationParam\n",
    "            print(\n",
    "                \"{}% of outputs with regularization param: {}\".format(\n",
    "                    int(len(ind) / n_voxels * 100), regularizationParam\n",
    "                )\n",
    "            )\n",
    "            # got good param, now obtain weights\n",
    "            dlambda = D ** 2 + np.eye(n_p) * regularizationParam\n",
    "            dlambdaInv = np.diag(D / np.diag(dlambda))\n",
    "            KlambdaInv = V.dot(dlambdaInv).dot(U.T)\n",
    "\n",
    "            weightMatrix[:, ind] = KlambdaInv.dot(train_data[:, ind])\n",
    "\n",
    "    return weightMatrix, r\n",
    "\n",
    "\n",
    "score_f = R2\n",
    "# score_f = corr\n",
    "# score_f = cosine\n",
    "\n",
    "\n",
    "def CV_ind(n, n_folds):\n",
    "    # index for cross validation\n",
    "    ind = np.zeros((n))\n",
    "    n_items = int(np.floor(n / n_folds))  # number of items in one fold\n",
    "    for i in range(0, n_folds - 1):\n",
    "        ind[i * n_items : (i + 1) * n_items] = i\n",
    "    ind[(n_folds - 1) * n_items :] = n_folds - 1\n",
    "    return ind\n",
    "\n",
    "\n",
    "def stacked_core(\n",
    "    n_voxels,\n",
    "    feat_use,\n",
    "    err,\n",
    "    train_data,\n",
    "    preds_test,\n",
    "    preds_train,\n",
    "    test_ind,\n",
    "    ind_num,\n",
    "    stacked_pred,\n",
    "    stacked_train_r2s_fold,\n",
    "    S_average,\n",
    "):\n",
    "\n",
    "    n_features = len(feat_use)\n",
    "    # calculate error matrix for stacking\n",
    "    P = np.zeros((n_voxels, n_features, n_features))\n",
    "    idI = 0\n",
    "    for i in feat_use:\n",
    "        idJ = 0\n",
    "        for j in feat_use:\n",
    "            P[:, idI, idJ] = np.mean(err[i] * err[j], 0)\n",
    "            idJ += 1\n",
    "        idI += 1\n",
    "\n",
    "    idI = 0\n",
    "    idJ = 0\n",
    "\n",
    "    # PROGRAMATICALLY SET THIS FROM THE NUMBER OF FEATURES\n",
    "    q = matrix(np.zeros((n_features)))\n",
    "    G = matrix(-np.eye(n_features, n_features))\n",
    "    h = matrix(np.zeros(n_features))\n",
    "    A = matrix(np.ones((1, n_features)))\n",
    "    b = matrix(np.ones(1))\n",
    "\n",
    "    S = np.zeros((n_voxels, n_features))\n",
    "\n",
    "    stacked_pred_train = np.zeros_like(train_data)\n",
    "\n",
    "    for i in range(0, n_voxels):\n",
    "        PP = matrix(P[i])\n",
    "        # solve for stacking weights for every voxel\n",
    "        S[i, :] = np.array(solvers.qp(PP, q, G, h, A, b)[\"x\"]).reshape(\n",
    "            n_features,\n",
    "        )\n",
    "        # combine the prednp.unique(np.nonzero(dt)[1]).shapeictions from the individual feature spaces for voxel i\n",
    "        z = np.array([preds_test[feature_j, test_ind, i] for feature_j in feat_use])\n",
    "        if i == 0:\n",
    "            print(z.shape)  # to make sure\n",
    "        # multiply the predictions by S[i,:]\n",
    "        stacked_pred[test_ind, i] = np.dot(S[i, :], z)\n",
    "        # combine the training predictions from the individual feature spaces for voxel i\n",
    "        z = np.array([preds_train[feature_j][:, i] for feature_j in feat_use])\n",
    "        stacked_pred_train[:, i] = np.dot(S[i, :], z)\n",
    "    #             if score_f(stacked_pred_train[:,i],train_data[:,i])>0.1:\n",
    "    #                 a = blablabla\n",
    "\n",
    "    S_average += S\n",
    "\n",
    "    # stacked prediction, computed over a fold\n",
    "    # stacked_r2s_fold[ind_num,:] = score_f(stacked_pred[test_ind],test_data)\n",
    "\n",
    "    stacked_train_r2s_fold[ind_num, :] = score_f(stacked_pred_train, train_data)\n",
    "\n",
    "    return stacked_pred, stacked_train_r2s_fold, S_average, S\n",
    "\n",
    "\n",
    "# THIS IS HOW I WOULD RUN A REGRESSION ANALYSIS: VERY VERY IMPORTANT\n",
    "# FMRI IS SLOW IN TIME AND WE CANNOT SAMPLE RANDOM POINTS... INSTEAD\n",
    "# WE HAVE TO USE CONTIGUOUS BLOCKS\n",
    "\n",
    "solvers.options[\"show_progress\"] = False\n",
    "\n",
    "score_f = R2\n",
    "# score_f = corr\n",
    "# score_f = cosine\n",
    "\n",
    "\n",
    "def CV_ind(n, n_folds):\n",
    "    # index for cross validation\n",
    "    ind = np.zeros((n))\n",
    "    n_items = int(np.floor(n / n_folds))  # number of items in one fold\n",
    "    for i in range(0, n_folds - 1):\n",
    "        ind[i * n_items : (i + 1) * n_items] = i\n",
    "    ind[(n_folds - 1) * n_items :] = n_folds - 1\n",
    "    return ind\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
