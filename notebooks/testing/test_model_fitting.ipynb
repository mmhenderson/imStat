{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import fft, ifft\n",
    "import scipy\n",
    "\n",
    "from skimage import data\n",
    "from skimage import io, transform, color\n",
    "from skimage.util import img_as_float, pad\n",
    "from skimage.filters import gabor_kernel\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import nibabel as nib\n",
    "\n",
    "import gfb_utils as g\n",
    "import nsd_utils as n\n",
    "import model_fitting as m\n",
    "\n",
    "sys.path.append('/user_data/mmhender/coco_annot/cocoapi/PythonAPI/')\n",
    "from pycocotools.coco import COCO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d789483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gfb_encoding_model(nn.Module):\n",
    "    \"\"\"\n",
    "    Definition of a simple linear encoding model that can be fit with grad descent.\n",
    "    nFeats would be e.g. number of feature maps. \n",
    "    \"\"\"\n",
    "    def __init__(self, nFeats, nVoxels, nRFs):\n",
    "    \n",
    "        super(gfb_encoding_model, self).__init__()\n",
    "#         self.bank = filter_bank\n",
    "        self.nFeats = nFeats\n",
    "        self.nVoxels = nVoxels\n",
    "        self.nRFs = nRFs\n",
    "        self.weights = nn.Parameter(torch.randn(nFeats, nVoxels, nRFs) / np.sqrt(nFeats*nVoxels*nRFs))\n",
    "        self.bias = nn.Parameter(torch.zeros(nVoxels, nRFs))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        nTrials = x.shape[0]\n",
    "        out = torch.zeros(nTrials, self.nVoxels, self.nRFs)\n",
    "        for rf in range(nRFs):   \n",
    "            out[:,:,rf] = torch.matmul(x[:,:,rf], self.weights[:,:,rf]) + self.bias[:,rf]\n",
    "        pred_resp = out\n",
    "#         pred_resp = torch.matmul(x, self.weights) + torch.tile(self.bias,[nTrials, 1]) \n",
    "        return pred_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4795b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of filter stack will be:\n",
      "(600, 600, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:24<00:00, 12.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 200, 200, 216)\n"
     ]
    }
   ],
   "source": [
    "## Making the filters here:\n",
    "\n",
    "# First define the feature bank itself\n",
    "freqs_cpp = np.round(np.logspace(np.log10(0.02), np.log10(0.25), 6),2)\n",
    "orient_step = 5\n",
    "orients_deg = np.arange(0,181-orient_step, orient_step)\n",
    "spat_freq_bw = 1\n",
    "spat_aspect_ratio = 1\n",
    "n_sd_out = 7\n",
    "\n",
    "# Specify stuff about images\n",
    "process_at_size = [200,200]\n",
    "\n",
    "bank = g.filter_bank(orients_deg, freqs_cpp, spat_freq_bw, spat_aspect_ratio, n_sd_out, image_size = process_at_size)\n",
    "nsd_inds = [0,1]\n",
    "all_feat = g.get_nsd_gabor_feat(nsd_inds, bank)\n",
    "                            \n",
    "print(np.shape(all_feat))    \n",
    "\n",
    "# Create set of candidate RFs\n",
    "sizes = np.arange(5, 21, 5)\n",
    "x_centers = np.arange(20, 181, 20)\n",
    "y_centers = np.arange(20, 181, 20)\n",
    "\n",
    "rf_stack, x_list, y_list, size_list  = g.get_rf_stack(x_centers, y_centers, sizes, process_at_size)\n",
    "\n",
    "nRFs = np.shape(rf_stack)[2]\n",
    "nFeats = np.shape(all_feat)[3]\n",
    "\n",
    "# Making a full matrix, [nIms x nFeatures x nRFs]\n",
    "# feats_by_rfs = g.get_feats_by_rfs(all_feat, rf_stack)\n",
    "\n",
    "# print(np.shape(feats_by_rfs))\n",
    "# nFeats = np.shape(feats_by_rfs)[1]\n",
    "# nRFs = np.shape(feats_by_rfs)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97a1c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'curr_batch_trn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7570d2eaf2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurr_batch_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'curr_batch_trn' is not defined"
     ]
    }
   ],
   "source": [
    "curr_batch_trn['subject_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b275eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5py loading time is 6.10\n",
      "h5py loading time is 5.85\n",
      "h5py loading time is 6.30\n",
      "h5py loading time is 5.75\n",
      "h5py loading time is 7.89\n",
      "h5py loading time is 9.64\n",
      "h5py loading time is 9.53\n",
      "h5py loading time is 11.62\n",
      "h5py loading time is 9.44\n",
      "h5py loading time is 7.37\n",
      "h5py loading time is 6.48\n",
      "h5py loading time is 6.62\n",
      "h5py loading time is 6.69\n",
      "h5py loading time is 7.29\n"
     ]
    }
   ],
   "source": [
    "## Set up training skeleton\n",
    "\n",
    "\n",
    "# First info abt subject, ROI to look at\n",
    "subj = 1\n",
    "roi_label = 1\n",
    "roi_filename='lh.prf-visualrois.nii.gz'\n",
    "roi_voxels = n.get_roi_voxels(subj, roi_label, roi_filename)\n",
    "nVox = np.shape(roi_voxels)[1]\n",
    "\n",
    "dset = n.nsd_dataset(subj, voxel_inds = roi_voxels)\n",
    "trn, val, _ = n.get_dataset_splits(dset)\n",
    "val_batch_size = 2\n",
    "trn_batch_size = 50\n",
    "valgenerator = n.nsd_dataloader(val, batch_size=val_batch_size, shuffle=True, rndseed = 858875)\n",
    "trngenerator = n.nsd_dataloader(trn, batch_size=trn_batch_size, shuffle=True, rndseed = 543545)\n",
    "\n",
    "curr_batch_trn = next(trngenerator)\n",
    "# Data for this batch, trials x voxels\n",
    "dat2fit = curr_batch_trn['data']\n",
    "# Which images were shown on these trials? get indices into NSD 0-73000\n",
    "nsd_inds = curr_batch_trn['subject_df']['nsdId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48463a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting features for this batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:51<00:00,  8.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get features for these images based on gabor filter bank (already defined)\n",
    "print('getting features for this batch')\n",
    "all_feat = g.get_nsd_gabor_feat(nsd_inds, bank)    \n",
    "\n",
    "# Combine these features with all the possible RFs\n",
    "feats_by_rfs = g.get_feats_by_rfs(all_feat, rf_stack)\n",
    "x = feats_by_rfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509c7a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 - getting batch ready\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss_sse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a23214e2c506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# first get predictions and loss for the current weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mpred_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat2fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnRFs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mloss_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_sse' is not defined"
     ]
    }
   ],
   "source": [
    "lr = 10e-12\n",
    "\n",
    "model = gfb_encoding_model(nFeats, nVox, nRFs).double()\n",
    "\n",
    "loss_all = np.zeros([nRFs, nVox])\n",
    "\n",
    "max_steps = 50\n",
    "\n",
    "# counting total passes over the entire training set (nepochs = nsteps/nbatches)\n",
    "nepochs_done = 0 \n",
    "   \n",
    "# loop over training steps \n",
    "# one step=one weight update, based on one batch of data\n",
    "for step in range(max_steps):\n",
    "\n",
    "    print('step %d - getting batch ready'%step)\n",
    "#     # first get the next batch of data from trn set\n",
    "#     try:\n",
    "#       # try taking next sample from current iterator object\n",
    "#       curr_batch_trn = next(trngenerator)\n",
    "#     except StopIteration:\n",
    "#       # if the previous iterator object is exhausted, then the epoch is finished, \n",
    "#       # need to make a new iterator for next epoch.\n",
    "#       nepochs_done = nepochs_done+1;\n",
    "#       trngenerator = n.nsd_dataloader(trn, batch_size=trn_batch_size, shuffle=True, rndseed = (543545+n_epochs_done))\n",
    "#       curr_batch_trn = next(trngenerator)\n",
    "\n",
    "#       print('STARTING EPOCH %d'%nepochs_done)\n",
    "    \n",
    "#     # Data for this batch, trials x voxels\n",
    "#     dat2fit = curr_batch_trn['data']\n",
    "    \n",
    "#     # Which images were shown on these trials? get indices into NSD 0-73000\n",
    "#     nsd_inds = curr_batch_trn['subject_df']['nsdId']\n",
    "    \n",
    "#     # Get features for these images based on gabor filter bank (already defined)\n",
    "#     print('getting features for this batch')\n",
    "#     all_feat = g.get_nsd_gabor_feat(nsd_inds, bank)    \n",
    "    \n",
    "#     # Combine these features with all the possible RFs\n",
    "#     feats_by_rfs = g.get_feats_by_rfs(all_feat, rf_stack)\n",
    "#     rf=0\n",
    "#     x = feats_by_rfs\n",
    "    \n",
    "    # first get predictions and loss for the current weights.\n",
    "    pred_resp = model(x) \n",
    "    loss = loss_sse(pred_resp, np.tile(dat2fit[:,:,np.newaxis], [1,1,nRFs]))\n",
    "    loss_all = loss.detach().numpy()\n",
    "        \n",
    "    # Summing over all voxels and RFs. Because need a scalar value for loss.\n",
    "    # If we minimize this value, it is same as minimizing for one voxel/RF at a time.\n",
    "    # This works because the weights that contribute to a given voxel and a given RF are \n",
    "    # restricted to one column of weight matrix.\n",
    "    summed_loss = torch.sum(loss)\n",
    "    \n",
    "    print('step %d, summed loss is %.2e'%(step, summed_loss.item()))\n",
    "    \n",
    "    # run the graph backward, to get gradient values. \n",
    "    summed_loss.backward()\n",
    "#     print('one selected units gradient is %.6f'%model.weights.grad[0,0,0])\n",
    "#     print('weight of that unit before update is %.6f'%model.weights[0,0,0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # update weights based on this learning step\n",
    "        model.weights -= model.weights.grad * lr\n",
    "        model.bias -= model.bias.grad * lr\n",
    "        # zero the gradients out before next step\n",
    "        model.weights.grad.zero_()\n",
    "        model.bias.grad.zero_()\n",
    "\n",
    "#     print('weight of that unit after update is %.6f'%model.weights[0,0,0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(loss_all))\n",
    "best_spat_rf = np.argmin(loss_all,axis=1)\n",
    "best_spat_rf.shape\n",
    "\n",
    "dat_pred = pred_resp.detach().numpy()\n",
    "\n",
    "nTrials = np.shape(dat_pred)[0]\n",
    "\n",
    "best_pred_resp = np.zeros([nTrials, nVoxels])\n",
    "for vv in range(nVoxels):\n",
    "\n",
    "    best_pred_resp[:,vv] = dat_pred[:,vv,best_spat_rf[vv]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(dat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8cd4c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00e-04\n"
     ]
    }
   ],
   "source": [
    "print('%.2e'%0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e61c10e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41780.29431899, 33562.17129152, 12991.80968866, ...,\n",
       "         8182.211206  , 13622.49080108,  5935.08898458],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ],\n",
       "       ...,\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_all[rf,:] = loss.detach().numpy()\n",
    "loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def loss_sse(pred_resp, real_resp):\n",
    "    \"\"\" \n",
    "    Calculate loss based on sum of squared error.\n",
    "    If input is a matrix, assume [nTrials x nVoxels] and returns [nVoxels]\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(pred_resp, torch.Tensor):\n",
    "        pred_resp = torch.tensor(pred_resp)\n",
    "    if not isinstance(real_resp, torch.Tensor):\n",
    "        real_resp = torch.tensor(real_resp)\n",
    "\n",
    "    if len(torch.squeeze(pred_resp).shape)==1 & len(torch.squeeze(real_resp).shape)==1:\n",
    "        pred_resp = torch.squeeze(pred_resp)\n",
    "        real_resp = torch.squeeze(real_resp)       \n",
    "        error = torch.sum(torch.square(pred_resp - real_resp))\n",
    "    else:             \n",
    "        assert(np.all(pred_resp.shape==real_resp.shape))\n",
    "        error = torch.sum(torch.square(pred_resp - real_resp), axis=0)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9e1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of filter stack will be:\n",
      "(600, 600, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [05:29<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 200, 200, 12)\n",
      "torch.Size([750, 12, 324])\n"
     ]
    }
   ],
   "source": [
    "## Making the filters here:\n",
    "\n",
    "# First define the feature bank itself\n",
    "freqs_cpp = np.round(np.logspace(np.log10(0.02), np.log10(0.25), 3),2)\n",
    "orient_step = 45\n",
    "orients_deg = np.arange(0,181-orient_step, orient_step)\n",
    "spat_freq_bw = 1\n",
    "spat_aspect_ratio = 1\n",
    "n_sd_out = 7\n",
    "\n",
    "# Specify stuff about images\n",
    "process_at_size = [200,200]\n",
    "\n",
    "bank = g.filter_bank(orients_deg, freqs_cpp, spat_freq_bw, spat_aspect_ratio, n_sd_out, image_size = process_at_size)\n",
    "all_feat = g.get_nsd_gabor_feat(nsd_inds, bank)\n",
    "                            \n",
    "print(np.shape(all_feat))    \n",
    "\n",
    "# Create set of candidate RFs\n",
    "sizes = np.arange(5, 21, 5)\n",
    "x_centers = np.arange(20, 181, 20)\n",
    "y_centers = np.arange(20, 181, 20)\n",
    "\n",
    "rf_stack, x_list, y_list, size_list  = g.get_rf_stack(x_centers, y_centers, sizes, process_at_size)\n",
    "\n",
    "# Making a full matrix, [nIms x nFeatures x nRFs]\n",
    "# feats_by_rfs = g.get_feats_by_rfs(all_feat, rf_stack)\n",
    "\n",
    "# print(np.shape(feats_by_rfs))\n",
    "# nFeats = np.shape(feats_by_rfs)[1]\n",
    "# nRFs = np.shape(feats_by_rfs)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = 10\n",
    "nVox = 6\n",
    "nSteps=50\n",
    "lr = 0.000001\n",
    "\n",
    "model = m.encoding_model(nFeats).double()\n",
    "\n",
    "# for vv in range(nVox):\n",
    "for vv in range(1):\n",
    "    \n",
    "    print('fitting model for voxel %d of %d'%(vv, nVox))\n",
    "    \n",
    "    # gather the real data we would like to fit, for a single voxel over many images\n",
    "    real_resp = torch.tensor(dat2fit[:,vv])\n",
    "    \n",
    "    for rf in range(1):\n",
    "#     for rf in range(nRFs):\n",
    "        \n",
    "        print('fitting model for rf position %d of %d'%(rf, nRFs))\n",
    "        \n",
    "        # grabbing features for each image, within this candidate RF\n",
    "        x = feats_by_rfs[:,:,rf]\n",
    "\n",
    "        for ss in range(nSteps):\n",
    "            \n",
    "            # first get predictions and loss for the current weights.\n",
    "            pred_resp = model(x) \n",
    "            loss = m.loss_sse(pred_resp, real_resp)\n",
    "\n",
    "            print('step %d, loss is %.2f'%(ss, loss))\n",
    "        \n",
    "            # run the graph backward, to get gradient values. \n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # update weights based on this learning step\n",
    "                model.weights -= model.weights.grad * lr\n",
    "                model.bias -= model.bias.grad * lr\n",
    "                # zero the gradients out before next step\n",
    "                model.weights.grad.zero_()\n",
    "                model.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3db5ca47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(467.5542, dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some code to test ridge regression function w fake data\n",
    "\n",
    "vv=0\n",
    "rf=0\n",
    "model = ridge_regression_model(lamb=0.001)\n",
    "# make random trn data (these are features)\n",
    "x_trn = torch.tensor(np.random.normal(0,1,[15,4]))\n",
    "# random mapping from trn features to responses\n",
    "rand_wts = torch.tensor(np.random.normal(0,1,[4,6]))\n",
    "y_trn = x_trn @ rand_wts\n",
    "\n",
    "# tst data is just trn data plus some noise\n",
    "x_tst = x_trn + np.random.normal(0,0.5, np.shape(x_trn))\n",
    "y_tst = y_trn + np.random.normal(0,0.5, np.shape(y_trn))\n",
    "\n",
    "# fit and predict\n",
    "model.fit(x_trn, y_trn)\n",
    "y_hat = model.predict(x_tst)\n",
    "\n",
    "print(np.shape(y_hat))\n",
    "\n",
    "plt.figure();\n",
    "plt.subplot(2,2,1)\n",
    "plt.pcolormesh(y_tst)\n",
    "plt.subplot(2,2,2)\n",
    "plt.pcolormesh(y_hat) # plot predictions of voxel responses\n",
    "plt.subplot(2,2,3)\n",
    "plt.pcolormesh(rand_wts)\n",
    "plt.subplot(2,2,4)\n",
    "nFeats = np.shape(rand_wts)[0]\n",
    "plt.pcolormesh(model.w[0:nFeats,:]) # plot computed weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = 10\n",
    "batch_size = 200\n",
    "nVox = 6\n",
    "nEpochs = 20\n",
    "nSteps = 10\n",
    "# nSteps = int(np.ceil(nSamples / batch_size * nEpochs))\n",
    "lr = 1e-8\n",
    "\n",
    "model = encoding_model(nFeats).double()\n",
    "\n",
    "dat2fit = dat2use[0:nSamples,0:nVox]\n",
    "# dat2fit = np.random.normal(0,1,[nSamples, nVox])\n",
    "\n",
    "# first get features for all samples\n",
    "nsd_inds = np.arange(0,nSamples)\n",
    "\n",
    "# for vv in range(nVox):\n",
    "for vv in range(1):\n",
    "    \n",
    "    print('fitting model for voxel %d of %d'%(vv, nVox))\n",
    "    \n",
    "    # gather the real data we would like to fit, for a single voxel over many images\n",
    "    real_resp = torch.tensor(dat2fit[:,vv])\n",
    "    \n",
    "    for rf in range(1):\n",
    "#     for rf in range(nRFs):\n",
    "        \n",
    "        print('fitting model for rf position %d of %d'%(rf, nRFs))\n",
    "        \n",
    "        # grabbing features for each image, within this candidate RF\n",
    "        x = feats_by_rfs[:,:,rf]\n",
    "\n",
    "        for ss in range(nSteps):\n",
    "            \n",
    "            # first get predictions and loss for the current weights.\n",
    "            pred_resp = model(x) \n",
    "#             loss = torch.sqrt(loss_sse(pred_resp, real_resp))\n",
    "            loss = loss_sse(pred_resp, real_resp)\n",
    "    \n",
    "            print('step %d, loss is %.2f'%(ss, loss))\n",
    "            \n",
    "            \n",
    "            # run the graph backward, to get gradient values. \n",
    "            loss.backward()\n",
    "\n",
    "            print(model.weights.grad[0])\n",
    "            print(model.weights[0])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # update weights based on this learning step\n",
    "                model.weights -= model.weights.grad * lr\n",
    "                model.bias -= model.bias.grad * lr\n",
    "                # zero the gradients out before next step\n",
    "                model.weights.grad.zero_()\n",
    "                model.bias.grad.zero_()\n",
    "                \n",
    "            print(model.weights[0])\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
