{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27419c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "# import custom modules\n",
    "root_dir   = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.join(root_dir,'code'))\n",
    "from model_src import fwrf_fit as fwrf_fit\n",
    "from model_src import fwrf_predict as fwrf_predict\n",
    "from model_src import texture_statistics as texture_statistics\n",
    "\n",
    "from model_fitting import initialize_fitting\n",
    "\n",
    "fpX = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3abeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=1\n",
    "roi=None\n",
    "\n",
    "ridge=0\n",
    "\n",
    "shuffle_images=0\n",
    "random_images=0\n",
    "random_voxel_data=0\n",
    "\n",
    "sample_batch_size=100\n",
    "voxel_batch_size=100\n",
    "zscore_features=1\n",
    "nonlin_fn=0\n",
    "padding_mode='circular'\n",
    "\n",
    "n_ori=8\n",
    "n_sf=4\n",
    "up_to_sess=1\n",
    "debug=1\n",
    "shuff_rnd_seed=0\n",
    "# shuff_rnd_seed=251709\n",
    "\n",
    "fitting_type='texture'\n",
    "\n",
    "\n",
    "\n",
    "do_fitting=1\n",
    "do_val=1\n",
    "do_partial=1\n",
    "date_str=None\n",
    "# date_str='Jul-09-2021_1736'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf8acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = initialize_fitting.init_cuda()\n",
    "nsd_root, stim_root, beta_root, mask_root = initialize_fitting.get_paths()\n",
    "\n",
    "if do_fitting==False and date_str is None:\n",
    "    raise ValueError('if you want to start midway through the process (--do_fitting=False), then specify the date when training result was saved (--date_str).')\n",
    "\n",
    "if do_fitting==True and date_str is not None:\n",
    "    raise ValueError('if you want to do fitting from scratch (--do_fitting=True), specify --date_str=None (rather than entering a date)')\n",
    "\n",
    "# output_dir, fn2save = initialize_fitting.get_save_path(root_dir, subject, model_name, shuffle_images, random_images, random_voxel_data, debug, date_str)\n",
    "\n",
    "def save_all():\n",
    "    print('\\nSaving to %s\\n'%fn2save)\n",
    "    torch.save({\n",
    "    'feature_table_simple': _gaborizer_simple.feature_table,\n",
    "    'sf_tuning_masks_simple': _gaborizer_simple.sf_tuning_masks, \n",
    "    'ori_tuning_masks_simple': _gaborizer_simple.ori_tuning_masks,\n",
    "    'cyc_per_stim_simple': _gaborizer_simple.cyc_per_stim,\n",
    "    'orients_deg_simple': _gaborizer_simple.orients_deg,\n",
    "    'orient_filters_simple': _gaborizer_simple.orient_filters,  \n",
    "    'feature_table_complex': _gaborizer_complex.feature_table,\n",
    "    'sf_tuning_masks_complex': _gaborizer_complex.sf_tuning_masks, \n",
    "    'ori_tuning_masks_complex': _gaborizer_complex.ori_tuning_masks,\n",
    "    'cyc_per_stim_complex': _gaborizer_complex.cyc_per_stim,\n",
    "    'orients_deg_complex': _gaborizer_complex.orients_deg,\n",
    "    'orient_filters_complex': _gaborizer_complex.orient_filters,  \n",
    "    'aperture': aperture,\n",
    "    'aperture_rf_range': aperture_rf_range,\n",
    "    'models': models,\n",
    "    'include_autocorrs': include_autocorrs,\n",
    "    'feature_info':feature_info,\n",
    "    'voxel_mask': voxel_mask,\n",
    "    'brain_nii_shape': brain_nii_shape,\n",
    "    'image_order': image_order,\n",
    "    'voxel_index': voxel_index,\n",
    "    'voxel_roi': voxel_roi,\n",
    "    'voxel_ncsnr': voxel_ncsnr, \n",
    "    'best_params': best_params,\n",
    "    'lambdas': lambdas, \n",
    "    'best_lambdas': best_lambdas,\n",
    "    'best_losses': best_losses,\n",
    "    'val_cc': val_cc,\n",
    "    'val_r2': val_r2,   \n",
    "    'val_cc_partial': val_cc_partial,\n",
    "    'val_r2_partial': val_r2_partial,   \n",
    "    'features_each_model_val': features_each_model_val,\n",
    "    'voxel_feature_correlations_val': voxel_feature_correlations_val,\n",
    "    'zscore_features': zscore_features,\n",
    "    'nonlin_fn': nonlin_fn,\n",
    "    'padding_mode': padding_mode,\n",
    "    'n_prf_sd_out': n_prf_sd_out,\n",
    "    'autocorr_output_pix': autocorr_output_pix,\n",
    "    'debug': debug,\n",
    "    'up_to_sess': up_to_sess,\n",
    "    'shuff_rnd_seed': shuff_rnd_seed\n",
    "    }, fn2save, pickle_protocol=4)\n",
    "\n",
    "\n",
    "# decide what voxels to use  \n",
    "voxel_mask, voxel_index, voxel_roi, voxel_ncsnr, brain_nii_shape = initialize_fitting.get_voxel_info(mask_root, beta_root, subject, roi)\n",
    "\n",
    "# get all data and corresponding images, in two splits. always fixed set that gets left out\n",
    "trn_stim_data, trn_voxel_data, val_stim_single_trial_data, val_voxel_single_trial_data, \\\n",
    "    n_voxels, n_trials_val, image_order = initialize_fitting.get_data_splits(nsd_root, beta_root, stim_root, subject, voxel_mask, up_to_sess, \n",
    "                                                                             shuffle_images=shuffle_images, random_images=random_images, random_voxel_data=random_voxel_data)\n",
    "\n",
    "# Set up the filters\n",
    "_gaborizer_complex, _gaborizer_simple, _fmaps_fn_complex, _fmaps_fn_simple = initialize_fitting.get_feature_map_simple_complex_fn(n_ori, n_sf, padding_mode=padding_mode, device=device, nonlin_fn=nonlin_fn)\n",
    "\n",
    "# Params for the spatial aspect of the model (possible pRFs)\n",
    "#     aperture_rf_range=0.8 # using smaller range here because not sure what to do with RFs at edges...\n",
    "aperture_rf_range = 1.1\n",
    "aperture, models = initialize_fitting.get_prf_models(aperture_rf_range=aperture_rf_range)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1014c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize the \"texture\" model which builds on first level feature maps\n",
    "include_pixel=1\n",
    "include_simple=1\n",
    "include_complex=1\n",
    "include_autocorrs=1\n",
    "include_crosscorrs=1\n",
    "model_name, feature_types_exclude = initialize_fitting.get_model_name(ridge, n_ori, n_sf, include_pixel, include_simple, include_complex, include_autocorrs, include_crosscorrs)\n",
    "\n",
    "\n",
    "autocorr_output_pix=5\n",
    "n_prf_sd_out=2\n",
    "_texture_fn = texture_statistics.texture_feature_extractor(_fmaps_fn_complex, _fmaps_fn_simple, sample_batch_size=sample_batch_size, feature_types_exclude=feature_types_exclude, autocorr_output_pix=autocorr_output_pix, n_prf_sd_out=n_prf_sd_out, aperture=aperture, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8938192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "\n",
      "Possible lambda values are:\n",
      "[1.0000000e+00 4.2169652e+00 1.7782795e+01 7.4989418e+01 3.1622775e+02\n",
      " 1.3335215e+03 5.6234131e+03 2.3713736e+04 1.0000000e+05]\n",
      "trn_size = 619 (90.0%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "---------------------------------------\n",
      "Seeding random number generator: seed is 160115\n",
      "\n",
      "\n",
      "model 0\n",
      "\n",
      "Computing pixel-level statistics...\n",
      "time elapsed = 0.05533\n",
      "Computing complex cell features...\n",
      "time elapsed = 0.48893\n",
      "Computing simple cell features...\n",
      "time elapsed = 0.39703\n",
      "Computing higher order correlations...\n",
      "time elapsed = 4.67855\n",
      "Final size of features concatenated is [688 x 3412]\n",
      "Feature types included are:\n",
      "['wmean', 'wvar', 'wskew', 'wkurt', 'complex_feature_means', 'simple_feature_means', 'complex_feature_autocorrs', 'simple_feature_autocorrs', 'complex_within_scale_crosscorrs', 'simple_within_scale_crosscorrs', 'complex_across_scale_crosscorrs', 'simple_across_scale_crosscorrs']\n",
      "n zero columns: 1224\n",
      "   408 columns are complex_feature_autocorrs\n",
      "   816 columns are simple_feature_autocorrs\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "model 1\n",
      "\n",
      "Computing pixel-level statistics...\n",
      "time elapsed = 0.03814\n",
      "Computing complex cell features...\n",
      "time elapsed = 0.46908\n",
      "Computing simple cell features...\n",
      "time elapsed = 0.39398\n",
      "Computing higher order correlations...\n",
      "time elapsed = 4.68250\n",
      "Final size of features concatenated is [688 x 3412]\n",
      "Feature types included are:\n",
      "['wmean', 'wvar', 'wskew', 'wkurt', 'complex_feature_means', 'simple_feature_means', 'complex_feature_autocorrs', 'simple_feature_autocorrs', 'complex_within_scale_crosscorrs', 'simple_within_scale_crosscorrs', 'complex_across_scale_crosscorrs', 'simple_across_scale_crosscorrs']\n",
      "n zero columns: 1224\n",
      "   408 columns are complex_feature_autocorrs\n",
      "   816 columns are simple_feature_autocorrs\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "---------------------------------------\n",
      "total time = 46.018995s\n",
      "total throughput = 0.003086s/voxel\n",
      "voxel throughput = 0.000240s/voxel\n",
      "setup throughput = 0.048508s/model\n",
      "\n",
      "Done with training\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fn2save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e2907cb257eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mvoxel_feature_correlations_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msave_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-881c14e8c12c>\u001b[0m in \u001b[0;36msave_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nSaving to %s\\n'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mfn2save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     torch.save({\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m'feature_table_simple'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_gaborizer_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fn2save' is not defined"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print('\\nStarting training...\\n')\n",
    "\n",
    "zscore_features=True\n",
    "ridge=True\n",
    "# More params for fitting\n",
    "holdout_size, lambdas = initialize_fitting.get_fitting_pars(trn_voxel_data, zscore_features, ridge=ridge)\n",
    "\n",
    "\n",
    "\n",
    "if shuff_rnd_seed==0:\n",
    "    shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "best_losses, best_lambdas, best_params, feature_info = fit_texture_model_ridge(trn_stim_data, trn_voxel_data, _texture_fn, models, lambdas, \\\n",
    "    zscore=zscore_features, voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, shuffle=True, add_bias=True, debug=debug, shuff_rnd_seed=shuff_rnd_seed)\n",
    "# note there's also a shuffle param in the above fn call, that determines the nested heldout data for lambda and param selection. always using true.\n",
    "print('\\nDone with training\\n')\n",
    "\n",
    "val_cc=None\n",
    "val_r2=None\n",
    "val_cc_partial=None\n",
    "val_r2_partial=None\n",
    "features_each_model_val=None;\n",
    "voxel_feature_correlations_val=None;\n",
    "\n",
    "save_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e4dd894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "787dcf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_texture_model_ridge(images, voxel_data, _texture_fn, models, lambdas, zscore=False, voxel_batch_size=100, \n",
    "                            holdout_size=100, shuffle=True, add_bias=False, debug=False, shuff_rnd_seed=0):\n",
    "   \n",
    "    \"\"\"\n",
    "    Solve for encoding model weights using ridge regression.\n",
    "    Inputs:\n",
    "        images: the training images, [n_trials x 1 x height x width]\n",
    "        voxel_data: the training voxel data, [n_trials x n_voxels]\n",
    "        _texture_fn: module that maps from images to texture model features\n",
    "        models: the list of possible pRFs to test, columns are [x, y, sigma]\n",
    "        lambdas: ridge lambda parameters to test\n",
    "        zscore: want to zscore each column of feature matrix before fitting?\n",
    "        voxel_batch_size: how many voxels to use at a time for model fitting\n",
    "        holdout_size: how many training trials to hold out for computing loss/lambda selection?\n",
    "        shuffle: do we shuffle training data order before holding trials out?\n",
    "        add_bias: add a column of ones to feature matrix, for an additive bias?\n",
    "        debug: want to run a shortened version of this, to test it?\n",
    "        shuff_rnd_seed: if we do shuffle training data (shuffle=True), what random seed to use? if zero, choose a new random seed in this code.\n",
    "    Outputs:\n",
    "        best_losses: loss value for each voxel (with best pRF and best lambda), eval on held out set\n",
    "        best_lambdas: best lambda for each voxel (chosen based on loss w held out set)\n",
    "        best_params: \n",
    "            [0] best pRF for each voxel [x,y,sigma]\n",
    "            [1] best weights for each voxel/feature\n",
    "            [2] if add_bias=True, best bias value for each voxel\n",
    "            [3] if zscore=True, the mean of each feature before z-score\n",
    "            [4] if zscore=True, the std of each feature before z-score\n",
    "            [5] index of the best pRF for each voxel (i.e. index of row in \"models\")\n",
    "        feature_info: describes types of features in texture model, see texture_feature_extractor in texture_statistics.py\n",
    "        \n",
    "    \"\"\"\n",
    "   \n",
    "    dtype = images.dtype.type\n",
    "    device = next(_texture_fn.parameters()).device\n",
    "    trn_size = len(voxel_data) - holdout_size\n",
    "    assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "    \n",
    "    print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "    print ('dtype = %s' % dtype)\n",
    "    print ('device = %s' % device)\n",
    "    print ('---------------------------------------')\n",
    "    \n",
    "    # First do shuffling of data and define set to hold out\n",
    "    n_trials = len(images)\n",
    "    n_prfs = len(models)\n",
    "    n_voxels = voxel_data.shape[1]\n",
    "    order = np.arange(len(voxel_data), dtype=int)\n",
    "    if shuffle:\n",
    "        if shuff_rnd_seed==0:\n",
    "            print('Computing a new random seed')\n",
    "            shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "        print('Seeding random number generator: seed is %d'%shuff_rnd_seed)\n",
    "        np.random.seed(shuff_rnd_seed)\n",
    "        np.random.shuffle(order)\n",
    "    images = images[order]\n",
    "    voxel_data = voxel_data[order]  \n",
    "    trn_data = voxel_data[:trn_size]\n",
    "    out_data = voxel_data[trn_size:]\n",
    "\n",
    "    n_features_total = _texture_fn.n_features_total\n",
    "        \n",
    "    # Create full model value buffers    \n",
    "    best_models = np.full(shape=(n_voxels,), fill_value=-1, dtype=int)   \n",
    "    best_lambdas = np.full(shape=(n_voxels,), fill_value=-1, dtype=int)\n",
    "    best_losses = np.full(fill_value=np.inf, shape=(n_voxels), dtype=dtype)\n",
    "    best_w_params = np.zeros(shape=(n_voxels, n_features_total), dtype=dtype)\n",
    "\n",
    "    if add_bias:\n",
    "        best_w_params = np.concatenate([best_w_params, np.ones(shape=(len(best_w_params),1), dtype=dtype)], axis=1)\n",
    "    features_mean = None\n",
    "    features_std = None\n",
    "    if zscore:\n",
    "        features_mean = np.zeros(shape=(n_voxels, n_features_total), dtype=dtype)\n",
    "        features_std  = np.zeros(shape=(n_voxels, n_features_total), dtype=dtype)\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    vox_loop_time = 0\n",
    "    print ('')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Looping over models (here models are different spatial RF definitions)\n",
    "        for m,(x,y,sigma) in enumerate(models):\n",
    "            if debug and m>1:\n",
    "                break\n",
    "            print('\\nmodel %d\\n'%m)\n",
    "            t = time.time()   \n",
    "            \n",
    "            # Get features for the desired pRF, across all trn set image   \n",
    "        \n",
    "            all_feat_concat, feature_info = _texture_fn(images, [x,y,sigma])\n",
    "            \n",
    "            features = torch_utils.get_value(all_feat_concat)\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "        \n",
    "            if zscore:  \n",
    "                features_m = np.mean(features, axis=0, keepdims=True) #[:trn_size]\n",
    "                features_s = np.std(features, axis=0, keepdims=True) + 1e-6          \n",
    "                features -= features_m\n",
    "                features /= features_s    \n",
    "                \n",
    "            if add_bias:\n",
    "                features = np.concatenate([features, np.ones(shape=(len(features), 1), dtype=dtype)], axis=1)\n",
    "            \n",
    "            # separate design matrix into training/held out data (for lambda selection)\n",
    "            trn_features = features[:trn_size]\n",
    "            out_features = features[trn_size:]   \n",
    "\n",
    "            # Send matrices to gpu\n",
    "            _xtrn = torch_utils._to_torch(trn_features, device=device)\n",
    "            _xout = torch_utils._to_torch(out_features, device=device)   \n",
    "            \n",
    "            zero_columns = np.sum(torch_utils.get_value(_xtrn[:,0:-1]), axis=0)==0\n",
    "            if np.sum(zero_columns)>0:\n",
    "                print('n zero columns: %d'%np.sum(zero_columns))\n",
    "                for ff in range(len(feature_info[1])):\n",
    "                    if np.sum(zero_columns[feature_info[0]==ff])>0:\n",
    "                        print('   %d columns are %s'%(np.sum(zero_columns[feature_info[0]==ff]), feature_info[1][ff]))\n",
    "                        \n",
    "            # Do part of the matrix math involved in ridge regression optimization out of the loop, \n",
    "            # because this part will be same for all the voxels.\n",
    "            _cof = _cofactor_fn_cpu(_xtrn, lambdas)\n",
    "            \n",
    "            # Now looping over batches of voxels (only reason is because can't store all in memory at same time)\n",
    "            vox_start = time.time()\n",
    "            for rv,lv in numpy_utility.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "                sys.stdout.write('\\rfitting model %4d of %-4d, voxels [%6d:%-6d] of %d' % (m, n_prfs, rv[0], rv[-1], n_voxels))\n",
    "\n",
    "                # Send matrices to gpu\n",
    "                _vtrn = torch_utils._to_torch(trn_data[:,rv], device=device)\n",
    "                _vout = torch_utils._to_torch(out_data[:,rv], device=device)\n",
    "\n",
    "                # Here is where optimization happens - relatively simple matrix math inside loss fn.\n",
    "                _betas, _loss = _loss_fn(_cof, _vtrn, _xout, _vout) #   [#lambda, #feature, #voxel, ], [#lambda, #voxel]\n",
    "                # Now have a set of weights (in betas) and a loss value for every voxel and every lambda. \n",
    "                # goal is then to choose for each voxel, what is the best lambda and what weights went with that lambda.\n",
    "                \n",
    "                # first choose best lambda value and the loss that went with it.\n",
    "                _values, _select = torch.min(_loss, dim=0)\n",
    "                betas = torch_utils.get_value(_betas)\n",
    "                values, select = torch_utils.get_value(_values), torch_utils.get_value(_select)\n",
    "\n",
    "                # comparing this loss to the other models for each voxel (e.g. the other RF position/sizes)\n",
    "                imp = values<best_losses[rv]\n",
    "                \n",
    "                if np.sum(imp)>0:                    \n",
    "                    # for whichever voxels had improvement relative to previous models, save parameters now\n",
    "                    # this means we won't have to save all params for all models, just best.\n",
    "                    arv = np.array(rv)[imp]\n",
    "                    li = select[imp]\n",
    "                    best_lambdas[arv] = li\n",
    "                    best_losses[arv] = values[imp]\n",
    "                    best_models[arv] = m\n",
    "                    if zscore:\n",
    "                        features_mean[arv] = features_m # broadcast over updated voxels\n",
    "                        features_std[arv]  = features_s\n",
    "                    # taking the weights associated with the best lambda value\n",
    "                    best_w_params[arv,:] = numpy_utility.select_along_axis(betas[:,:,imp], li, run_axis=2, choice_axis=0).T\n",
    "              \n",
    "            vox_loop_time += (time.time() - vox_start)\n",
    "            elapsed = (time.time() - vox_start)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    # Print information about how fitting went...\n",
    "    total_time = time.time() - start_time\n",
    "    inv_time = total_time - vox_loop_time\n",
    "    return_params = [best_w_params[:,:n_features_total],]\n",
    "    if add_bias:\n",
    "        return_params += [best_w_params[:,-1],]\n",
    "    else: \n",
    "        return_params += [None,]\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('total throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    print ('voxel throughput = %fs/voxel' % (vox_loop_time / n_voxels))\n",
    "    print ('setup throughput = %fs/model' % (inv_time / n_prfs))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    best_params = [models[best_models],]+return_params+[features_mean, features_std]+[best_models]\n",
    "    \n",
    "    return best_losses, best_lambdas, best_params, feature_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "028647d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _cofactor_fn_cpu(_x, lambdas):\n",
    "    '''\n",
    "    Generating a matrix needed to solve ridge regression model for each lambda value.\n",
    "    Ridge regression (Tikhonov) solution is :\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    This func will return (X^T*X + I*lambda)^-1 * X^T. \n",
    "    So once we have that, can just multiply by training data (Y) to get weights.\n",
    "    returned size is [nLambdas x nFeatures x nTrials]\n",
    "    This version makes sure that the torch inverse operation is done on the cpu, and in floating point-64 precision.\n",
    "    Otherwise get bad results for small lambda values. This seems to be a torch-specific bug.\n",
    "    \n",
    "    '''\n",
    "    device_orig = _x.device\n",
    "    type_orig = _x.dtype\n",
    "    # switch to this specific format which works with inverse\n",
    "    _x = _x.to('cpu').to(torch.float64)\n",
    "    _f = torch.stack([(torch.mm(torch.t(_x), _x) + torch.eye(_x.size()[1], device='cpu', dtype=torch.float64) * l).inverse() for l in lambdas], axis=0) \n",
    "    \n",
    "    # [#lambdas, #feature, #feature] \n",
    "    cof = torch.tensordot(_f, _x, dims=[[2],[1]]) # [#lambdas, #feature, #sample]\n",
    "    \n",
    "    # put back to whatever way it was before, so that we can continue with other operations as usual\n",
    "    return cof.to(device_orig).to(type_orig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f43b07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as I\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import numpy_utility, torch_utils\n",
    "\n",
    "\n",
    "def _loss_fn(_cofactor, _vtrn, _xout, _vout):\n",
    "    '''\n",
    "    Calculate loss given \"cofactor\" from cofactor_fn, training data, held-out design matrix, held out data.\n",
    "    returns weights (betas) based on equation\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    also returns loss for these weights w the held out data. SSE is loss func here.\n",
    "    '''\n",
    "\n",
    "    _beta = torch.tensordot(_cofactor, _vtrn, dims=[[2], [0]]) # [#lambdas, #feature, #voxel]\n",
    "    _pred = torch.tensordot(_xout, _beta, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "    _loss = torch.sum(torch.pow(_vout[:,None,:] - _pred, 2), dim=0) # [#lambdas, #voxels]\n",
    "    return _beta, _loss\n",
    "\n",
    "\n",
    "def get_fmaps_sizes(_fmaps_fn, image_batch, device):\n",
    "    \"\"\" \n",
    "    Passing a batch of images through feature maps, in order to compute sizes.\n",
    "    Returns number of total features across all groups of maps, and the resolution of each map group.\n",
    "    \"\"\"\n",
    "    n_features = 0\n",
    "    _x = torch.tensor(image_batch).to(device) # the input variable.\n",
    "    _fmaps = _fmaps_fn(_x)\n",
    "    resolutions_each_sf = []\n",
    "    for k,_fm in enumerate(_fmaps):\n",
    "        n_features = n_features + _fm.size()[1]\n",
    "        resolutions_each_sf.append(_fm.size()[2])\n",
    "    \n",
    "    return n_features, resolutions_each_sf\n",
    "\n",
    "\n",
    "\n",
    "def get_features_in_prf(prf_params, _fmaps_fn, images, sample_batch_size, aperture, device, to_numpy=True):\n",
    "    \"\"\"\n",
    "    For a given set of images and a specified pRF position and size, compute the\n",
    "    activation in each feature map channel. Returns [nImages x nFeatures]\n",
    "    \"\"\"\n",
    "    \n",
    "    dtype = images.dtype.type\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        x,y,sigma = prf_params\n",
    "        n_trials = images.shape[0]\n",
    "\n",
    "        # pass first batch of images through feature map, just to get sizes.\n",
    "        n_features, fmaps_rez = get_fmaps_sizes(_fmaps_fn, images[0:sample_batch_size], device)\n",
    "\n",
    "        features = np.zeros(shape=(n_trials, n_features), dtype=dtype)\n",
    "        if to_numpy==False:\n",
    "             features = torch_utils._to_torch(features, device=device)\n",
    "                \n",
    "        # Define the RF for this \"model\" version - at several resolutions.\n",
    "        _prfs = [torch_utils._to_torch(numpy_utility.make_gaussian_mass(x, y, sigma, n_pix, size=aperture, \\\n",
    "                                  dtype=dtype)[2], device=device) for n_pix in fmaps_rez]\n",
    "\n",
    "        # To make full design matrix for all trials, first looping over trials in batches to get the features\n",
    "        # Only reason to loop is memory constraints, because all trials is big matrices.\n",
    "        t = time.time()\n",
    "        n_batches = np.ceil(n_trials/sample_batch_size)\n",
    "        bb=-1\n",
    "        for rt,rl in numpy_utility.iterate_range(0, n_trials, sample_batch_size):\n",
    "\n",
    "            bb=bb+1\n",
    "#             sys.stdout.write('\\rbatch %d of %d'%(bb,n_batches))\n",
    "            # multiplying feature maps by RFs here. \n",
    "            # we have one specified RF position for this version of the model. \n",
    "            # Feature maps in _fm go [nTrials x nFeatures(orientations) x nPixels x nPixels]\n",
    "            # spatial RFs in _prfs go [nPixels x nPixels]\n",
    "            # purpose of the for looping within this statement is to loop over map resolutions \n",
    "            # (e.g. spatial frequencies in model)\n",
    "            # output _features is [nTrials x nFeatures*nResolutions], so a 2D matrix. \n",
    "            # Combining features/resolutions here finally, so we can solve for weights \n",
    "            # in that full orient x SF feature space.\n",
    "\n",
    "            # then combine this with the other \"batches\" of trials to make a full \"model space tensor\"\n",
    "            # features is [nTrialsTotal x nFeatures*nResolutions]\n",
    "\n",
    "            # note this is concatenating SFs together from low to high - \n",
    "            # cycles through all orient channels in order for first SF, then again for next SF.\n",
    "            _features = torch.cat([torch.tensordot(_fm, _prf, dims=[[2,3], [0,1]]) \\\n",
    "                                   for _fm,_prf in zip(_fmaps_fn(torch_utils._to_torch(images[rt], \\\n",
    "                                           device=device)), _prfs)], dim=1) # [#samples, #features]\n",
    "\n",
    "            # Add features for this batch to full design matrix over all trials\n",
    "            if to_numpy:\n",
    "                features[rt] = torch_utils.get_value(_features)\n",
    "            else:\n",
    "                features[rt] = _features\n",
    "                \n",
    "        elapsed = time.time() - t\n",
    "#         print('\\nComputing features took %d sec'%elapsed)\n",
    "        \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26b4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
