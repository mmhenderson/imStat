{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "import skimage.io as skio\n",
    "from skimage.util.shape import view_as_windows\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  \n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurvRectValues:  \n",
    "    def __init__(self):\n",
    "        self.files           = []\n",
    "        self.image_size      = 128 \n",
    "        self.randstate       = 49\n",
    "        self.file_block_size = 20\n",
    "        self.images          = []\n",
    "        self.fft_images      = []\n",
    "        self.cg_parameters   = {'kA':0.3,'bend':0.01,'orientation':45*np.pi/180}\n",
    "        self.curv_values     = []\n",
    "        self.rect_values     = []\n",
    "        self.curv_max        = []\n",
    "        self.rect_max        = []\n",
    "        self.curv_unique     = []\n",
    "        self.rect_unique     = []\n",
    "        self.__generate_kernels__()\n",
    "        \n",
    "    \n",
    "    def __bananakernel__(self):\n",
    "        \"\"\"\n",
    "        input: cg_parameters is a dictionary, including kA, bA, alphaA, mA, sigmaXbend, sigmaYbend, \n",
    "                                               xA_half, yA_half, xA_shift, yA_shift\n",
    "                                               \n",
    "        the function is used to generate banana wavelet kernels.  The kernels\n",
    "        can be used to filter a image to quantify curvatures.\n",
    "\n",
    "        kA:          length of the wave vector K\n",
    "        bA:          bending value b\n",
    "        alphaA:      direction of the wave vector\n",
    "        mA:          magnitude value m\n",
    "        xA_half:     x-size\n",
    "        yA_half:     y-size\n",
    "        xA_shift:    center shift in x direction\n",
    "        yA_shift:    center shift in y direction\n",
    "\n",
    "        for references:\n",
    "        preFactorA:  pre-factor p\n",
    "        DCPartRealA: real dc-part\n",
    "        DCPartImagA: imaginary dc-part\n",
    "        gaussPartA:  Gaussian part    \n",
    "\n",
    "        filter requency: (cycle/object) = xA*kA/(2*pi*mA)\n",
    "        kernel size: 2*4*sigmaYbend*mA*(1/kA)\n",
    "\n",
    "        return SpaceKernel, FreKernel\n",
    "\n",
    "        last updated 5/23/2021\n",
    "        last updated 3/23/3021\n",
    "        \"\"\"\n",
    "        kA         = self.cg_parameters['kA']\n",
    "        bA         = self.cg_parameters['bend']    \n",
    "        alphaA     = self.cg_parameters.get('orientation',45*np.pi/180)\n",
    "        mA         = self.cg_parameters.get('mA',3)\n",
    "        sigmaXbend = self.cg_parameters.get('sigmaXbend',2)\n",
    "        sigmaYbend = self.cg_parameters.get('sigmaYbend',2)\n",
    "        xA_half    = self.cg_parameters.get('xA_half',self.image_size/2)\n",
    "        yA_half    = self.cg_parameters.get('yA_half',self.image_size/2)\n",
    "        xA_shift   = self.cg_parameters.get('x_shift',0)\n",
    "        yA_shift   = self.cg_parameters.get('y_shift',0)\n",
    "        \n",
    "        if isinstance(bA, complex):\n",
    "            print('bA has to be real number. However your input is a complex number')\n",
    "            bA = np.real(bA)\n",
    "\n",
    "        if any(x<=0 for x in np.array([kA, mA])) or any(np.isnan(np.array([kA, bA, alphaA, mA]))):     \n",
    "            out_ranage_value = 10**-20\n",
    "            SpaceKernel = np.ones((2*xA_half,2*yA_half))*out_ranage_value\n",
    "            FreKernel   = np.ones((2*xA_half,2*yA_half))*out_ranage_value\n",
    "            return SpaceKernel, FreKernel\n",
    "\n",
    "        kernel_size = 2*xA_half\n",
    "        if kernel_size%2 !=0:\n",
    "            kernel_size = kernel_size + 1\n",
    "        [xA, yA] = np.meshgrid(np.arange(-kernel_size/2, kernel_size/2,1),np.arange(-kernel_size/2, kernel_size/2,1)) \n",
    "        xA = xA - xA_shift\n",
    "        yA = yA - yA_shift\n",
    "\n",
    "        xRotL = np.cos(alphaA)*xA + np.sin(alphaA)*yA \n",
    "        yRotL = np.cos(alphaA)*yA - np.sin(alphaA)*xA\n",
    "\n",
    "        xRotBendL = xRotL + bA * (yRotL)**2\n",
    "        yRotBendL = yRotL\n",
    "\n",
    "        \"\"\"make the DC free\"\"\" \n",
    "        tmpgaussPartA = np.exp(-0.5*(kA)**2*((xRotBendL/sigmaXbend)**2 + (yRotBendL/(mA*sigmaYbend))**2))\n",
    "        tmprealteilL  = 1*tmpgaussPartA*(np.cos(kA*xRotBendL) - 0)\n",
    "        tmpimagteilL  = 1*tmpgaussPartA*(np.sin(kA*xRotBendL) - 0)\n",
    "\n",
    "        numeratorRealL = np.sum(tmprealteilL)\n",
    "        numeratorImagL = np.sum(tmpimagteilL)\n",
    "        denominatorL   = np.sum(tmpgaussPartA)\n",
    "\n",
    "        DCValueAnalysis = np.exp(-0.5 * sigmaXbend * sigmaXbend)\n",
    "        if denominatorL==0:\n",
    "            DCPartRealA = DCValueAnalysis\n",
    "            DCPartImagA = 0\n",
    "        else:    \n",
    "            DCPartRealA = numeratorRealL/denominatorL\n",
    "            DCPartImagA = numeratorImagL/denominatorL\n",
    "            if DCPartRealA < DCValueAnalysis:\n",
    "                DCPartRealA = DCValueAnalysis\n",
    "                DCPartImagA = 0\n",
    "\n",
    "        \"\"\"generate a space kernel\"\"\" \n",
    "        preFactorA = kA**2\n",
    "        gaussPartA = np.exp(-0.5*(kA)**2*((xRotBendL/sigmaXbend)**2 + (yRotBendL/(mA*sigmaYbend))**2))\n",
    "        realteilL  = preFactorA*gaussPartA*(np.cos(kA*xRotBendL) - DCPartRealA)\n",
    "        imagteilL  = preFactorA*gaussPartA*(np.sin(kA*xRotBendL) - DCPartImagA)\n",
    "\n",
    "        \"\"\"normalize the kernel\"\"\"  \n",
    "        normRealL   = np.sqrt(np.sum(realteilL**2))\n",
    "        normImagL   = np.sqrt(np.sum(imagteilL**2))\n",
    "        normFactorL = kA**2\n",
    "\n",
    "        total_std = normRealL + normImagL\n",
    "        if total_std == 0:\n",
    "            total_std = 10**20\n",
    "        norm_realteilL = realteilL*normFactorL/(0.5*total_std)\n",
    "        norm_imagteilL = imagteilL*normFactorL/(0.5*total_std)\n",
    "        \n",
    "        space_kernel = norm_realteilL + norm_imagteilL*1j\n",
    "        freq_kernel = np.fft.ifft2(space_kernel)\n",
    "        return space_kernel, freq_kernel\n",
    "                                  \n",
    "        \n",
    "    def __generate_kernels__(self, kA_scales=[1,5,8]):\n",
    "        all_kA = [2*np.pi/((np.sqrt(2))**x) for x in kA_scales]\n",
    "        bends = [0, 0.02,0.07,0.10,0.18,0.45]\n",
    "        alphaA = np.linspace(0,2*np.pi,8).tolist()\n",
    "        \n",
    "        curv_freq_kernels,rect_freq_kernels,curv_space,rect_space = [],[],[],[]\n",
    "        for kA, bA, orien in itertools.product(all_kA, bends, alphaA):\n",
    "            self.cg_parameters['kA']          = kA\n",
    "            self.cg_parameters['bend']        = bA/8\n",
    "            self.cg_parameters['orientation'] = orien\n",
    "            neuron, Freq_kernel = self.__bananakernel__()\n",
    "            if bA == 0:\n",
    "                rect_freq_kernels.append(Freq_kernel)\n",
    "                rect_space.append(neuron.real) \n",
    "            else:\n",
    "                curv_freq_kernels.append(Freq_kernel)\n",
    "                curv_space.append(neuron.real)\n",
    "\n",
    "        self.kernels = {'curv_freq':curv_freq_kernels, 'curv_space':curv_space,\n",
    "                        'rect_freq':rect_freq_kernels, 'rect_space':rect_space}\n",
    "\n",
    "        \n",
    "    \n",
    "    def __patchnorm__(self,image):\n",
    "        \"\"\" make sure it is gray scale image in range from 0 - 255 \"\"\" \n",
    "        if np.max(image) <=1:\n",
    "            image = 255*image/np.max(image)\n",
    "        orig_size = image.shape\n",
    "        \n",
    "        if image.shape[0]%3 == 0:\n",
    "            patch_size = 3\n",
    "        else:\n",
    "            patch_size = 4\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        \"\"\"create patches with the patch_size\"\"\"\n",
    "        patches = view_as_windows(image, (patch_size,patch_size), patch_size)\n",
    "\n",
    "        \"\"\" caculate norm of the local patches \"\"\" \n",
    "        local_norm = np.sqrt(np.einsum('ijkl->ij',patches**2))\n",
    "        local_norm[local_norm<1] = 1\n",
    "\n",
    "        \"\"\"normalize local patches \"\"\" \n",
    "        normed_patches = patches/local_norm[:,:,np.newaxis,np.newaxis]\n",
    "\n",
    "        \"\"\"reshape normalized local patch to original shape \"\"\" \n",
    "#         local_normed_image = normed_patches.transpose(0,2,1,3).reshape(-1,normed_patches.shape[1]*normed_patches.shape[3])\n",
    "        local_normed_image = rearrange(normed_patches,'h w c d -> (h c) (w d)')\n",
    "        \n",
    "        return {'local_norm':local_norm, 'local_normed_image':local_normed_image, \n",
    "                'total_local_norm':np.sqrt(local_norm.sum())}\n",
    "\n",
    "    \n",
    "    def processing_images(self, files):\n",
    "        images_list, fft_images_list = [],[]\n",
    "        self.files = files\n",
    "        self.curv_values     = []\n",
    "        self.rect_values     = []\n",
    "        self.curv_max        = []\n",
    "        self.rect_max        = []\n",
    "        self.curv_unique     = []\n",
    "        self.rect_unique     = []    \n",
    "        folder_name = os.path.dirname(files[0])\n",
    "        print(f'processing {len(files)} images...')\n",
    "        for i in tqdm.tqdm(range(0, len(files), self.file_block_size)):\n",
    "            block_files   = files[i:i + self.file_block_size]\n",
    "            _, fft_images = self.__read_images__(block_files)\n",
    "            self.__calcuate_curv_rect_values__(fft_images)\n",
    "            \n",
    "        self.curv_max    = np.dstack(self.curv_max)\n",
    "        self.curv_unique = np.dstack(self.curv_unique)\n",
    "        \n",
    "        self.rect_max    = np.dstack(self.rect_max)\n",
    "        self.rect_unique = np.dstack(self.rect_unique)\n",
    "        df = pd.DataFrame({'files':self.files, \n",
    "                           'curv_values':self.curv_values, \n",
    "                           'rect_values':self.rect_values})    \n",
    "        df.to_csv(f'{folder_name}_curv_rect_values.csv', index=False)\n",
    "        \n",
    "        \n",
    "    def __read_images__(self,file_block):  \n",
    "        images_list,fft_images_list = [],[]    \n",
    "        for image_name in file_block:\n",
    "            orig_image = skio.imread(image_name)\n",
    "#             if len(orig_image.shape)==3:\n",
    "#                 if orig_image.shape[2]>3:\n",
    "#                     orig_image = rgb2gray(rgba2rgb(orig_image))*255\n",
    "#                 else:    \n",
    "            orig_image = rgb2gray(orig_image)*255\n",
    "\n",
    "            image = resize(orig_image, (self.image_size,self.image_size))\n",
    "\n",
    "            patch_processed_image = self.__patchnorm__(image)\n",
    "            output_image          = patch_processed_image['local_normed_image']\n",
    "    \n",
    "            fft_image = np.fft.fft2(output_image)\n",
    "\n",
    "            images_list.append(output_image)\n",
    "            fft_images_list.append(fft_image)  \n",
    "            \n",
    "        self.images.append(images_list) \n",
    "        self.fft_images.append(fft_images_list) \n",
    "        return images_list, fft_images_list\n",
    "\n",
    "    def __get_max_image__(self,fft_image_list,kernel_list):\n",
    "        \"\"\"image x, image y, kernel dimension, all images (4D array)\"\"\"\n",
    "        all_kernels = np.dstack(kernel_list)\n",
    "        \n",
    "        \"\"\"calcuate kernel norm for normalization\"\"\"\n",
    "        all_kernels_power =  np.einsum('ijk,ijk->k',np.abs(all_kernels),np.abs(all_kernels))\n",
    "        all_kernels_power =  np.sqrt(all_kernels_power)\n",
    "\n",
    "        \"\"\"stack fft image list to a 3d array\"\"\"\n",
    "        fft_images        = np.dstack(fft_image_list)\n",
    "        all_conved_images = np.abs(np.fft.ifft2(fft_images[:,:,np.newaxis,:]*all_kernels[:,:,:,np.newaxis],axes=(0,1)))\n",
    "        all_conved_images = np.power(all_conved_images,1/2) ## power correction\n",
    "        all_conved_images = all_conved_images/all_kernels_power[np.newaxis, np.newaxis,:,np.newaxis]\n",
    "    \n",
    "        max_images = np.max(all_conved_images,axis=2)\n",
    "        return max_images  \n",
    " \n",
    "    \n",
    "    def __calcuate_curv_rect_values__(self, fft_image_list):\n",
    "        curv_max_response = self.__get_max_image__(fft_image_list, self.kernels['curv_freq'])\n",
    "        rect_max_response = self.__get_max_image__(fft_image_list, self.kernels['rect_freq'])\n",
    "        \n",
    "        x, y,_ = curv_max_response.shape        \n",
    "        self.curv_max.append(curv_max_response) \n",
    "        self.rect_max.append(rect_max_response) \n",
    "        \n",
    "        curv_unique = np.where(curv_max_response>rect_max_response, curv_max_response, 0)\n",
    "        curv_values = np.einsum('ijk->k',curv_unique)\n",
    "        self.curv_unique.append(curv_unique)\n",
    "        \n",
    "        rect_unique = np.where(rect_max_response>curv_max_response, rect_max_response, 0)\n",
    "        rect_values = np.einsum('ijk->k',rect_unique)\n",
    "        self.rect_unique.append(rect_unique)\n",
    "        \n",
    "        self.curv_values.extend(curv_values/(2*(x/2)**2))\n",
    "        self.rect_values.extend(rect_values/(2*(x/2)**2))\n",
    "\n",
    "    def show_kernel_example(self):\n",
    "        fig,ax = plt.subplots(2,2,figsize=(8,6))\n",
    "        ax = ax.flat\n",
    "        ax[0].imshow(self.kernels['curv_space'][100])\n",
    "        ax[0].set(title='curvilinear kernel')\n",
    "        ax[1].imshow((np.log(np.abs(self.kernels['curv_freq'][100]))))\n",
    "        ax[1].set(title='power of the curvilinear kernel')\n",
    "                                \n",
    "        ax[2].imshow(self.kernels['rect_space'][15])\n",
    "        ax[2].set(title='rectilinear kernel')\n",
    "        ax[3].imshow((np.log(np.abs(self.kernels['rect_freq'][15]))))\n",
    "        ax[3].set(title='power of the curvilinear kernel')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def show_curv_rect_example(self):\n",
    "        fig, ax = plt.subplots(2,2,figsize=(8,6))\n",
    "        ax = ax.flat\n",
    "        ax[0].imshow(np.fft.fftshift(self.curv_max[:,:,0]))\n",
    "        ax[0].set(title='a max curvilinear image')\n",
    "        \n",
    "        ax[1].imshow(np.fft.fftshift(self.rect_max[:,:,0]))\n",
    "        ax[1].set(title='a max rectilinear image')\n",
    "        \n",
    "        ax[2].imshow(np.fft.fftshift(self.curv_unique[:,:,0]))\n",
    "        ax[2].set(title='a unique curvilinear image')\n",
    "        \n",
    "        ax[3].imshow(np.fft.fftshift(self.rect_unique[:,:,0]))\n",
    "        ax[3].set(title='a unique rectilinear image')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "                               \n",
    "            \n",
    "    def show_correlation(self):\n",
    "        tmp_corr = stats.pearsonr(self.curv_values, self.rect_values)\n",
    "        fig,ax = plt.subplots(1,1)\n",
    "        ax.scatter(self.curv_values,self.rect_values)\n",
    "        ax.set(xlabel='curvilinear values',\n",
    "               ylabel='rectilinear values',\n",
    "               title=f'correlation:{tmp_corr[0]:.3f}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84087caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    file_list = glob.glob('examples/*.png')\n",
    "    curvrect_score= CurvRectValues()\n",
    "    curvrect_score.processing_images(file_list)\n",
    "    curvrect_score.show_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302379cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
