{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433f976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "import skimage.transform\n",
    "\n",
    "# import custom modules\n",
    "root_dir   = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.join(root_dir,'code'))\n",
    "from model_src import fwrf_fit as fwrf_fit\n",
    "from model_src import fwrf_predict as fwrf_predict\n",
    "from model_src import texture_statistics_gabor, texture_statistics_pyramid\n",
    "\n",
    "from model_fitting import initialize_fitting\n",
    "\n",
    "fpX = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8868e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as I\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import numpy_utility, torch_utils\n",
    "from model_src import fwrf_fit as fwrf_fit\n",
    "from model_src import texture_statistics_gabor as texture_statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dd19ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as I\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import numpy_utility, torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7c33b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user_data/mmhender/imStat'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52a8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=1\n",
    "roi=None\n",
    "\n",
    "ridge=0\n",
    "\n",
    "shuffle_images=0\n",
    "random_images=0\n",
    "random_voxel_data=0\n",
    "\n",
    "sample_batch_size=100\n",
    "voxel_batch_size=100\n",
    "zscore_features=1\n",
    "nonlin_fn=0\n",
    "padding_mode='circular'\n",
    "\n",
    "n_ori=4\n",
    "n_sf=4\n",
    "up_to_sess=1\n",
    "debug=1\n",
    "shuff_rnd_seed=0\n",
    "# shuff_rnd_seed=251709\n",
    "\n",
    "fitting_type='texture'\n",
    "\n",
    "do_fitting=1\n",
    "do_val=1\n",
    "do_partial=1\n",
    "date_str=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f141f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e0a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stamp: Aug-14-2021_1231\n",
      "\n",
      "Will save final output file to /user_data/mmhender/model_fits/S01/texture_pyramid_OLS_4ori_4sf/Aug-14-2021_1231_DEBUG/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# device = initialize_fitting.init_cuda()\n",
    "device = torch.device('cpu:0')\n",
    "nsd_root, stim_root, beta_root, mask_root = initialize_fitting.get_paths()\n",
    "model_name, feature_types_exclude = initialize_fitting.get_pyramid_model_name(ridge, n_ori, n_sf)\n",
    "\n",
    "if do_fitting==False and date_str is None:\n",
    "    raise ValueError('if you want to start midway through the process (--do_fitting=False), then specify the date when training result was saved (--date_str).')\n",
    "\n",
    "if do_fitting==True and date_str is not None:\n",
    "    raise ValueError('if you want to do fitting from scratch (--do_fitting=True), specify --date_str=None (rather than entering a date)')\n",
    "\n",
    "output_dir, fn2save = initialize_fitting.get_save_path(root_dir, subject, model_name, shuffle_images, random_images, random_voxel_data, debug, date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a03346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3794 voxels of overlap between kastner and prf definitions, using prf defs\n",
      "unique values in retino labels:\n",
      "[-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18. 19. 20. 21. 22. 23. 24. 25.]\n",
      "0 voxels of overlap between face and place definitions, using place defs\n",
      "unique values in categ labels:\n",
      "[-1.  0. 26. 27. 28. 30. 31. 32. 33.]\n",
      "1535 voxels are defined (differently) in both retinotopic areas and category areas\n",
      "\n",
      "14913 voxels are defined across all areas, and will be used for analysis\n",
      "\n",
      "Loading numerical label/name mappings for all ROIs:\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'VO1', 'VO2', 'PHC1', 'PHC2', 'TO2', 'TO1', 'LO2', 'LO1', 'V3B', 'V3A', 'IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'SPL1', 'FEF']\n",
      "[1, 2, 3, 4, 5]\n",
      "['OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces']\n",
      "[1, 2, 3]\n",
      "['OPA', 'PPA', 'RSC']\n",
      "\n",
      "Sizes of all defined ROIs in this subject:\n",
      "Region V1 has 2392 voxels. Includes subregions:\n",
      "['V1v', 'V1d']\n",
      "Region V2 has 2096 voxels. Includes subregions:\n",
      "['V2v', 'V2d']\n",
      "Region V3 has 1674 voxels. Includes subregions:\n",
      "['V3v', 'V3d']\n",
      "Region hV4 has 721 voxels. Includes subregions:\n",
      "['hV4']\n",
      "Region VO1-2 has 482 voxels. Includes subregions:\n",
      "['VO1', 'VO2']\n",
      "Region PHC1-2 has 382 voxels. Includes subregions:\n",
      "['PHC1', 'PHC2']\n",
      "Region LO1-2 has 488 voxels. Includes subregions:\n",
      "['LO2', 'LO1']\n",
      "Region TO1-2 has 339 voxels. Includes subregions:\n",
      "['TO2', 'TO1']\n",
      "Region V3ab has 965 voxels. Includes subregions:\n",
      "['V3B', 'V3A']\n",
      "Region IPS0-5 has 2155 voxels. Includes subregions:\n",
      "['IPS0', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5']\n",
      "Region SPL1 has 164 voxels. Includes subregions:\n",
      "['SPL1']\n",
      "Region FEF has 72 voxels. Includes subregions:\n",
      "['FEF']\n",
      "\n",
      "\n",
      "Region OFA has 355 voxels.\n",
      "Region FFA-1 has 484 voxels.\n",
      "Region FFA-2 has 310 voxels.\n",
      "Region mTL-faces has 0 voxels.\n",
      "Region aTL-faces has 159 voxels.\n",
      "Region OPA has 1611 voxels.\n",
      "Region PPA has 1033 voxels.\n",
      "Region RSC has 566 voxels.\n",
      "\n",
      "Loading images for subject 1\n",
      "\n",
      "image data size: (10000, 3, 227, 227) , dtype: uint8 , value range: 0 255\n",
      "Loading data for sessions 1:1...\n",
      "/lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR\n",
      "/lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR\n",
      "324\n",
      "/lab_data/tarrlab/common/datasets/NSD/nsddata_betas/ppdata/subj01/func1pt8mm/betas_fithrf_GLMdenoise_RR/betas_session01.nii.gz\n",
      "int16 -32768 32767 (750, 81, 104, 83)\n",
      "<beta> = 1.237, <sigma> = 1.391\n",
      "\n",
      "Size of full data set [nTrials x nVoxels] is:\n",
      "(750, 14913)\n",
      "Total number of voxels = 14913\n",
      "most extreme RF positions:\n",
      "[-0.55 -0.55  0.04]\n",
      "[0.55       0.55       0.40000001]\n",
      "[]\n",
      "\n",
      "Possible lambda values are:\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# decide what voxels to use  \n",
    "voxel_mask, voxel_index, voxel_roi, voxel_ncsnr, brain_nii_shape = initialize_fitting.get_voxel_info(mask_root, beta_root, subject, roi)\n",
    "\n",
    "# get all data and corresponding images, in two splits. always fixed set that gets left out\n",
    "trn_stim_data, trn_voxel_data, val_stim_single_trial_data, val_voxel_single_trial_data, \\\n",
    "    n_voxels, n_trials_val, image_order = initialize_fitting.get_data_splits(nsd_root, beta_root, stim_root, subject, voxel_mask, up_to_sess, \n",
    "                                                                             shuffle_images=shuffle_images, random_images=random_images, random_voxel_data=random_voxel_data)\n",
    "\n",
    "# Need a multiple of 8\n",
    "process_at_size=240\n",
    "trn_stim_data = skimage.transform.resize(trn_stim_data, output_shape=(trn_stim_data.shape[0],1,process_at_size, process_at_size))\n",
    "val_stim_single_trial_data = skimage.transform.resize(val_stim_single_trial_data, output_shape=(val_stim_single_trial_data.shape[0],1,process_at_size, process_at_size))\n",
    "\n",
    "# Set up the pyramid\n",
    "_fmaps_fn = texture_statistics_pyramid.steerable_pyramid_extractor(pyr_height=n_sf, n_ori = n_ori)\n",
    "# Params for the spatial aspect of the model (possible pRFs)\n",
    "#     aperture_rf_range=0.8 # using smaller range here because not sure what to do with RFs at edges...\n",
    "aperture_rf_range = 1.1\n",
    "aperture, models = initialize_fitting.get_prf_models(aperture_rf_range=aperture_rf_range)    \n",
    "\n",
    "# Initialize the \"texture\" model which builds on first level feature maps\n",
    "n_prf_sd_out=2\n",
    "_texture_fn = texture_statistics_pyramid.texture_feature_extractor(_fmaps_fn,sample_batch_size=sample_batch_size, feature_types_exclude=feature_types_exclude, n_prf_sd_out=n_prf_sd_out, aperture=aperture, device=device)\n",
    "\n",
    "# More params for fitting\n",
    "holdout_size, lambdas = initialize_fitting.get_fitting_pars(trn_voxel_data, zscore_features, ridge=ridge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87aa3f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "trn_size = 619 (90.0%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cpu:0\n",
      "---------------------------------------\n",
      "Seeding random number generator: seed is 321214\n",
      "\n",
      "\n",
      "model 0\n",
      "\n",
      "Computing higher order correlations...\n",
      "time elapsed: 39.44852 s\n",
      "time elapsed: 39.19156 s\n",
      "time elapsed: 37.57936 s\n",
      "time elapsed: 37.40673 s\n",
      "time elapsed: 38.01229 s\n",
      "time elapsed: 37.34752 s\n",
      "time elapsed: 33.22914 s\n",
      "time elapsed = 646.16804\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "\n",
      "Partial version 0 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 1 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 2 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 3 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 4 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 5 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 6 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 7 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 8 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 9 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 10 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 11 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 12 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 13 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 14 of 15\n",
      "fitting model    0 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "model 1\n",
      "\n",
      "Computing higher order correlations...\n",
      "time elapsed: 33.36803 s\n",
      "time elapsed: 33.18342 s\n",
      "time elapsed: 33.88859 s\n",
      "time elapsed: 36.08079 s\n",
      "time elapsed: 38.05827 s\n",
      "time elapsed: 39.85524 s\n",
      "time elapsed: 35.77892 s\n",
      "time elapsed = 637.66824\n",
      "Final size of features concatenated is [688 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "\n",
      "Partial version 0 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 1 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 2 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 3 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 4 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 5 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 6 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 7 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 8 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 9 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 10 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 11 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 12 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 13 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "Partial version 14 of 15\n",
      "fitting model    1 of 875 , voxels [ 14900:14912 ] of 14913\n",
      "---------------------------------------\n",
      "total time = 1359.040921s\n",
      "total throughput = 0.091131s/voxel\n",
      "voxel throughput = 0.004083s/voxel\n",
      "setup throughput = 1.483606s/model\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print('\\nStarting training...\\n')\n",
    "if shuff_rnd_seed==0:\n",
    "    shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "best_losses, best_lambdas, best_params, feature_info = fit_texture_model_ridge_varpart(trn_stim_data, trn_voxel_data, _texture_fn, models, lambdas, \\\n",
    "    zscore=zscore_features, voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, shuffle=True, add_bias=True, debug=debug, shuff_rnd_seed=shuff_rnd_seed,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbbe5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_texture_model_ridge_varpart(images, voxel_data, _texture_fn, models, lambdas, zscore=False, voxel_batch_size=100, \n",
    "                            holdout_size=100, shuffle=True, add_bias=False, debug=False, shuff_rnd_seed=0, device=None):\n",
    "   \n",
    "    \"\"\"\n",
    "    Solve for encoding model weights using ridge regression.\n",
    "    Inputs:\n",
    "        images: the training images, [n_trials x 1 x height x width]\n",
    "        voxel_data: the training voxel data, [n_trials x n_voxels]\n",
    "        _texture_fn: module that maps from images to texture model features\n",
    "        models: the list of possible pRFs to test, columns are [x, y, sigma]\n",
    "        lambdas: ridge lambda parameters to test\n",
    "        zscore: want to zscore each column of feature matrix before fitting?\n",
    "        voxel_batch_size: how many voxels to use at a time for model fitting\n",
    "        holdout_size: how many training trials to hold out for computing loss/lambda selection?\n",
    "        shuffle: do we shuffle training data order before holding trials out?\n",
    "        add_bias: add a column of ones to feature matrix, for an additive bias?\n",
    "        debug: want to run a shortened version of this, to test it?\n",
    "        shuff_rnd_seed: if we do shuffle training data (shuffle=True), what random seed to use? if zero, choose a new random seed in this code.\n",
    "    Outputs:\n",
    "        best_losses: loss value for each voxel (with best pRF and best lambda), eval on held out set\n",
    "        best_lambdas: best lambda for each voxel (chosen based on loss w held out set)\n",
    "        best_params: \n",
    "            [0] best pRF for each voxel [x,y,sigma]\n",
    "            [1] best weights for each voxel/feature\n",
    "            [2] if add_bias=True, best bias value for each voxel\n",
    "            [3] if zscore=True, the mean of each feature before z-score\n",
    "            [4] if zscore=True, the std of each feature before z-score\n",
    "            [5] index of the best pRF for each voxel (i.e. index of row in \"models\")\n",
    "        feature_info: describes types of features in texture model, see texture_feature_extractor in texture_statistics.py\n",
    "        \n",
    "    \"\"\"\n",
    "   \n",
    "    dtype = images.dtype.type\n",
    "    if device is None:\n",
    "        device=torch.device('cpu:0')\n",
    "#     device = next(_texture_fn.parameters()).device\n",
    "    trn_size = len(voxel_data) - holdout_size\n",
    "    assert trn_size>0, 'Training size needs to be greater than zero'\n",
    "    \n",
    "    print ('trn_size = %d (%.1f%%)' % (trn_size, float(trn_size)*100/len(voxel_data)))\n",
    "    print ('dtype = %s' % dtype)\n",
    "    print ('device = %s' % device)\n",
    "    print ('---------------------------------------')\n",
    "    \n",
    "    # First do shuffling of data and define set to hold out\n",
    "    n_trials = len(images)\n",
    "    n_prfs = len(models)\n",
    "    n_voxels = voxel_data.shape[1]\n",
    "    order = np.arange(len(voxel_data), dtype=int)\n",
    "    if shuffle:\n",
    "        if shuff_rnd_seed==0:\n",
    "            print('Computing a new random seed')\n",
    "            shuff_rnd_seed = int(time.strftime('%M%H%d', time.localtime()))\n",
    "        print('Seeding random number generator: seed is %d'%shuff_rnd_seed)\n",
    "        np.random.seed(shuff_rnd_seed)\n",
    "        np.random.shuffle(order)\n",
    "    images = images[order]\n",
    "    voxel_data = voxel_data[order]  \n",
    "    trn_data = voxel_data[:trn_size]\n",
    "    out_data = voxel_data[trn_size:]\n",
    "\n",
    "    n_features_total = _texture_fn.n_features_total\n",
    "    n_feature_types = len(_texture_fn.feature_types_include)\n",
    "    n_partial_versions = n_feature_types+1\n",
    "    partial_version_names = ['full'] + _texture_fn.feature_types_include\n",
    "    # \"partial versions\" will be listed as: [full model, leave out first set of features, leave out second set of features...]\n",
    "\n",
    "    # Create full model value buffers    \n",
    "    best_models = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)   \n",
    "    best_lambdas = np.full(shape=(n_voxels,n_partial_versions), fill_value=-1, dtype=int)\n",
    "    best_losses = np.full(fill_value=np.inf, shape=(n_voxels,n_partial_versions), dtype=dtype)\n",
    "    # creating a third dim here, listing the \"partial\" versions of the model (setting to zero a subset of features at a time)\n",
    "    best_w_params = np.zeros(shape=(n_voxels, n_features_total,n_partial_versions), dtype=dtype)\n",
    "\n",
    "    if add_bias:\n",
    "        best_w_params = np.concatenate([best_w_params, np.ones(shape=(n_voxels,1,n_partial_versions), dtype=dtype)], axis=1)\n",
    "\n",
    "    features_mean = None\n",
    "    features_std = None\n",
    "    if zscore:\n",
    "        features_mean = np.zeros(shape=(n_voxels, n_features_total), dtype=dtype)\n",
    "        features_std  = np.zeros(shape=(n_voxels, n_features_total), dtype=dtype)\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    vox_loop_time = 0\n",
    "    print ('')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Looping over models (here models are different spatial RF definitions)\n",
    "        for m,(x,y,sigma) in enumerate(models):\n",
    "            if debug and m>1:\n",
    "                break\n",
    "            print('\\nmodel %d\\n'%m)\n",
    "            t = time.time()   \n",
    "            \n",
    "            # Get features for the desired pRF, across all trn set image   \n",
    "        \n",
    "            all_feat_concat, feature_info = _texture_fn(images, [x,y,sigma])\n",
    "            \n",
    "            features = torch_utils.get_value(all_feat_concat)\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "        \n",
    "            if zscore:  \n",
    "                features_m = np.mean(features, axis=0, keepdims=True) #[:trn_size]\n",
    "                features_s = np.std(features, axis=0, keepdims=True) + 1e-6          \n",
    "                features -= features_m\n",
    "                features /= features_s    \n",
    "                \n",
    "            if add_bias:\n",
    "                features = np.concatenate([features, np.ones(shape=(len(features), 1), dtype=dtype)], axis=1)\n",
    "            \n",
    "            # separate design matrix into training/held out data (for lambda selection)\n",
    "            trn_features = features[:trn_size]\n",
    "            out_features = features[trn_size:]   \n",
    "\n",
    "            zero_columns = np.sum(trn_features[:,0:-1], axis=0)==0\n",
    "            if np.sum(zero_columns)>0:\n",
    "                print('n zero columns: %d'%np.sum(zero_columns))\n",
    "                for ff in range(len(feature_info[1])):\n",
    "                    if np.sum(zero_columns[feature_info[0]==ff])>0:\n",
    "                        print('   %d columns are %s'%(np.sum(zero_columns[feature_info[0]==ff]), feature_info[1][ff]))\n",
    "                      \n",
    "            masks = np.concatenate([np.expand_dims(np.array(_texture_fn.feature_column_labels!=ff).astype('int'), axis=0) for ff in np.arange(-1,n_feature_types)], axis=0)\n",
    "            masks = np.concatenate([masks, np.ones([masks.shape[0],1])], axis=1) # always include intercept \n",
    "            masks = np.transpose(masks)\n",
    "            # masks is [n_features_total (including intercept) x n_partial_versions]\n",
    "\n",
    "#            \n",
    "#             # goes [full model, leave out first set of features, leave out second set of features...]\n",
    "#             trn_features_partial = np.tile(np.expand_dims(trn_features, axis=2), [1,1,n_partial_versions])\n",
    "#             trn_features_partial = trn_features_partial * np.tile(np.expand_dims(masks, axis=0), [trn_features_partial.shape[0],1,1])\n",
    "            \n",
    "#             out_features_partial = np.tile(np.expand_dims(out_features, axis=2), [1,1,n_partial_versions])\n",
    "#             out_features_partial = out_features_partial * np.tile(np.expand_dims(masks, axis=0), [out_features_partial.shape[0],1,1])\n",
    "\n",
    "            # Looping over versions of model w different features set to zero (variance partition)\n",
    "            for pp in range(n_partial_versions):\n",
    "                \n",
    "                print('\\nPartial version %d of %d, '%(pp, n_partial_versions))\n",
    "\n",
    "                nonzero_inds = masks[:,pp]==1\n",
    "                best_w_tmp = best_w_params[:,nonzero_inds,pp] # chunk of the full weights matrix to work with for this partial model\n",
    "\n",
    "                # Send matrices to gpu\n",
    "                _xtrn = torch_utils._to_torch(trn_features[:,nonzero_inds], device=device)\n",
    "                _xout = torch_utils._to_torch(out_features[:,nonzero_inds], device=device)   \n",
    "\n",
    "                # Do part of the matrix math involved in ridge regression optimization out of the loop, \n",
    "                # because this part will be same for all the voxels.\n",
    "                _cof = _cofactor_fn_cpu(_xtrn, lambdas)\n",
    "\n",
    "                # Now looping over batches of voxels (only reason is because can't store all in memory at same time)\n",
    "                vox_start = time.time()\n",
    "                for rv,lv in numpy_utility.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "                    sys.stdout.write('\\rfitting model %4d of %-4d, voxels [%6d:%-6d] of %d' % (m, n_prfs, rv[0], rv[-1], n_voxels))\n",
    "\n",
    "                    # Send matrices to gpu\n",
    "                    _vtrn = torch_utils._to_torch(trn_data[:,rv], device=device)\n",
    "                    _vout = torch_utils._to_torch(out_data[:,rv], device=device)\n",
    "\n",
    "                    # Here is where optimization happens - relatively simple matrix math inside loss fn.\n",
    "                    _betas, _loss = _loss_fn(_cof, _vtrn, _xout, _vout) #   [#lambda, #feature, #voxel, ], [#lambda, #voxel]\n",
    "                    # Now have a set of weights (in betas) and a loss value for every voxel and every lambda. \n",
    "                    # goal is then to choose for each voxel, what is the best lambda and what weights went with that lambda.\n",
    "\n",
    "                    # first choose best lambda value and the loss that went with it.\n",
    "                    _values, _select = torch.min(_loss, dim=0)\n",
    "                    betas = torch_utils.get_value(_betas)\n",
    "                    values, select = torch_utils.get_value(_values), torch_utils.get_value(_select)\n",
    "\n",
    "                    # comparing this loss to the other models for each voxel (e.g. the other RF position/sizes)\n",
    "                    imp = values<best_losses[rv,pp]\n",
    "\n",
    "                    if np.sum(imp)>0:                    \n",
    "                        # for whichever voxels had improvement relative to previous models, save parameters now\n",
    "                        # this means we won't have to save all params for all models, just best.\n",
    "                        arv = np.array(rv)[imp]\n",
    "                        li = select[imp]\n",
    "                        best_lambdas[arv,pp] = li\n",
    "                        best_losses[arv,pp] = values[imp]\n",
    "                        best_models[arv,pp] = m\n",
    "                        if zscore:\n",
    "                            features_mean[arv] = features_m # broadcast over updated voxels\n",
    "                            features_std[arv]  = features_s\n",
    "                        # taking the weights associated with the best lambda value\n",
    "                        best_w_tmp[arv,:] = numpy_utility.select_along_axis(betas[:,:,imp], li, run_axis=2, choice_axis=0).T\n",
    "\n",
    "                best_w_params[:,nonzero_inds,pp] = best_w_tmp\n",
    "\n",
    "                vox_loop_time += (time.time() - vox_start)\n",
    "                elapsed = (time.time() - vox_start)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    # Print information about how fitting went...\n",
    "    total_time = time.time() - start_time\n",
    "    inv_time = total_time - vox_loop_time\n",
    "    return_params = [best_w_params[:,:n_features_total,:]]\n",
    "    if add_bias:\n",
    "        return_params += [best_w_params[:,-1,:]]\n",
    "    else: \n",
    "        return_params += [None,]\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('total throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    print ('voxel throughput = %fs/voxel' % (vox_loop_time / n_voxels))\n",
    "    print ('setup throughput = %fs/model' % (inv_time / n_prfs))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    best_params = [models[best_models],]+return_params+[features_mean, features_std]+[best_models]\n",
    "    \n",
    "    return best_losses, best_lambdas, best_params, feature_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b6a3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _cofactor_fn_cpu(_x, lambdas):\n",
    "    '''\n",
    "    Generating a matrix needed to solve ridge regression model for each lambda value.\n",
    "    Ridge regression (Tikhonov) solution is :\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    This func will return (X^T*X + I*lambda)^-1 * X^T. \n",
    "    So once we have that, can just multiply by training data (Y) to get weights.\n",
    "    returned size is [nLambdas x nFeatures x nTrials]\n",
    "    This version makes sure that the torch inverse operation is done on the cpu, and in floating point-64 precision.\n",
    "    Otherwise get bad results for small lambda values. This seems to be a torch-specific bug.\n",
    "    \n",
    "    '''\n",
    "    device_orig = _x.device\n",
    "    type_orig = _x.dtype\n",
    "    # switch to this specific format which works with inverse\n",
    "    _x = _x.to('cpu').to(torch.float64)\n",
    "    _f = torch.stack([(torch.mm(torch.t(_x), _x) + torch.eye(_x.size()[1], device='cpu', dtype=torch.float64) * l).inverse() for l in lambdas], axis=0) \n",
    "    \n",
    "    # [#lambdas, #feature, #feature] \n",
    "    cof = torch.tensordot(_f, _x, dims=[[2],[1]]) # [#lambdas, #feature, #sample]\n",
    "    \n",
    "    # put back to whatever way it was before, so that we can continue with other operations as usual\n",
    "    return cof.to(device_orig).to(type_orig)\n",
    "\n",
    "\n",
    "\n",
    "def _loss_fn(_cofactor, _vtrn, _xout, _vout):\n",
    "    '''\n",
    "    Calculate loss given \"cofactor\" from cofactor_fn, training data, held-out design matrix, held out data.\n",
    "    returns weights (betas) based on equation\n",
    "    w = (X^T*X + I*lambda)^-1 * X^T * Y\n",
    "    also returns loss for these weights w the held out data. SSE is loss func here.\n",
    "    '''\n",
    "\n",
    "    _beta = torch.tensordot(_cofactor, _vtrn, dims=[[2], [0]]) # [#lambdas, #feature, #voxel]\n",
    "    _pred = torch.tensordot(_xout, _beta, dims=[[1],[1]]) # [#samples, #lambdas, #voxels]\n",
    "    _loss = torch.sum(torch.pow(_vout[:,None,:] - _pred, 2), dim=0) # [#lambdas, #voxels]\n",
    "    return _beta, _loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b364a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting features for prf 0: [x,y,sigma] is [-0.55 -0.55 0.0400]\n",
      "Computing higher order correlations...\n",
      "time elapsed: 14.06518 s\n",
      "time elapsed = 40.48914\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Getting features for prf 1: [x,y,sigma] is [-0.49 -0.55 0.0400]\n",
      "Computing higher order correlations...\n",
      "time elapsed: 14.06656 s\n",
      "time elapsed = 41.45912\n",
      "Final size of features concatenated is [62 x 641]\n",
      "Feature types included are:\n",
      "['pixel_stats', 'mean_magnitudes', 'mean_realparts', 'marginal_stats_lowpass_recons', 'variance_highpass_resid', 'magnitude_feature_autocorrs', 'lowpass_recon_autocorrs', 'highpass_resid_autocorrs', 'magnitude_within_scale_crosscorrs', 'real_within_scale_crosscorrs', 'magnitude_across_scale_crosscorrs', 'real_imag_across_scale_crosscorrs', 'real_spatshift_within_scale_crosscorrs', 'real_spatshift_across_scale_crosscorrs']\n",
      "Getting predictions for voxels [0-99] of 14913\n",
      "\n",
      "Partial version 0 of 15\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 641 but corresponding boolean dimension is 642",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2b8e2e067cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                                              \u001b[0mval_stim_single_trial_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_texture_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                                              \u001b[0msample_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoxel_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                                              debug=debug, dtype=fpX)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-d3a7001c9823>\u001b[0m in \u001b[0;36mvalidate_texture_model_varpart\u001b[0;34m(best_params, prf_models, val_voxel_single_trial_data, val_stim_single_trial_data, _texture_fn, sample_batch_size, voxel_batch_size, debug, dtype)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mnonzero_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnonzero_inds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# making sure to gather only the columns for features included in this partial model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 641 but corresponding boolean dimension is 642"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# val_cc, val_r2 = fwrf_predict.validate_texture_model(best_params, models, val_voxel_single_trial_data, val_stim_single_trial_data, \\\n",
    "#                                                      _texture_fn, sample_batch_size=sample_batch_size, voxel_batch_size=voxel_batch_size, \\\n",
    "#                                                      debug=debug, dtype=fpX)\n",
    "\n",
    "val_cc_partial, val_r2_partial = validate_texture_model_varpart(best_params, models, val_voxel_single_trial_data, \\\n",
    "                                                                             val_stim_single_trial_data, _texture_fn, \\\n",
    "                                                                             sample_batch_size=sample_batch_size, voxel_batch_size=voxel_batch_size, \\\n",
    "                                                                             debug=debug, dtype=fpX)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "749f4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_texture_model_varpart(best_params, prf_models, val_voxel_single_trial_data, val_stim_single_trial_data, _texture_fn, sample_batch_size=100, voxel_batch_size=100, debug=False, dtype=np.float32):\n",
    "    \n",
    "    \"\"\" \n",
    "    Evaluate trained model, leaving out a subset of features at a time.\n",
    "    \"\"\"\n",
    "    images = val_stim_single_trial_data\n",
    "    params = best_params\n",
    "    dtype = images.dtype.type\n",
    "    device = _texture_fn.device\n",
    "    \n",
    "    n_trials, n_voxels = len(images), len(params[0])\n",
    "    n_prfs = prf_models.shape[0]\n",
    "    n_features = params[1].shape[1]  \n",
    "\n",
    "    best_models, weights, bias, features_mt, features_st, best_model_inds = params\n",
    "    \n",
    "    # val_cc is the correlation coefficient bw real and predicted responses across trials, for each voxel.\n",
    "    n_voxels = np.shape(val_voxel_single_trial_data)[1]\n",
    "    n_feature_types = len(_texture_fn.feature_types_include)\n",
    "    n_partial_versions = n_feature_types+1\n",
    "    \n",
    "    \n",
    "    val_cc  = np.zeros(shape=(n_voxels, n_partial_versions), dtype=dtype)\n",
    "    val_r2 = np.zeros(shape=(n_voxels, n_partial_versions), dtype=dtype)\n",
    "\n",
    "    pred_models = np.full(fill_value=0, shape=(n_trials, n_features, n_prfs), dtype=dtype)\n",
    "    \n",
    "    start_time = time.time()    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # First gather texture features for all pRFs.\n",
    "        for mm in range(n_prfs):\n",
    "            if mm>1 and debug:\n",
    "                break\n",
    "            print('Getting features for prf %d: [x,y,sigma] is [%.2f %.2f %.4f]'%(mm, prf_models[mm,0],  prf_models[mm,1],  prf_models[mm,2] ))\n",
    "            all_feat_concat, feature_info = _texture_fn(images,prf_models[mm,:])\n",
    "            \n",
    "            pred_models[:,:,mm] = torch_utils.get_value(all_feat_concat)\n",
    "        \n",
    "    \n",
    "        vv=-1\n",
    "        ## Looping over voxels here in batches, will eventually go through all.\n",
    "        for rv, lv in numpy_utility.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "            vv=vv+1\n",
    "            print('Getting predictions for voxels [%d-%d] of %d'%(rv[0],rv[-1],n_voxels))\n",
    "\n",
    "            if vv>1 and debug:\n",
    "                break\n",
    "                \n",
    "            # [trials x features x voxels]\n",
    "            features_full = pred_models[:,:,best_model_inds[rv]]\n",
    "            \n",
    "            masks = np.concatenate([np.expand_dims(np.array(_texture_fn.feature_column_labels!=ff).astype('int'), axis=0) for ff in np.arange(-1,n_feature_types)], axis=0)\n",
    "            masks = np.concatenate([masks, np.ones([masks.shape[0],1])], axis=1) # always include intercept \n",
    "            masks = np.transpose(masks)\n",
    "            # masks is [n_features_total (including intercept) x n_partial_versions]\n",
    "\n",
    "            # Looping over versions of model w different features set to zero (variance partition)\n",
    "            for pp in range(n_partial_versions):\n",
    "                \n",
    "                print('\\nPartial version %d of %d'%(pp, n_partial_versions))\n",
    "\n",
    "                nonzero_inds = masks[:,pp]==1\n",
    "                \n",
    "                features = features_full[:,nonzero_inds,:]\n",
    "\n",
    "                # making sure to gather only the columns for features included in this partial model\n",
    "                _weights = torch_utils._to_torch(weights[rv,nonzero_inds]) \n",
    "                \n",
    "                _bias = torch_utils._to_torch(bias[rv])\n",
    "\n",
    "            \n",
    "                if features_mt is not None:\n",
    "                    _features_m = torch_utils._to_torch(features_mt[rv,nonzero_inds])\n",
    "                if features_st is not None:\n",
    "                    _features_s = torch_utils._to_torch(features_st[rv,nonzero_inds])\n",
    "                \n",
    "                pred_block = np.full(fill_value=0, shape=(n_trials, lv), dtype=dtype)\n",
    "                \n",
    "                \n",
    "                # Now looping over validation set trials in batches\n",
    "                for rt, lt in numpy_utility.iterate_range(0, n_trials, sample_batch_size):\n",
    "\n",
    "                    _features = torch_utils._to_torch(features[rt,:,:]) # trials x features x voxels\n",
    "                    if features_mt is not None:    \n",
    "                        # features_m is [nvoxels x nfeatures] - need [trials x features x voxels]\n",
    "                        _features = _features - torch.tile(torch.unsqueeze(_features_m, dim=0), [_features.shape[0], 1, 1]).moveaxis([1],[2])\n",
    "\n",
    "                    if features_st is not None:\n",
    "                        _features = _features/torch.tile(torch.unsqueeze(_features_s, dim=0), [_features.shape[0], 1, 1]).moveaxis([1],[2])\n",
    "                        _features[torch.isnan(_features)] = 0.0 # this applies in the pca case when last few columns of features are missing\n",
    "\n",
    "                    # features is [#samples, #features, #voxels] - swap dims to [#voxels, #samples, features]\n",
    "                    _features = torch.transpose(torch.transpose(_features, 0, 2), 1, 2)\n",
    "                    # weights is [#voxels, #features]\n",
    "                    # _r will be [#voxels, #samples, 1] - then [#samples, #voxels]\n",
    "\n",
    "                    _r = torch.squeeze(torch.bmm(_features, torch.unsqueeze(_weights, 2)), dim=2).t() \n",
    "\n",
    "                    if _bias is not None:\n",
    "                        _r = _r + torch.tile(torch.unsqueeze(_bias, 0), [_r.shape[0],1])\n",
    "\n",
    "                    pred_block[rt] = torch_utils.get_value(_r) \n",
    "\n",
    "                # Now for this batch of voxels and this partial version of the model, measure performance.\n",
    "                print('\\nEvaluating correlation coefficient on validation set...\\n')\n",
    "                for vi in range(lv):   \n",
    "                    val_cc[rv[vi],pp] = np.corrcoef(val_voxel_single_trial_data[:,rv[vi]], pred_block[:,vi])[0,1]  \n",
    "                    val_r2[rv[vi],pp] = get_r2(val_voxel_single_trial_data[:,rv[vi]], pred_block[:,vi])\n",
    "                \n",
    "                sys.stdout.flush()\n",
    "        \n",
    "    val_cc = np.nan_to_num(val_cc)\n",
    "    val_r2 = np.nan_to_num(val_r2) \n",
    "    \n",
    "    return val_cc, val_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642508c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_predictions_texture_model(images, _texture_fn, params, prf_models, sample_batch_size=100, voxel_batch_size=100, debug=False):\n",
    "   \n",
    "    dtype = images.dtype.type\n",
    "    device = _texture_fn.device\n",
    "\n",
    "    best_models, weights, bias, features_mt, features_st, best_model_inds = params\n",
    "        \n",
    "    n_trials, n_voxels = len(images), len(params[0])\n",
    "    n_prfs = prf_models.shape[0]\n",
    "    n_features = params[1].shape[1]    \n",
    "    \n",
    "    pred = np.full(fill_value=0, shape=(n_trials, n_voxels), dtype=dtype)\n",
    "    pred_models = np.full(fill_value=0, shape=(n_trials, n_features, n_prfs), dtype=dtype)\n",
    "    \n",
    "    start_time = time.time()    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # First gather texture features for all pRFs.\n",
    "        for mm in range(n_prfs):\n",
    "            if mm>1 and debug:\n",
    "                break\n",
    "            print('Getting features for prf %d: [x,y,sigma] is [%.2f %.2f %.4f]'%(mm, prf_models[mm,0],  prf_models[mm,1],  prf_models[mm,2] ))\n",
    "            all_feat_concat, feature_info = _texture_fn(images,prf_models[mm,:])\n",
    "            \n",
    "            pred_models[:,:,mm] = torch_utils.get_value(all_feat_concat)\n",
    "        \n",
    "        vv=-1\n",
    "        ## Looping over voxels here in batches, will eventually go through all.\n",
    "        for rv, lv in numpy_utility.iterate_range(0, n_voxels, voxel_batch_size):\n",
    "            vv=vv+1\n",
    "            print('Getting predictions for voxels [%d-%d] of %d'%(rv[0],rv[-1],n_voxels))\n",
    "\n",
    "            if vv>1 and debug:\n",
    "                break\n",
    "                \n",
    "            # [trials x features x voxels]\n",
    "            features = pred_models[:,:,best_model_inds[rv]]\n",
    "\n",
    "            pred_block = np.full(fill_value=0, shape=(n_trials, lv), dtype=dtype)\n",
    "            if features_mt is not None:\n",
    "                _features_m = torch_utils._to_torch(features_mt[rv,:])\n",
    "            if features_st is not None:\n",
    "                _features_s = torch_utils._to_torch(features_st[rv,:])\n",
    "            _weights = torch_utils._to_torch(weights[rv,:])\n",
    "            _bias = torch_utils._to_torch(bias[rv])\n",
    "                \n",
    "            # Now looping over validation set trials in batches\n",
    "            for rt, lt in numpy_utility.iterate_range(0, n_trials, sample_batch_size):\n",
    "\n",
    "                _features = torch_utils._to_torch(features[rt,:,:]) # trials x features x voxels\n",
    "                if features_mt is not None:    \n",
    "                    # features_m is [nvoxels x nfeatures] - need [trials x features x voxels]\n",
    "                    _features = _features - torch.tile(torch.unsqueeze(_features_m, dim=0), [_features.shape[0], 1, 1]).moveaxis([1],[2])\n",
    "\n",
    "                if features_st is not None:\n",
    "                    _features = _features/torch.tile(torch.unsqueeze(_features_s, dim=0), [_features.shape[0], 1, 1]).moveaxis([1],[2])\n",
    "                    _features[torch.isnan(_features)] = 0.0 # this applies in the pca case when last few columns of features are missing\n",
    "\n",
    "                # features is [#samples, #features, #voxels] - swap dims to [#voxels, #samples, features]\n",
    "                _features = torch.transpose(torch.transpose(_features, 0, 2), 1, 2)\n",
    "                # weights is [#voxels, #features]\n",
    "                # _r will be [#voxels, #samples, 1] - then [#samples, #voxels]\n",
    "\n",
    "                _r = torch.squeeze(torch.bmm(_features, torch.unsqueeze(_weights, 2)), dim=2).t() \n",
    "\n",
    "                if _bias is not None:\n",
    "                    _r = _r + torch.tile(torch.unsqueeze(_bias, 0), [_r.shape[0],1])\n",
    "\n",
    "                pred_block[rt] = torch_utils.get_value(_r) \n",
    "                \n",
    "            pred[:,rv] = pred_block\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    print ('\\n---------------------------------------')\n",
    "    print ('total time = %fs' % total_time)\n",
    "    print ('sample throughput = %fs/sample' % (total_time / n_trials))\n",
    "    print ('voxel throughput = %fs/voxel' % (total_time / n_voxels))\n",
    "    sys.stdout.flush()\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
